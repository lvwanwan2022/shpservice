#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“è¿æ¥å’Œæ“ä½œæ¨¡å—
"""

import psycopg2
from psycopg2.extras import RealDictCursor
from config import DB_CONFIG
import time
import json
import os

def get_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        # ä½¿ç”¨æ˜ç¡®çš„å‚æ•°è¿æ¥ï¼Œé¿å…ç¼–ç é—®é¢˜
        # è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨è‹±æ–‡é”™è¯¯ä¿¡æ¯
        os.environ['LC_ALL'] = 'C'
        os.environ['LANG'] = 'C'
        
        conn = psycopg2.connect(
            host=DB_CONFIG['host'],
            port=DB_CONFIG['port'],
            database=DB_CONFIG['database'],
            user=DB_CONFIG['user'],
            password=DB_CONFIG['password'],
            client_encoding='utf8'
        )
        # è®¾ç½®ä¼šè¯ç¼–ç 
        conn.set_client_encoding('UTF8')
        return conn
    except psycopg2.OperationalError as e:
        # å¤„ç†ç¼–ç é—®é¢˜ - å°è¯•è§£æGB2312ç¼–ç çš„é”™è¯¯ä¿¡æ¯
        error_msg = str(e)
        try:
            # å¦‚æœåŸå§‹é”™è¯¯åŒ…å«å­—èŠ‚ä¿¡æ¯ï¼Œå°è¯•è§£ç 
            if hasattr(e, 'args') and len(e.args) > 1:
                error_bytes = e.args[1]
                if isinstance(error_bytes, bytes):
                    try:
                        decoded_msg = error_bytes.decode('gb2312', errors='ignore')
                        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - è¿æ¥é”™è¯¯: {decoded_msg}"
                    except:
                        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - è¿æ¥é”™è¯¯: {error_msg}"
        except:
            pass
        
        print(error_msg)
        raise Exception(error_msg)
    except psycopg2.DatabaseError as e:
        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - æ•°æ®åº“é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    except UnicodeDecodeError as e:
        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - ç¼–ç é”™è¯¯: PostgreSQLæœåŠ¡å™¨è¿”å›äº†éUTF-8ç¼–ç çš„é”™è¯¯ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯ä¸­æ–‡Windowsç³»ç»Ÿçš„ç¼–ç é—®é¢˜"
        print(error_msg)
        print("ğŸ’¡ å»ºè®®:")
        print("   - æ£€æŸ¥PostgreSQLé…ç½®æ–‡ä»¶ä¸­çš„è¯­è¨€è®¾ç½®")
        print("   - ç¡®ä¿PostgreSQLä½¿ç”¨UTF-8ç¼–ç ")
        print("   - æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç æ˜¯å¦æ­£ç¡®")
        raise Exception(error_msg)
    except Exception as e:
        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - æœªçŸ¥é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)

def execute_query(query, params=None, fetch=True):
    """æ‰§è¡ŒSQLæŸ¥è¯¢
    
    Args:
        query: SQLæŸ¥è¯¢è¯­å¥
        params: æŸ¥è¯¢å‚æ•°
        fetch: æ˜¯å¦è·å–ç»“æœ
        
    Returns:
        æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼ˆå¦‚æœfetch=Trueï¼‰
    """
    conn = None
    try:
        conn = get_connection()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute(query, params)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¿®æ”¹æ“ä½œï¼ˆINSERT/UPDATE/DELETEï¼‰
            query_type = query.strip().upper().split()[0]
            is_modify_operation = query_type in ('INSERT', 'UPDATE', 'DELETE')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰RETURNINGå­å¥
            has_returning = 'RETURNING' in query.upper()
            
            if fetch and (not is_modify_operation or has_returning):
                # åªæœ‰åœ¨éä¿®æ”¹æ“ä½œæˆ–æœ‰RETURNINGå­å¥æ—¶æ‰è·å–ç»“æœ
                result = cursor.fetchall()
                # å¦‚æœæ˜¯ä¿®æ”¹æ“ä½œï¼Œæäº¤äº‹åŠ¡
                if is_modify_operation:
                    conn.commit()
                
                # è½¬æ¢ç»“æœä¸ºå­—å…¸åˆ—è¡¨
                dict_result = []
                for row in result:
                    # å°† RealDictRow è½¬æ¢ä¸ºæ™®é€šå­—å…¸
                    row_dict = dict(row)
                    # ç‰¹æ®Šå¤„ç†JSONå­—æ®µ
                    for key, value in row_dict.items():
                        if isinstance(value, (dict, list)):
                            row_dict[key] = value
                    dict_result.append(row_dict)
                return dict_result
            else:
                # å¯¹äºä¿®æ”¹æ“ä½œï¼ˆä¸å¸¦RETURNINGï¼‰æˆ–ä¸éœ€è¦è·å–ç»“æœçš„æ“ä½œï¼Œç›´æ¥æäº¤
                if is_modify_operation:
                    conn.commit()
                    # è¿”å›å—å½±å“çš„è¡Œæ•°
                    return cursor.rowcount
                else:
                    conn.commit()
                return None
                
    except psycopg2.OperationalError as e:
        if conn:
            conn.rollback()
        error_msg = f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥ - è¿æ¥é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    except psycopg2.DatabaseError as e:
        if conn:
            conn.rollback()
        error_msg = f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥ - æ•°æ®åº“é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    except Exception as e:
        if conn:
            conn.rollback()
        error_msg = f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥ - æœªçŸ¥é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    finally:
        if conn:
            conn.close()

def execute_transaction(queries):
    """æ‰§è¡Œå¤šä¸ªSQLæŸ¥è¯¢ä½œä¸ºå•ä¸ªäº‹åŠ¡
    
    Args:
        queries: (query, params)å…ƒç»„åˆ—è¡¨
        
    Returns:
        æœ€åä¸€ä¸ªæŸ¥è¯¢çš„ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    """
    conn = None
    result = None
    try:
        conn = get_connection()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            for query, params in queries:
                cursor.execute(query, params)
                
                # å¦‚æœæ˜¯SELECTæŸ¥è¯¢ï¼Œè·å–ç»“æœ
                if query.strip().upper().startswith('SELECT'):
                    result = cursor.fetchall()
            
            conn.commit()
            
            # è½¬æ¢ç»“æœä¸ºå­—å…¸åˆ—è¡¨
            if result:
                dict_result = []
                for row in result:
                    dict_result.append(dict(row))
                return dict_result
            return None
                
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"æ‰§è¡Œäº‹åŠ¡å¤±è´¥: {str(e)}")
        raise
    finally:
        if conn:
            conn.close()

def execute_batch(query, params_list):
    """æ‰¹é‡æ‰§è¡ŒSQLæŸ¥è¯¢
    
    Args:
        query: SQLæŸ¥è¯¢è¯­å¥
        params_list: å‚æ•°åˆ—è¡¨
        
    Returns:
        None
    """
    conn = None
    try:
        conn = get_connection()
        with conn.cursor() as cursor:
            for params in params_list:
                cursor.execute(query, params)
            conn.commit()
                
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"æ‰¹é‡æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥: {str(e)}")
        raise
    finally:
        if conn:
            conn.close()

def check_table_exists(table_name):
    """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    
    Args:
        table_name: è¡¨å
        
    Returns:
        å¸ƒå°”å€¼ï¼Œè¡¨ç¤ºè¡¨æ˜¯å¦å­˜åœ¨
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_schema = 'public'
        AND table_name = %s
    )
    """
    
    result = execute_query(query, (table_name,))
    return result[0]['exists'] if result else False

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    try:
        # æ£€æŸ¥å¹¶åˆ›å»ºPostGISæ‰©å±•
        check_postgis_sql = """
        SELECT EXISTS (
            SELECT 1 FROM pg_extension WHERE extname = 'postgis'
        )
        """
        result = execute_query(check_postgis_sql)
        has_postgis = result[0]['exists']
        
        if not has_postgis:
            print("PostGISæ‰©å±•ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º...")
            try:
                create_postgis_sql = "CREATE EXTENSION postgis"
                execute_query(create_postgis_sql, fetch=False)
                print("âœ… PostGISæ‰©å±•åˆ›å»ºæˆåŠŸ")
                
                # åˆ›å»ºPostGISæ‹“æ‰‘æ‰©å±•ï¼ˆå¯é€‰ï¼‰
                create_postgis_topology_sql = "CREATE EXTENSION postgis_topology"
                execute_query(create_postgis_topology_sql, fetch=False)
                print("âœ… PostGISæ‹“æ‰‘æ‰©å±•åˆ›å»ºæˆåŠŸ")
                
                # åˆ›å»ºå…¶ä»–æœ‰ç”¨çš„PostGISç›¸å…³æ‰©å±•
                try:
                    # ç”¨äºæ …æ ¼æ•°æ®å¤„ç†
                    execute_query("CREATE EXTENSION postgis_raster", fetch=False)
                    print("âœ… PostGISæ …æ ¼æ‰©å±•åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºPostGISæ …æ ¼æ‰©å±•å¤±è´¥: {str(e)}")
                
                try:
                    # ç”¨äºåœ°å€è§£æå’Œåœ°ç†ç¼–ç 
                    execute_query("CREATE EXTENSION fuzzystrmatch", fetch=False)
                    execute_query("CREATE EXTENSION address_standardizer", fetch=False)
                    execute_query("CREATE EXTENSION address_standardizer_data_us", fetch=False)
                    execute_query("CREATE EXTENSION postgis_tiger_geocoder", fetch=False)
                    print("âœ… PostGISåœ°ç†ç¼–ç æ‰©å±•åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºåœ°ç†ç¼–ç æ‰©å±•å¤±è´¥: {str(e)}")
                    print("éƒ¨åˆ†åœ°ç†ç¼–ç åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
                
                # åˆ›å»ºç©ºé—´ç´¢å¼•æ‰©å±•
                try:
                    execute_query("CREATE EXTENSION btree_gist", fetch=False)
                    print("âœ… GiSTç´¢å¼•æ‰©å±•åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºGiSTç´¢å¼•æ‰©å±•å¤±è´¥: {str(e)}")
            except Exception as e:
                print(f"âš ï¸ åˆ›å»ºPostGISæ‰©å±•å¤±è´¥: {str(e)}")
                print("è¯·ç¡®ä¿PostgreSQLå·²å®‰è£…PostGISï¼Œå¹¶ä¸”å½“å‰ç”¨æˆ·æœ‰åˆ›å»ºæ‰©å±•çš„æƒé™")
        else:
            print("âœ… PostGISæ‰©å±•å·²å­˜åœ¨")
            
            # æ£€æŸ¥PostGISç‰ˆæœ¬
            postgis_version_sql = "SELECT PostGIS_Version()"
            try:
                version_result = execute_query(postgis_version_sql)
                print(f"âœ… å½“å‰PostGISç‰ˆæœ¬: {version_result[0]['postgis_version']}")
            except:
                print("âš ï¸ æ— æ³•è·å–PostGISç‰ˆæœ¬ä¿¡æ¯")
            
            # æ£€æŸ¥å…¶ä»–æ‰©å±•
            check_extensions_sql = """
            SELECT extname FROM pg_extension 
            WHERE extname IN ('postgis_topology', 'postgis_raster', 'fuzzystrmatch', 
                             'address_standardizer', 'postgis_tiger_geocoder', 'btree_gist')
            """
            try:
                extensions_result = execute_query(check_extensions_sql)
                installed_extensions = [ext['extname'] for ext in extensions_result]
                print(f"âœ… å·²å®‰è£…çš„æ‰©å±•: {', '.join(installed_extensions)}")
                
                # æ£€æŸ¥ç¼ºå¤±çš„æ‰©å±•
                all_extensions = ['postgis_topology', 'postgis_raster', 'fuzzystrmatch', 
                                 'address_standardizer', 'postgis_tiger_geocoder', 'btree_gist']
                missing_extensions = [ext for ext in all_extensions if ext not in installed_extensions]
                
                if missing_extensions:
                    print(f"âš ï¸ ç¼ºå°‘çš„æ‰©å±•: {', '.join(missing_extensions)}")
                    print("éƒ¨åˆ†ç©ºé—´æ•°æ®åŠŸèƒ½å¯èƒ½å—é™")
            except:
                print("âš ï¸ æ— æ³•æ£€æŸ¥å·²å®‰è£…æ‰©å±•")
        
        # åˆ›å»ºç”¨æˆ·è¡¨
        create_users_table = """
        CREATE TABLE IF NOT EXISTS users (
            id BIGINT PRIMARY KEY,
            username VARCHAR(50) UNIQUE NOT NULL,
            password VARCHAR(100) NOT NULL,
            email VARCHAR(100) UNIQUE NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        execute_query(create_users_table, fetch=False)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·
        check_admin_user = "SELECT COUNT(*) FROM users WHERE username = 'admin'"
        admin_count = execute_query(check_admin_user)[0]['count']
        
        if admin_count == 0:
            # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·ï¼Œä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            import hashlib
            from utils.snowflake import get_snowflake_id
            
            # ç”Ÿæˆå¯†ç å“ˆå¸Œ
            default_password = "admin123"
            password_hash = hashlib.sha256(default_password.encode()).hexdigest()
            
            # ä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            admin_id = get_snowflake_id()
            
            # æ’å…¥ç®¡ç†å‘˜ç”¨æˆ·
            insert_admin_sql = """
            INSERT INTO users (id, username, password, email    ) 
            VALUES (%s, %s, %s, %s)
            """
            execute_query(insert_admin_sql, (admin_id, "admin", password_hash, "admin@example.com"), fetch=False)
            print("âœ… å·²åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ· (ç”¨æˆ·å: admin, å¯†ç : admin123)")
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºé»˜è®¤æ™®é€šç”¨æˆ·
        check_user_user = "SELECT COUNT(*) FROM users WHERE username = 'user'"
        user_count = execute_query(check_user_user)[0]['count']
        
        if user_count == 0:
            # åˆ›å»ºé»˜è®¤æ™®é€šç”¨æˆ·ï¼Œä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            import hashlib
            from utils.snowflake import get_snowflake_id
            
            # ç”Ÿæˆå¯†ç å“ˆå¸Œ
            default_password = "user123"
            password_hash = hashlib.sha256(default_password.encode()).hexdigest()
            
            # ä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            user_id = get_snowflake_id()
            
            # æ’å…¥ç®¡ç†å‘˜ç”¨æˆ·
            insert_user_sql = """
            INSERT INTO users (id, username, password, email    ) 
            VALUES (%s, %s, %s, %s)
            """
            execute_query(insert_user_sql, (user_id, "user", password_hash, "user@example.com"), fetch=False)
            print("âœ… å·²åˆ›å»ºé»˜è®¤æ™®é€šç”¨æˆ· (ç”¨æˆ·å: user, å¯†ç : user123)")
        # åˆ›å»ºæ–‡ä»¶è¡¨ - æ›´æ–°ä»¥åŒ¹é…æ–°çš„æ•°æ®åº“ç»“æ„
        create_files_table = """
        CREATE TABLE IF NOT EXISTS files (
            id BIGINT PRIMARY KEY,
            file_name VARCHAR(100) NOT NULL,
            file_path VARCHAR(200) NOT NULL,
            original_name VARCHAR(100) NOT NULL,
            file_size BIGINT NOT NULL,
            is_public BOOLEAN DEFAULT TRUE,
            discipline VARCHAR(50) NOT NULL,
            dimension VARCHAR(10) NOT NULL,
            file_type VARCHAR(20) NOT NULL,
            coordinate_system VARCHAR(20),
            tags VARCHAR(200),
            description TEXT,
            user_id BIGINT REFERENCES users(id),
            upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            status VARCHAR(20) DEFAULT 'uploaded',
            bbox JSONB,
            geometry_type VARCHAR(50),
            feature_count INTEGER,
            metadata JSONB
        )
        """
        
        # åˆ›å»ºGeoServerå·¥ä½œç©ºé—´è¡¨
        create_geoserver_workspaces_table = """
        CREATE TABLE IF NOT EXISTS geoserver_workspaces (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) UNIQUE NOT NULL,
            namespace_uri VARCHAR(255),
            namespace_prefix VARCHAR(100),
            description TEXT,
            is_default BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºGeoServerå­˜å‚¨ä»“åº“è¡¨
        create_geoserver_stores_table = """
        CREATE TABLE IF NOT EXISTS geoserver_stores (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            store_type VARCHAR(50) NOT NULL,
            data_type VARCHAR(50),
            connection_params JSONB,
            description TEXT,
            enabled BOOLEAN DEFAULT TRUE,
            file_id BIGINT REFERENCES files(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(workspace_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerè¦ç´ ç±»å‹è¡¨
        create_geoserver_featuretypes_table = """
        CREATE TABLE IF NOT EXISTS geoserver_featuretypes (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100),
            native_name VARCHAR(100),
            store_id BIGINT REFERENCES geoserver_stores(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            keywords TEXT[],
            srs VARCHAR(50),
            projection_policy VARCHAR(50) DEFAULT 'REPROJECT_TO_DECLARED',
            native_bbox JSONB,
            lat_lon_bbox JSONB,
            attributes JSONB,
            enabled BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(store_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerè¦†ç›–èŒƒå›´è¡¨
        create_geoserver_coverages_table = """
        CREATE TABLE IF NOT EXISTS geoserver_coverages (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            native_name VARCHAR(100),
            store_id BIGINT REFERENCES geoserver_stores(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            keywords TEXT[],
            srs VARCHAR(50) DEFAULT 'EPSG:4326',
            native_srs VARCHAR(50),
            native_bbox JSONB,
            lat_lon_bbox JSONB,
            grid_info JSONB,
            bands_info JSONB,
            enabled BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(store_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerå›¾å±‚è¡¨ - æ›´æ–°ä»¥æ”¯æŒçŸ¢é‡å’Œæ …æ ¼æ•°æ®
        create_geoserver_layers_table = """
        CREATE TABLE IF NOT EXISTS geoserver_layers (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            featuretype_id BIGINT REFERENCES geoserver_featuretypes(id) ON DELETE CASCADE,
            coverage_id BIGINT REFERENCES geoserver_coverages(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            default_style VARCHAR(100),
            additional_styles TEXT[],
            enabled BOOLEAN DEFAULT TRUE,
            queryable BOOLEAN DEFAULT TRUE,
            opaque BOOLEAN DEFAULT FALSE,
            attribution TEXT,
            wms_url TEXT,
            wfs_url TEXT,
            wcs_url TEXT,
            file_id BIGINT REFERENCES files(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            style_config JSONB,
            UNIQUE(workspace_id, name),
            CONSTRAINT check_data_source CHECK (
                (featuretype_id IS NOT NULL AND coverage_id IS NULL) OR 
                (featuretype_id IS NULL AND coverage_id IS NOT NULL)
            )
        )
        """
        
        # åˆ›å»ºGeoServeræ ·å¼è¡¨
        create_geoserver_styles_table = """
        CREATE TABLE IF NOT EXISTS geoserver_styles (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            filename VARCHAR(255),
            format VARCHAR(50) DEFAULT 'sld',
            language_version VARCHAR(20),
            content TEXT,
            description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(workspace_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerå›¾å±‚ç»„è¡¨
        create_geoserver_layergroups_table = """
        CREATE TABLE IF NOT EXISTS geoserver_layergroups (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            mode VARCHAR(50) DEFAULT 'SINGLE',
            layers JSONB,
            bounds JSONB,
            enabled BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(workspace_id, name)
        )
        """
        
        # åˆ›å»ºåœºæ™¯è¡¨ - æ›´æ–°ä»¥åŒ¹é…æ–°çš„æ•°æ®åº“ç»“æ„
        create_scenes_table = """
        CREATE TABLE IF NOT EXISTS scenes (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            description TEXT,
            is_public BOOLEAN DEFAULT TRUE,
            user_id BIGINT REFERENCES users(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºåœºæ™¯å›¾å±‚è¡¨ - æ›´æ–°ä»¥åŒ¹é…æ–°çš„æ•°æ®åº“ç»“æ„
        create_scene_layers_table = """
        CREATE TABLE IF NOT EXISTS scene_layers (
            id BIGINT PRIMARY KEY,
            scene_id BIGINT NOT NULL REFERENCES scenes(id) ON DELETE CASCADE,
            layer_id BIGINT NOT NULL,
            martin_service_id BIGINT,
            martin_service_type VARCHAR(20) DEFAULT NULL,
            layer_type VARCHAR(20) DEFAULT 'geoserver',
            layer_order INTEGER DEFAULT 0,
            visible BOOLEAN DEFAULT true,
            opacity NUMERIC(3,2) DEFAULT 1.0,
            style_name VARCHAR(100),
            custom_style JSONB,
            queryable BOOLEAN DEFAULT true,
            selectable BOOLEAN DEFAULT true,
            service_reference VARCHAR(100),
            service_url TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            CONSTRAINT chk_layer_type CHECK (layer_type IN ('geoserver', 'martin'))
        )
        """
        
        # åˆ›å»ºç»Ÿä¸€çš„çŸ¢é‡MartinæœåŠ¡è¡¨ï¼ˆåˆå¹¶geojsonå’ŒshpæœåŠ¡ï¼‰
        create_vector_martin_services_table = """
        CREATE TABLE IF NOT EXISTS vector_martin_services (
            id BIGINT PRIMARY KEY,
            file_id VARCHAR(36) NOT NULL UNIQUE,
            original_filename VARCHAR(255) NOT NULL,
            file_path TEXT NOT NULL,
            vector_type VARCHAR(20) NOT NULL, -- 'geojson' æˆ– 'shp'
            table_name VARCHAR(100) NOT NULL,
            service_url TEXT,
            mvt_url TEXT,
            tilejson_url TEXT,
            style JSONB,
            vector_info JSONB,  -- å­˜å‚¨åŸå§‹çŸ¢é‡æ–‡ä»¶ä¿¡æ¯
            postgis_info JSONB,
            status VARCHAR(20) DEFAULT 'active',
            user_id BIGINT REFERENCES users(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºGeoJSONæ–‡ä»¶è¡¨ï¼ˆç”¨äºGeoJSONç›´æ¥æœåŠ¡ï¼‰
        create_geojson_files_table = """
        CREATE TABLE IF NOT EXISTS geojson_files (
            id BIGINT PRIMARY KEY,
            file_id VARCHAR(36) NOT NULL UNIQUE,
            original_filename VARCHAR(255) NOT NULL,
            file_path TEXT NOT NULL,
            stored_path TEXT,
            file_size BIGINT NOT NULL,
            feature_count INTEGER DEFAULT 0,
            geometry_types JSONB,
            property_fields JSONB,
            bbox JSONB,
            upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            status VARCHAR(20) DEFAULT 'active',
            user_id BIGINT REFERENCES users(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºçŸ¢é‡MartinæœåŠ¡è¡¨çš„ç´¢å¼•
        create_vector_martin_services_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_file_id ON vector_martin_services(file_id)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_table_name ON vector_martin_services(table_name)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_vector_type ON vector_martin_services(vector_type)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_status ON vector_martin_services(status)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_user_id ON vector_martin_services(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_service_url ON vector_martin_services(service_url)"
        ]
        
        # åˆ›å»ºGeoJSONæ–‡ä»¶è¡¨çš„ç´¢å¼•
        create_geojson_files_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_file_id ON geojson_files(file_id)",
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_status ON geojson_files(status)",
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_user_id ON geojson_files(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_upload_date ON geojson_files(upload_date)"
        ]
        
        # åˆ›å»ºåœºæ™¯å›¾å±‚è¡¨çš„ç´¢å¼•
        create_scene_layers_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_scene_id ON scene_layers(scene_id)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_layer_id ON scene_layers(layer_id)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_martin_service_id ON scene_layers(martin_service_id)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_layer_order ON scene_layers(layer_order)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_order ON scene_layers(scene_id, layer_order)"
        ]
        
        # åˆ›å»ºå…¶ä»–è¡¨çš„ç´¢å¼•ï¼ˆä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼‰
        create_users_indexes = []
        create_files_indexes = []
        create_geoserver_workspaces_indexes = []
        create_geoserver_stores_indexes = []
        create_geoserver_featuretypes_indexes = []
        create_geoserver_coverages_indexes = []
        create_geoserver_layers_indexes = []
        create_geoserver_styles_indexes = []
        create_geoserver_layergroups_indexes = []
        create_scenes_indexes = []
        
        # æ‰§è¡Œæ‰€æœ‰åˆ›å»ºè¡¨çš„SQL
        tables = [
            create_users_table,
            create_files_table,
            create_geoserver_workspaces_table,
            create_geoserver_stores_table,
            create_geoserver_featuretypes_table,
            create_geoserver_coverages_table,
            create_geoserver_layers_table,
            create_geoserver_styles_table,
            create_geoserver_layergroups_table,
            create_scenes_table,
            create_scene_layers_table,
            create_vector_martin_services_table,
            create_geojson_files_table
        ]
        
        for table_sql in tables:
            execute_query(table_sql, fetch=False)
        
        # åˆ›å»ºæ‰€æœ‰ç´¢å¼•
        all_indexes = (
            create_users_indexes +
            create_files_indexes +
            create_geoserver_workspaces_indexes +
            create_geoserver_stores_indexes +
            create_geoserver_featuretypes_indexes +
            create_geoserver_coverages_indexes +
            create_geoserver_layers_indexes +
            create_geoserver_styles_indexes +
            create_geoserver_layergroups_indexes +
            create_scenes_indexes +
            create_vector_martin_services_indexes +
            create_scene_layers_indexes +
            create_geojson_files_indexes
        )
        
        for index_sql in all_indexes:
            execute_query(index_sql, fetch=False)
        
        print("æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        
      
        
        
        # ç¡®ä¿GeoServerå·¥ä½œç©ºé—´å­˜åœ¨
        try:
            from config import GEOSERVER_CONFIG
            workspace_name = GEOSERVER_CONFIG.get('workspace', 'shpservice')
            
            # æ£€æŸ¥geoserver_workspacesè¡¨ä¸­æ˜¯å¦å·²å­˜åœ¨è¯¥å·¥ä½œç©ºé—´
            workspace_check_sql = """
            SELECT id FROM geoserver_workspaces WHERE name = %s
            """
            workspace_result = execute_query(workspace_check_sql, (workspace_name,))
            
            if not workspace_result:
                print(f"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºGeoServerå·¥ä½œç©ºé—´è®°å½•: {workspace_name}")
                # åœ¨æ•°æ®åº“ä¸­åˆ›å»ºå·¥ä½œç©ºé—´è®°å½•
                insert_workspace_sql = """
                INSERT INTO geoserver_workspaces 
                (id,name, namespace_uri, namespace_prefix, description, is_default, created_at, updated_at)
                VALUES (%s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                RETURNING id
                """
                # ç”Ÿæˆé›ªèŠ±ç®—æ³•ID
                from utils.snowflake import get_snowflake_id
                id=get_snowflake_id()
                result = execute_query(insert_workspace_sql, (
                    id,
                    workspace_name,
                    f"http://{workspace_name}",
                    workspace_name,
                    f"Default workspace for {workspace_name}",
                    True
                ))
                
                workspace_id = result[0]['id']
                print(f"âœ… æ•°æ®åº“ä¸­GeoServerå·¥ä½œç©ºé—´è®°å½•åˆ›å»ºæˆåŠŸï¼ŒID: {workspace_id}")
                
                # å°è¯•åœ¨GeoServerä¸­åˆ›å»ºå·¥ä½œç©ºé—´
                try:
                    # å¯¼å…¥GeoServerServiceå¹¶åˆ›å»ºå·¥ä½œç©ºé—´
                    from services.geoserver_service import GeoServerService
                    geoserver = GeoServerService()
                    geoserver._create_workspace_in_geoserver()
                    print(f"âœ… GeoServerä¸­å·¥ä½œç©ºé—´ {workspace_name} åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ GeoServerä¸­åˆ›å»ºå·¥ä½œç©ºé—´å¤±è´¥: {str(e)}")
                    print("è¯·ç¡®ä¿GeoServeræœåŠ¡æ­£åœ¨è¿è¡Œï¼Œå¹¶æ£€æŸ¥è¿æ¥é…ç½®")
            else:
                print(f"âœ… æ•°æ®åº“ä¸­GeoServerå·¥ä½œç©ºé—´ {workspace_name} å·²å­˜åœ¨ï¼ŒID: {workspace_result[0]['id']}")
                
                # æ£€æŸ¥GeoServerä¸­æ˜¯å¦å­˜åœ¨è¯¥å·¥ä½œç©ºé—´
                try:
                    from services.geoserver_service import GeoServerService
                    geoserver = GeoServerService()
                    # æ£€æŸ¥å·¥ä½œç©ºé—´
                    geoserver._ensure_workspace_exists()
                    print(f"âœ… GeoServerä¸­å·¥ä½œç©ºé—´ {workspace_name} å·²å­˜åœ¨")
                except Exception as e:
                    print(f"âš ï¸ GeoServerå·¥ä½œç©ºé—´æ£€æŸ¥å¤±è´¥: {str(e)}")
        except Exception as e:
            print(f"âš ï¸ GeoServerå·¥ä½œç©ºé—´åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        
        print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
    except Exception as e:
        print(f"åˆå§‹åŒ–æ•°æ®åº“å¤±è´¥: {str(e)}")
        raise

def insert_with_snowflake_id(table_name, data):
    """
    ä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆIDå¹¶æ’å…¥æ•°æ®
    
    Args:
        table_name: è¡¨å
        data: è¦æ’å…¥çš„æ•°æ®å­—å…¸
        
    Returns:
        æ’å…¥çš„è®°å½•ID
    """
    try:
        # ç”Ÿæˆé›ªèŠ±ç®—æ³•ID
        from utils.snowflake import get_snowflake_id
        snowflake_id = get_snowflake_id()
        
        # æ·»åŠ IDåˆ°æ•°æ®ä¸­
        data['id'] = snowflake_id
        
        # æ„å»ºSQLè¯­å¥
        columns = list(data.keys())
        placeholders = [f'%({col})s' for col in columns]
        
        query = f"""
        INSERT INTO {table_name} ({', '.join(columns)})
        VALUES ({', '.join(placeholders)})
        RETURNING id
        """
        
        # æ‰§è¡Œæ’å…¥
        result = execute_query(query, data)
        
        # è¿”å›æ’å…¥çš„ID
        if result and len(result) > 0:
            return result[0]['id']
        return snowflake_id
    except Exception as e:
        error_msg = f"æ’å…¥æ•°æ®åˆ°{table_name}å¤±è´¥: {str(e)}"
        print(error_msg)
        print(f"æ•°æ®: {data}")
        print(f"é›ªèŠ±ID: {snowflake_id}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ•´æ•°èŒƒå›´é”™è¯¯
        if "integer out of range" in str(e).lower():
            print("é”™è¯¯: é›ªèŠ±ç®—æ³•IDè¶…å‡ºäº†INTEGERèŒƒå›´ï¼Œè¯·ç¡®ä¿æ•°æ®åº“è¡¨çš„IDå­—æ®µç±»å‹æ˜¯BIGINT")
            print("è§£å†³æ–¹æ¡ˆ: è¯·æ‰§è¡Œä»¥ä¸‹SQLä¿®æ”¹è¡¨ç»“æ„:")
            print(f"ALTER TABLE {table_name} ALTER COLUMN id TYPE BIGINT;")
        
        raise

if __name__ == "__main__":
    init_database() 