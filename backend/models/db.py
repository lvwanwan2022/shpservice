#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“è¿æ¥å’Œæ“ä½œæ¨¡å—
"""

import psycopg2
from psycopg2.extras import RealDictCursor
from config import DB_CONFIG
import time
import json
import os

def get_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        # ä½¿ç”¨æ˜ç¡®çš„å‚æ•°è¿æ¥ï¼Œé¿å…ç¼–ç é—®é¢˜
        # è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨è‹±æ–‡é”™è¯¯ä¿¡æ¯
        os.environ['LC_ALL'] = 'C'
        os.environ['LANG'] = 'C'
        
        conn = psycopg2.connect(
            host=DB_CONFIG['host'],
            port=DB_CONFIG['port'],
            database=DB_CONFIG['database'],
            user=DB_CONFIG['user'],
            password=DB_CONFIG['password'],
            client_encoding='utf8'
        )
        # è®¾ç½®ä¼šè¯ç¼–ç 
        conn.set_client_encoding('UTF8')
        return conn
    except psycopg2.OperationalError as e:
        # å¤„ç†ç¼–ç é—®é¢˜ - å°è¯•è§£æGB2312ç¼–ç çš„é”™è¯¯ä¿¡æ¯
        error_msg = str(e)
        try:
            # å¦‚æœåŸå§‹é”™è¯¯åŒ…å«å­—èŠ‚ä¿¡æ¯ï¼Œå°è¯•è§£ç 
            if hasattr(e, 'args') and len(e.args) > 1:
                error_bytes = e.args[1]
                if isinstance(error_bytes, bytes):
                    try:
                        decoded_msg = error_bytes.decode('gb2312', errors='ignore')
                        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - è¿æ¥é”™è¯¯: {decoded_msg}"
                    except:
                        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - è¿æ¥é”™è¯¯: {error_msg}"
        except:
            pass
        
        print(error_msg)
        raise Exception(error_msg)
    except psycopg2.DatabaseError as e:
        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - æ•°æ®åº“é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    except UnicodeDecodeError as e:
        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - ç¼–ç é”™è¯¯: PostgreSQLæœåŠ¡å™¨è¿”å›äº†éUTF-8ç¼–ç çš„é”™è¯¯ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯ä¸­æ–‡Windowsç³»ç»Ÿçš„ç¼–ç é—®é¢˜"
        print(error_msg)
        print("ğŸ’¡ å»ºè®®:")
        print("   - æ£€æŸ¥PostgreSQLé…ç½®æ–‡ä»¶ä¸­çš„è¯­è¨€è®¾ç½®")
        print("   - ç¡®ä¿PostgreSQLä½¿ç”¨UTF-8ç¼–ç ")
        print("   - æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç æ˜¯å¦æ­£ç¡®")
        raise Exception(error_msg)
    except Exception as e:
        error_msg = f"æ•°æ®åº“è¿æ¥å¤±è´¥ - æœªçŸ¥é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)

def execute_query(query, params=None, fetch=True):
    """æ‰§è¡ŒSQLæŸ¥è¯¢
    
    Args:
        query: SQLæŸ¥è¯¢è¯­å¥
        params: æŸ¥è¯¢å‚æ•°
        fetch: æ˜¯å¦è·å–ç»“æœ
        
    Returns:
        æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼ˆå¦‚æœfetch=Trueï¼‰
    """
    conn = None
    try:
        conn = get_connection()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute(query, params)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¿®æ”¹æ“ä½œï¼ˆINSERT/UPDATE/DELETEï¼‰
            query_type = query.strip().upper().split()[0]
            is_modify_operation = query_type in ('INSERT', 'UPDATE', 'DELETE')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰RETURNINGå­å¥
            has_returning = 'RETURNING' in query.upper()
            
            if fetch and (not is_modify_operation or has_returning):
                # åªæœ‰åœ¨éä¿®æ”¹æ“ä½œæˆ–æœ‰RETURNINGå­å¥æ—¶æ‰è·å–ç»“æœ
                result = cursor.fetchall()
                # å¦‚æœæ˜¯ä¿®æ”¹æ“ä½œï¼Œæäº¤äº‹åŠ¡
                if is_modify_operation:
                    conn.commit()
                
                # è½¬æ¢ç»“æœä¸ºå­—å…¸åˆ—è¡¨
                dict_result = []
                for row in result:
                    # å°† RealDictRow è½¬æ¢ä¸ºæ™®é€šå­—å…¸
                    row_dict = dict(row)
                    # ç‰¹æ®Šå¤„ç†JSONå­—æ®µ
                    for key, value in row_dict.items():
                        if isinstance(value, (dict, list)):
                            row_dict[key] = value
                    dict_result.append(row_dict)
                return dict_result
            else:
                # å¯¹äºä¿®æ”¹æ“ä½œï¼ˆä¸å¸¦RETURNINGï¼‰æˆ–ä¸éœ€è¦è·å–ç»“æœçš„æ“ä½œï¼Œç›´æ¥æäº¤
                if is_modify_operation:
                    conn.commit()
                    # è¿”å›å—å½±å“çš„è¡Œæ•°
                    return cursor.rowcount
                else:
                    conn.commit()
                return None
                
    except psycopg2.OperationalError as e:
        if conn:
            conn.rollback()
        error_msg = f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥ - è¿æ¥é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    except psycopg2.DatabaseError as e:
        if conn:
            conn.rollback()
        error_msg = f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥ - æ•°æ®åº“é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    except Exception as e:
        if conn:
            conn.rollback()
        error_msg = f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥ - æœªçŸ¥é”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(error_msg)
    finally:
        if conn:
            conn.close()

def execute_transaction(queries):
    """æ‰§è¡Œå¤šä¸ªSQLæŸ¥è¯¢ä½œä¸ºå•ä¸ªäº‹åŠ¡
    
    Args:
        queries: (query, params)å…ƒç»„åˆ—è¡¨
        
    Returns:
        æœ€åä¸€ä¸ªæŸ¥è¯¢çš„ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    """
    conn = None
    result = None
    try:
        conn = get_connection()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            for query, params in queries:
                cursor.execute(query, params)
                
                # å¦‚æœæ˜¯SELECTæŸ¥è¯¢ï¼Œè·å–ç»“æœ
                if query.strip().upper().startswith('SELECT'):
                    result = cursor.fetchall()
            
            conn.commit()
            
            # è½¬æ¢ç»“æœä¸ºå­—å…¸åˆ—è¡¨
            if result:
                dict_result = []
                for row in result:
                    dict_result.append(dict(row))
                return dict_result
            return None
                
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"æ‰§è¡Œäº‹åŠ¡å¤±è´¥: {str(e)}")
        raise
    finally:
        if conn:
            conn.close()

def execute_batch(query, params_list):
    """æ‰¹é‡æ‰§è¡ŒSQLæŸ¥è¯¢
    
    Args:
        query: SQLæŸ¥è¯¢è¯­å¥
        params_list: å‚æ•°åˆ—è¡¨
        
    Returns:
        None
    """
    conn = None
    try:
        conn = get_connection()
        with conn.cursor() as cursor:
            for params in params_list:
                cursor.execute(query, params)
            conn.commit()
                
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"æ‰¹é‡æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥: {str(e)}")
        raise
    finally:
        if conn:
            conn.close()

def check_table_exists(table_name):
    """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    
    Args:
        table_name: è¡¨å
        
    Returns:
        å¸ƒå°”å€¼ï¼Œè¡¨ç¤ºè¡¨æ˜¯å¦å­˜åœ¨
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_schema = 'public'
        AND table_name = %s
    )
    """
    
    result = execute_query(query, (table_name,))
    return result[0]['exists'] if result else False

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    try:
        # æ£€æŸ¥å¹¶åˆ›å»ºPostGISæ‰©å±•
        check_postgis_sql = """
        SELECT EXISTS (
            SELECT 1 FROM pg_extension WHERE extname = 'postgis'
        )
        """
        result = execute_query(check_postgis_sql)
        has_postgis = result[0]['exists']
        
        if not has_postgis:
            print("PostGISæ‰©å±•ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º...")
            try:
                create_postgis_sql = "CREATE EXTENSION postgis"
                execute_query(create_postgis_sql, fetch=False)
                print("âœ… PostGISæ‰©å±•åˆ›å»ºæˆåŠŸ")
                
                # åˆ›å»ºPostGISæ‹“æ‰‘æ‰©å±•ï¼ˆå¯é€‰ï¼‰
                create_postgis_topology_sql = "CREATE EXTENSION postgis_topology"
                execute_query(create_postgis_topology_sql, fetch=False)
                print("âœ… PostGISæ‹“æ‰‘æ‰©å±•åˆ›å»ºæˆåŠŸ")
                
                # åˆ›å»ºå…¶ä»–æœ‰ç”¨çš„PostGISç›¸å…³æ‰©å±•
                try:
                    # ç”¨äºæ …æ ¼æ•°æ®å¤„ç†
                    execute_query("CREATE EXTENSION postgis_raster", fetch=False)
                    print("âœ… PostGISæ …æ ¼æ‰©å±•åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºPostGISæ …æ ¼æ‰©å±•å¤±è´¥: {str(e)}")
                
                try:
                    # ç”¨äºåœ°å€è§£æå’Œåœ°ç†ç¼–ç 
                    execute_query("CREATE EXTENSION fuzzystrmatch", fetch=False)
                    execute_query("CREATE EXTENSION address_standardizer", fetch=False)
                    execute_query("CREATE EXTENSION address_standardizer_data_us", fetch=False)
                    execute_query("CREATE EXTENSION postgis_tiger_geocoder", fetch=False)
                    print("âœ… PostGISåœ°ç†ç¼–ç æ‰©å±•åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºåœ°ç†ç¼–ç æ‰©å±•å¤±è´¥: {str(e)}")
                    print("éƒ¨åˆ†åœ°ç†ç¼–ç åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
                
                # åˆ›å»ºç©ºé—´ç´¢å¼•æ‰©å±•
                try:
                    execute_query("CREATE EXTENSION btree_gist", fetch=False)
                    print("âœ… GiSTç´¢å¼•æ‰©å±•åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºGiSTç´¢å¼•æ‰©å±•å¤±è´¥: {str(e)}")
            except Exception as e:
                print(f"âš ï¸ åˆ›å»ºPostGISæ‰©å±•å¤±è´¥: {str(e)}")
                print("è¯·ç¡®ä¿PostgreSQLå·²å®‰è£…PostGISï¼Œå¹¶ä¸”å½“å‰ç”¨æˆ·æœ‰åˆ›å»ºæ‰©å±•çš„æƒé™")
        else:
            print("âœ… PostGISæ‰©å±•å·²å­˜åœ¨")
            
            # æ£€æŸ¥PostGISç‰ˆæœ¬
            postgis_version_sql = "SELECT PostGIS_Version()"
            try:
                version_result = execute_query(postgis_version_sql)
                print(f"âœ… å½“å‰PostGISç‰ˆæœ¬: {version_result[0]['postgis_version']}")
            except:
                print("âš ï¸ æ— æ³•è·å–PostGISç‰ˆæœ¬ä¿¡æ¯")
            
            # æ£€æŸ¥å…¶ä»–æ‰©å±•
            check_extensions_sql = """
            SELECT extname FROM pg_extension 
            WHERE extname IN ('postgis_topology', 'postgis_raster', 'fuzzystrmatch', 
                             'address_standardizer', 'postgis_tiger_geocoder', 'btree_gist')
            """
            try:
                extensions_result = execute_query(check_extensions_sql)
                installed_extensions = [ext['extname'] for ext in extensions_result]
                print(f"âœ… å·²å®‰è£…çš„æ‰©å±•: {', '.join(installed_extensions)}")
                
                # æ£€æŸ¥ç¼ºå¤±çš„æ‰©å±•
                all_extensions = ['postgis_topology', 'postgis_raster', 'fuzzystrmatch', 
                                 'address_standardizer', 'postgis_tiger_geocoder', 'btree_gist']
                missing_extensions = [ext for ext in all_extensions if ext not in installed_extensions]
                
                if missing_extensions:
                    print(f"âš ï¸ ç¼ºå°‘çš„æ‰©å±•: {', '.join(missing_extensions)}")
                    print("éƒ¨åˆ†ç©ºé—´æ•°æ®åŠŸèƒ½å¯èƒ½å—é™")
            except:
                print("âš ï¸ æ— æ³•æ£€æŸ¥å·²å®‰è£…æ‰©å±•")
        
        # åˆ›å»ºç”¨æˆ·è¡¨
        create_users_table = """
        CREATE TABLE IF NOT EXISTS users (
            id BIGINT PRIMARY KEY,
            username VARCHAR(50) UNIQUE NOT NULL,
            password VARCHAR(100) NOT NULL,
            email VARCHAR(100) UNIQUE NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        execute_query(create_users_table, fetch=False)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·
        check_admin_user = "SELECT COUNT(*) FROM users WHERE username = 'admin'"
        admin_count = execute_query(check_admin_user)[0]['count']
        
        if admin_count == 0:
            # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·ï¼Œä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            import hashlib
            from utils.snowflake import get_snowflake_id
            
            # ç”Ÿæˆå¯†ç å“ˆå¸Œ
            default_password = "admin123"
            password_hash = hashlib.sha256(default_password.encode()).hexdigest()
            
            # ä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            admin_id = get_snowflake_id()
            
            # æ’å…¥ç®¡ç†å‘˜ç”¨æˆ·
            insert_admin_sql = """
            INSERT INTO users (id, username, password, email    ) 
            VALUES (%s, %s, %s, %s)
            """
            execute_query(insert_admin_sql, (admin_id, "admin", password_hash, "admin@example.com"), fetch=False)
            print("âœ… å·²åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ· (ç”¨æˆ·å: admin, å¯†ç : admin123)")
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºé»˜è®¤æ™®é€šç”¨æˆ·
        check_user_user = "SELECT COUNT(*) FROM users WHERE username = 'user'"
        user_count = execute_query(check_user_user)[0]['count']
        
        if user_count == 0:
            # åˆ›å»ºé»˜è®¤æ™®é€šç”¨æˆ·ï¼Œä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            import hashlib
            from utils.snowflake import get_snowflake_id
            
            # ç”Ÿæˆå¯†ç å“ˆå¸Œ
            default_password = "user123"
            password_hash = hashlib.sha256(default_password.encode()).hexdigest()
            
            # ä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆID
            user_id = get_snowflake_id()
            
            # æ’å…¥ç®¡ç†å‘˜ç”¨æˆ·
            insert_user_sql = """
            INSERT INTO users (id, username, password, email    ) 
            VALUES (%s, %s, %s, %s)
            """
            execute_query(insert_user_sql, (user_id, "user", password_hash, "user@example.com"), fetch=False)
            print("âœ… å·²åˆ›å»ºé»˜è®¤æ™®é€šç”¨æˆ· (ç”¨æˆ·å: user, å¯†ç : user123)")
        # åˆ›å»ºæ–‡ä»¶è¡¨ - æ›´æ–°ä»¥åŒ¹é…æ–°çš„æ•°æ®åº“ç»“æ„
        create_files_table = """
        CREATE TABLE IF NOT EXISTS files (
            id BIGINT PRIMARY KEY,
            file_name VARCHAR(100) NOT NULL,
            file_path VARCHAR(200) NOT NULL,
            original_name VARCHAR(100) NOT NULL,
            file_size BIGINT NOT NULL,
            is_public BOOLEAN DEFAULT TRUE,
            discipline VARCHAR(50) NOT NULL,
            dimension VARCHAR(10) NOT NULL,
            file_type VARCHAR(20) NOT NULL,
            coordinate_system VARCHAR(20),
            tags VARCHAR(200),
            description TEXT,
            user_id BIGINT REFERENCES users(id),
            upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            status VARCHAR(20) DEFAULT 'uploaded',
            bbox JSONB,
            geometry_type VARCHAR(50),
            feature_count INTEGER,
            metadata JSONB
        )
        """
        
        # åˆ›å»ºGeoServerå·¥ä½œç©ºé—´è¡¨
        create_geoserver_workspaces_table = """
        CREATE TABLE IF NOT EXISTS geoserver_workspaces (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) UNIQUE NOT NULL,
            namespace_uri VARCHAR(255),
            namespace_prefix VARCHAR(100),
            description TEXT,
            is_default BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºGeoServerå­˜å‚¨ä»“åº“è¡¨
        create_geoserver_stores_table = """
        CREATE TABLE IF NOT EXISTS geoserver_stores (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            store_type VARCHAR(50) NOT NULL,
            data_type VARCHAR(50),
            connection_params JSONB,
            description TEXT,
            enabled BOOLEAN DEFAULT TRUE,
            file_id BIGINT REFERENCES files(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(workspace_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerè¦ç´ ç±»å‹è¡¨
        create_geoserver_featuretypes_table = """
        CREATE TABLE IF NOT EXISTS geoserver_featuretypes (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100),
            native_name VARCHAR(100),
            store_id BIGINT REFERENCES geoserver_stores(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            keywords TEXT[],
            srs VARCHAR(50),
            projection_policy VARCHAR(50) DEFAULT 'REPROJECT_TO_DECLARED',
            native_bbox JSONB,
            lat_lon_bbox JSONB,
            attributes JSONB,
            enabled BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(store_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerè¦†ç›–èŒƒå›´è¡¨
        create_geoserver_coverages_table = """
        CREATE TABLE IF NOT EXISTS geoserver_coverages (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            native_name VARCHAR(100),
            store_id BIGINT REFERENCES geoserver_stores(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            keywords TEXT[],
            srs VARCHAR(50) DEFAULT 'EPSG:4326',
            native_srs VARCHAR(50),
            native_bbox JSONB,
            lat_lon_bbox JSONB,
            grid_info JSONB,
            bands_info JSONB,
            enabled BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(store_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerå›¾å±‚è¡¨ - æ›´æ–°ä»¥æ”¯æŒçŸ¢é‡å’Œæ …æ ¼æ•°æ®
        create_geoserver_layers_table = """
        CREATE TABLE IF NOT EXISTS geoserver_layers (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            featuretype_id BIGINT REFERENCES geoserver_featuretypes(id) ON DELETE CASCADE,
            coverage_id BIGINT REFERENCES geoserver_coverages(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            default_style VARCHAR(100),
            additional_styles TEXT[],
            enabled BOOLEAN DEFAULT TRUE,
            queryable BOOLEAN DEFAULT TRUE,
            opaque BOOLEAN DEFAULT FALSE,
            attribution TEXT,
            wms_url TEXT,
            wfs_url TEXT,
            wcs_url TEXT,
            file_id BIGINT REFERENCES files(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            style_config JSONB,
            UNIQUE(workspace_id, name),
            CONSTRAINT check_data_source CHECK (
                (featuretype_id IS NOT NULL AND coverage_id IS NULL) OR 
                (featuretype_id IS NULL AND coverage_id IS NOT NULL)
            )
        )
        """
        
        # åˆ›å»ºGeoServeræ ·å¼è¡¨
        create_geoserver_styles_table = """
        CREATE TABLE IF NOT EXISTS geoserver_styles (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            filename VARCHAR(255),
            format VARCHAR(50) DEFAULT 'sld',
            language_version VARCHAR(20),
            content TEXT,
            description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(workspace_id, name)
        )
        """
        
        # åˆ›å»ºGeoServerå›¾å±‚ç»„è¡¨
        create_geoserver_layergroups_table = """
        CREATE TABLE IF NOT EXISTS geoserver_layergroups (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            workspace_id BIGINT REFERENCES geoserver_workspaces(id) ON DELETE CASCADE,
            title VARCHAR(255),
            abstract TEXT,
            mode VARCHAR(50) DEFAULT 'SINGLE',
            layers JSONB,
            bounds JSONB,
            enabled BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(workspace_id, name)
        )
        """
        
        # åˆ›å»ºåœºæ™¯è¡¨ - æ›´æ–°ä»¥åŒ¹é…æ–°çš„æ•°æ®åº“ç»“æ„
        create_scenes_table = """
        CREATE TABLE IF NOT EXISTS scenes (
            id BIGINT PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            description TEXT,
            is_public BOOLEAN DEFAULT TRUE,
            user_id BIGINT REFERENCES users(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºåœºæ™¯å›¾å±‚è¡¨ - æ›´æ–°ä»¥åŒ¹é…æ–°çš„æ•°æ®åº“ç»“æ„
        create_scene_layers_table = """
        CREATE TABLE IF NOT EXISTS scene_layers (
            id BIGINT PRIMARY KEY,
            scene_id BIGINT NOT NULL REFERENCES scenes(id) ON DELETE CASCADE,
            layer_id BIGINT NOT NULL,
            martin_service_id BIGINT,
            martin_service_type VARCHAR(20) DEFAULT NULL,
            layer_type VARCHAR(20) DEFAULT 'geoserver',
            layer_order INTEGER DEFAULT 0,
            visible BOOLEAN DEFAULT true,
            opacity NUMERIC(3,2) DEFAULT 1.0,
            style_name VARCHAR(100),
            custom_style JSONB,
            queryable BOOLEAN DEFAULT true,
            selectable BOOLEAN DEFAULT true,
            service_reference VARCHAR(100),
            service_url TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            boundingbox JSONB,
            CONSTRAINT chk_layer_type CHECK (layer_type IN ('geoserver', 'martin'))
        )
        """
        
        # åˆ›å»ºç»Ÿä¸€çš„çŸ¢é‡MartinæœåŠ¡è¡¨ï¼ˆåˆå¹¶geojsonå’ŒshpæœåŠ¡ï¼‰
        create_vector_martin_services_table = """
        CREATE TABLE IF NOT EXISTS vector_martin_services (
            id BIGINT PRIMARY KEY,
            file_id VARCHAR(36) NOT NULL UNIQUE,
            original_filename VARCHAR(255) NOT NULL,
            file_path TEXT NOT NULL,
            vector_type VARCHAR(40) NOT NULL, -- 'geojson' æˆ– 'shp'
            table_name VARCHAR(100) NOT NULL,
            service_url TEXT,
            mvt_url TEXT,
            tilejson_url TEXT,
            style JSONB,
            vector_info JSONB,  -- å­˜å‚¨åŸå§‹çŸ¢é‡æ–‡ä»¶ä¿¡æ¯
            postgis_info JSONB,
            status VARCHAR(20) DEFAULT 'active',
            user_id BIGINT REFERENCES users(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºGeoJSONæ–‡ä»¶è¡¨ï¼ˆç”¨äºGeoJSONç›´æ¥æœåŠ¡ï¼‰
        create_geojson_files_table = """
        CREATE TABLE IF NOT EXISTS geojson_files (
            id BIGINT PRIMARY KEY,
            file_id VARCHAR(36) NOT NULL UNIQUE,
            original_filename VARCHAR(255) NOT NULL,
            file_path TEXT NOT NULL,
            stored_path TEXT,
            file_size BIGINT NOT NULL,
            feature_count INTEGER DEFAULT 0,
            geometry_types JSONB,
            property_fields JSONB,
            bbox JSONB,
            upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            status VARCHAR(20) DEFAULT 'active',
            user_id BIGINT REFERENCES users(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # ===== ç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿè¡¨ =====
        # åˆ›å»ºç”¨æˆ·æœåŠ¡é…ç½®è¡¨
        create_user_service_configs_table = """
        CREATE TABLE IF NOT EXISTS user_service_configs (
            id BIGINT PRIMARY KEY,
            user_id BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
            service_name VARCHAR(100) NOT NULL,
            service_type VARCHAR(20) NOT NULL CHECK (service_type IN ('geoserver', 'martin')),
            service_status VARCHAR(20) DEFAULT 'stopped' CHECK (service_status IN ('running', 'stopped', 'error', 'starting', 'stopping')),
            config_data JSONB NOT NULL,
            port_number INTEGER,
            resource_quota JSONB,
            description TEXT,
            is_default BOOLEAN DEFAULT FALSE,
            auto_start BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_started_at TIMESTAMP,
            last_stopped_at TIMESTAMP,
            UNIQUE(user_id, service_name, service_type)
        )
        """
        
        # åˆ›å»ºæœåŠ¡è¿è¡Œæ—¥å¿—è¡¨
        create_service_logs_table = """
        CREATE TABLE IF NOT EXISTS service_logs (
            id BIGINT PRIMARY KEY,
            service_config_id BIGINT NOT NULL REFERENCES user_service_configs(id) ON DELETE CASCADE,
            user_id BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
            operation_type VARCHAR(50) NOT NULL,
            operation_status VARCHAR(20) NOT NULL CHECK (operation_status IN ('success', 'failed', 'pending')),
            log_message TEXT,
            error_details JSONB,
            execution_time_ms INTEGER,
            ip_address VARCHAR(45),
            user_agent TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºç³»ç»Ÿèµ„æºé…é¢è¡¨
        create_system_resource_quotas_table = """
        CREATE TABLE IF NOT EXISTS system_resource_quotas (
            id BIGINT PRIMARY KEY,
            user_id BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
            max_geoserver_services INTEGER DEFAULT 3 CHECK (max_geoserver_services >= 0),
            max_martin_services INTEGER DEFAULT 5 CHECK (max_martin_services >= 0),
            max_memory_mb INTEGER DEFAULT 2048 CHECK (max_memory_mb > 0),
            max_storage_mb INTEGER DEFAULT 10240 CHECK (max_storage_mb > 0),
            concurrent_requests INTEGER DEFAULT 100 CHECK (concurrent_requests > 0),
            quota_type VARCHAR(20) DEFAULT 'standard' CHECK (quota_type IN ('basic', 'standard', 'premium')),
            effective_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            expiry_date TIMESTAMP,
            is_active BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(user_id, is_active, effective_date)
        )
        """
        
        # åˆ›å»ºæœåŠ¡ç«¯å£åˆ†é…è¡¨
        create_service_port_allocations_table = """
        CREATE TABLE IF NOT EXISTS service_port_allocations (
            id BIGINT PRIMARY KEY,
            port_number INTEGER NOT NULL UNIQUE CHECK (port_number BETWEEN 1024 AND 65535),
            user_id BIGINT REFERENCES users(id) ON DELETE SET NULL,
            service_config_id BIGINT REFERENCES user_service_configs(id) ON DELETE SET NULL,
            allocation_status VARCHAR(20) DEFAULT 'allocated' CHECK (allocation_status IN ('allocated', 'released', 'reserved')),
            allocated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            released_at TIMESTAMP,
            notes TEXT
        )
        """
        
        # ===== ç”¨æˆ·åé¦ˆç³»ç»Ÿè¡¨ =====
        # åˆ›å»ºåé¦ˆè¡¨
        create_feedback_items_table = """
        CREATE TABLE IF NOT EXISTS feedback_items (
            id BIGINT PRIMARY KEY,
            title VARCHAR(200) NOT NULL,
            description TEXT,
            category VARCHAR(50) NOT NULL, -- 'feature' æˆ– 'bug'
            module VARCHAR(50) NOT NULL,   -- 'frontend' æˆ– 'backend'
            type VARCHAR(50) NOT NULL,     -- 'ui' æˆ– 'code'
            priority VARCHAR(20) DEFAULT 'medium', -- 'low', 'medium', 'high', 'urgent'
            status VARCHAR(20) DEFAULT 'open',     -- 'open', 'in_progress', 'resolved', 'closed'
            
            -- ç”¨æˆ·ä¿¡æ¯ï¼ˆå¯ä»¥æ ¹æ®å®é™…ç³»ç»Ÿè°ƒæ•´ï¼‰
            user_id VARCHAR(100),          -- æ”¯æŒå­—ç¬¦ä¸²IDï¼Œå…¼å®¹é›ªèŠ±ç®—æ³•
            username VARCHAR(100),
            user_email VARCHAR(200),
            
            -- ç»Ÿè®¡ä¿¡æ¯
            support_count INTEGER DEFAULT 0,
            oppose_count INTEGER DEFAULT 0,
            comment_count INTEGER DEFAULT 0,
            view_count INTEGER DEFAULT 0,
            
            -- é™„ä»¶ä¿¡æ¯
            has_attachments BOOLEAN DEFAULT FALSE,
            
            -- æ—¶é—´æˆ³
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        
        # åˆ›å»ºåé¦ˆé™„ä»¶è¡¨
        create_feedback_attachments_table = """
        CREATE TABLE IF NOT EXISTS feedback_attachments (
            id BIGINT PRIMARY KEY,
            feedback_id BIGINT NOT NULL,
            filename VARCHAR(255) NOT NULL,
            original_name VARCHAR(255) NOT NULL,
            file_type VARCHAR(50),          -- 'image', 'document', 'archive'
            file_size BIGINT,
            file_path VARCHAR(500),
            mime_type VARCHAR(100),
            
            -- å›¾ç‰‡ç‰¹æ®Šä¿¡æ¯
            is_screenshot BOOLEAN DEFAULT FALSE,
            image_width INTEGER,
            image_height INTEGER,
            
            uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            
            FOREIGN KEY (feedback_id) REFERENCES feedback_items(id) ON DELETE CASCADE
        )
        """
        
        # åˆ›å»ºç”¨æˆ·æŠ•ç¥¨è¡¨
        create_feedback_votes_table = """
        CREATE TABLE IF NOT EXISTS feedback_votes (
            id BIGINT PRIMARY KEY,
            feedback_id BIGINT NOT NULL,
            user_id VARCHAR(100) NOT NULL,
            username VARCHAR(100),
            vote_type VARCHAR(10) NOT NULL,  -- 'support' æˆ– 'oppose'
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            
            FOREIGN KEY (feedback_id) REFERENCES feedback_items(id) ON DELETE CASCADE,
            UNIQUE (feedback_id, user_id)
        )
        """
        
        # åˆ›å»ºè¯„è®ºè¡¨
        create_feedback_comments_table = """
        CREATE TABLE IF NOT EXISTS feedback_comments (
            id BIGINT PRIMARY KEY,
            feedback_id BIGINT NOT NULL,
            parent_id BIGINT,               -- æ”¯æŒå›å¤è¯„è®º
            
            content TEXT NOT NULL,
            
            -- ç”¨æˆ·ä¿¡æ¯
            user_id VARCHAR(100) NOT NULL,
            username VARCHAR(100),
            user_email VARCHAR(200),
            
            -- çŠ¶æ€
            is_deleted BOOLEAN DEFAULT FALSE,
            
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            
            FOREIGN KEY (feedback_id) REFERENCES feedback_items(id) ON DELETE CASCADE,
            FOREIGN KEY (parent_id) REFERENCES feedback_comments(id) ON DELETE CASCADE
        )
        """
        
        # åˆ›å»ºçŸ¢é‡MartinæœåŠ¡è¡¨çš„ç´¢å¼•
        create_vector_martin_services_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_file_id ON vector_martin_services(file_id)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_table_name ON vector_martin_services(table_name)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_vector_type ON vector_martin_services(vector_type)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_status ON vector_martin_services(status)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_user_id ON vector_martin_services(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_vector_martin_services_service_url ON vector_martin_services(service_url)"
        ]
        
        # åˆ›å»ºGeoJSONæ–‡ä»¶è¡¨çš„ç´¢å¼•
        create_geojson_files_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_file_id ON geojson_files(file_id)",
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_status ON geojson_files(status)",
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_user_id ON geojson_files(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_geojson_files_upload_date ON geojson_files(upload_date)"
        ]
        
        # åˆ›å»ºåé¦ˆç³»ç»Ÿçš„ç´¢å¼•
        create_feedback_items_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_category ON feedback_items(category)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_module ON feedback_items(module)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_type ON feedback_items(type)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_status ON feedback_items(status)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_user_id ON feedback_items(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_created_at ON feedback_items(created_at)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_support_count ON feedback_items(support_count)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_oppose_count ON feedback_items(oppose_count)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_items_comment_count ON feedback_items(comment_count)"
        ]
        
        create_feedback_attachments_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_feedback_attachments_feedback_id ON feedback_attachments(feedback_id)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_attachments_file_type ON feedback_attachments(file_type)"
        ]
        
        create_feedback_votes_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_feedback_votes_feedback_id ON feedback_votes(feedback_id)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_votes_user_id ON feedback_votes(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_votes_vote_type ON feedback_votes(vote_type)"
        ]
        
        create_feedback_comments_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_feedback_comments_feedback_id ON feedback_comments(feedback_id)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_comments_parent_id ON feedback_comments(parent_id)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_comments_user_id ON feedback_comments(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_feedback_comments_created_at ON feedback_comments(created_at)"
        ]
        
        # åˆ›å»ºåœºæ™¯å›¾å±‚è¡¨çš„ç´¢å¼•
        create_scene_layers_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_scene_id ON scene_layers(scene_id)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_layer_id ON scene_layers(layer_id)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_martin_service_id ON scene_layers(martin_service_id)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_layer_order ON scene_layers(layer_order)",
            "CREATE INDEX IF NOT EXISTS idx_scene_layers_order ON scene_layers(scene_id, layer_order)"
        ]
        
        # åˆ›å»ºå…¶ä»–è¡¨çš„ç´¢å¼•ï¼ˆä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼‰
        create_users_indexes = []
        create_files_indexes = []
        create_geoserver_workspaces_indexes = []
        create_geoserver_stores_indexes = []
        create_geoserver_featuretypes_indexes = []
        create_geoserver_coverages_indexes = []
        create_geoserver_layers_indexes = []
        create_geoserver_styles_indexes = []
        create_geoserver_layergroups_indexes = []
        create_scenes_indexes = []
        
        # ç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿç´¢å¼•
        create_user_service_configs_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_user_service_configs_user_id ON user_service_configs(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_user_service_configs_type_status ON user_service_configs(service_type, service_status)",
            "CREATE INDEX IF NOT EXISTS idx_user_service_configs_port ON user_service_configs(port_number)",
            "CREATE INDEX IF NOT EXISTS idx_user_service_configs_created_at ON user_service_configs(created_at)",
            "CREATE INDEX IF NOT EXISTS idx_user_service_configs_default ON user_service_configs(user_id, is_default) WHERE is_default = TRUE"
        ]
        
        create_service_logs_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_service_logs_service_config_id ON service_logs(service_config_id)",
            "CREATE INDEX IF NOT EXISTS idx_service_logs_user_id ON service_logs(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_service_logs_created_at ON service_logs(created_at)",
            "CREATE INDEX IF NOT EXISTS idx_service_logs_operation_type ON service_logs(operation_type)",
            "CREATE INDEX IF NOT EXISTS idx_service_logs_status ON service_logs(operation_status)",
            "CREATE INDEX IF NOT EXISTS idx_service_logs_recent ON service_logs(user_id, created_at DESC)"
        ]
        
        create_system_resource_quotas_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_system_resource_quotas_user_id ON system_resource_quotas(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_system_resource_quotas_active ON system_resource_quotas(is_active)",
            "CREATE INDEX IF NOT EXISTS idx_system_resource_quotas_effective ON system_resource_quotas(effective_date, expiry_date)"
        ]
        
        create_service_port_allocations_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_service_port_allocations_status ON service_port_allocations(allocation_status)",
            "CREATE INDEX IF NOT EXISTS idx_service_port_allocations_user_id ON service_port_allocations(user_id)"
        ]
        
        # æ‰§è¡Œæ‰€æœ‰åˆ›å»ºè¡¨çš„SQL
        tables = [
            create_users_table,
            create_files_table,
            create_geoserver_workspaces_table,
            create_geoserver_stores_table,
            create_geoserver_featuretypes_table,
            create_geoserver_coverages_table,
            create_geoserver_layers_table,
            create_geoserver_styles_table,
            create_geoserver_layergroups_table,
            create_scenes_table,
            create_scene_layers_table,
            create_vector_martin_services_table,
            create_geojson_files_table,
            # ç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿè¡¨
            create_user_service_configs_table,
            create_service_logs_table,
            create_system_resource_quotas_table,
            create_service_port_allocations_table,
            # åé¦ˆç³»ç»Ÿè¡¨
            create_feedback_items_table,
            create_feedback_attachments_table,
            create_feedback_votes_table,
            create_feedback_comments_table
        ]
        
        for table_sql in tables:
            execute_query(table_sql, fetch=False)
        
        # åˆ›å»ºæ‰€æœ‰ç´¢å¼•
        all_indexes = (
            create_users_indexes +
            create_files_indexes +
            create_geoserver_workspaces_indexes +
            create_geoserver_stores_indexes +
            create_geoserver_featuretypes_indexes +
            create_geoserver_coverages_indexes +
            create_geoserver_layers_indexes +
            create_geoserver_styles_indexes +
            create_geoserver_layergroups_indexes +
            create_scenes_indexes +
            create_vector_martin_services_indexes +
            create_scene_layers_indexes +
            create_geojson_files_indexes +
            # ç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿç´¢å¼•
            create_user_service_configs_indexes +
            create_service_logs_indexes +
            create_system_resource_quotas_indexes +
            create_service_port_allocations_indexes +
            # åé¦ˆç³»ç»Ÿç´¢å¼•
            create_feedback_items_indexes +
            create_feedback_attachments_indexes +
            create_feedback_votes_indexes +
            create_feedback_comments_indexes
        )
        
        for index_sql in all_indexes:
            execute_query(index_sql, fetch=False)
        
        # åˆ›å»ºåé¦ˆç³»ç»Ÿçš„è§¦å‘å™¨å‡½æ•°
        try:
            # è§¦å‘å™¨å‡½æ•°ï¼šæ›´æ–°æŠ•ç¥¨ç»Ÿè®¡
            create_update_vote_counts_function = """
            CREATE OR REPLACE FUNCTION update_vote_counts() RETURNS TRIGGER AS $$
            BEGIN
                UPDATE feedback_items 
                SET 
                    support_count = (SELECT COUNT(*) FROM feedback_votes WHERE feedback_id = COALESCE(NEW.feedback_id, OLD.feedback_id) AND vote_type = 'support'),
                    oppose_count = (SELECT COUNT(*) FROM feedback_votes WHERE feedback_id = COALESCE(NEW.feedback_id, OLD.feedback_id) AND vote_type = 'oppose'),
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = COALESCE(NEW.feedback_id, OLD.feedback_id);
                RETURN COALESCE(NEW, OLD);
            END;
            $$ LANGUAGE plpgsql;
            """
            execute_query(create_update_vote_counts_function, fetch=False)
            
            # è§¦å‘å™¨å‡½æ•°ï¼šæ›´æ–°è¯„è®ºç»Ÿè®¡
            create_update_comment_count_function = """
            CREATE OR REPLACE FUNCTION update_comment_count() RETURNS TRIGGER AS $$
            BEGIN
                UPDATE feedback_items 
                SET 
                    comment_count = (SELECT COUNT(*) FROM feedback_comments WHERE feedback_id = COALESCE(NEW.feedback_id, OLD.feedback_id) AND is_deleted = FALSE),
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = COALESCE(NEW.feedback_id, OLD.feedback_id);
                RETURN COALESCE(NEW, OLD);
            END;
            $$ LANGUAGE plpgsql;
            """
            execute_query(create_update_comment_count_function, fetch=False)
            
            # è§¦å‘å™¨å‡½æ•°ï¼šæ›´æ–°é™„ä»¶æ ‡è®°
            create_update_attachments_flag_function = """
            CREATE OR REPLACE FUNCTION update_attachments_flag() RETURNS TRIGGER AS $$
            BEGIN
                UPDATE feedback_items 
                SET 
                    has_attachments = (SELECT COUNT(*) > 0 FROM feedback_attachments WHERE feedback_id = COALESCE(NEW.feedback_id, OLD.feedback_id)),
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = COALESCE(NEW.feedback_id, OLD.feedback_id);
                RETURN COALESCE(NEW, OLD);
            END;
            $$ LANGUAGE plpgsql;
            """
            execute_query(create_update_attachments_flag_function, fetch=False)
            
            # åˆ›å»ºè§¦å‘å™¨
            feedback_triggers = [
                # æŠ•ç¥¨ç»Ÿè®¡è§¦å‘å™¨
                "DROP TRIGGER IF EXISTS trigger_update_vote_counts_insert ON feedback_votes",
                "CREATE TRIGGER trigger_update_vote_counts_insert AFTER INSERT ON feedback_votes FOR EACH ROW EXECUTE FUNCTION update_vote_counts()",
                "DROP TRIGGER IF EXISTS trigger_update_vote_counts_update ON feedback_votes",
                "CREATE TRIGGER trigger_update_vote_counts_update AFTER UPDATE ON feedback_votes FOR EACH ROW EXECUTE FUNCTION update_vote_counts()",
                "DROP TRIGGER IF EXISTS trigger_update_vote_counts_delete ON feedback_votes",
                "CREATE TRIGGER trigger_update_vote_counts_delete AFTER DELETE ON feedback_votes FOR EACH ROW EXECUTE FUNCTION update_vote_counts()",
                
                # è¯„è®ºç»Ÿè®¡è§¦å‘å™¨
                "DROP TRIGGER IF EXISTS trigger_update_comment_count_insert ON feedback_comments",
                "CREATE TRIGGER trigger_update_comment_count_insert AFTER INSERT ON feedback_comments FOR EACH ROW EXECUTE FUNCTION update_comment_count()",
                "DROP TRIGGER IF EXISTS trigger_update_comment_count_update ON feedback_comments",
                "CREATE TRIGGER trigger_update_comment_count_update AFTER UPDATE ON feedback_comments FOR EACH ROW EXECUTE FUNCTION update_comment_count()",
                "DROP TRIGGER IF EXISTS trigger_update_comment_count_delete ON feedback_comments",
                "CREATE TRIGGER trigger_update_comment_count_delete AFTER DELETE ON feedback_comments FOR EACH ROW EXECUTE FUNCTION update_comment_count()",
                
                # é™„ä»¶ç»Ÿè®¡è§¦å‘å™¨
                "DROP TRIGGER IF EXISTS trigger_update_attachments_flag_insert ON feedback_attachments",
                "CREATE TRIGGER trigger_update_attachments_flag_insert AFTER INSERT ON feedback_attachments FOR EACH ROW EXECUTE FUNCTION update_attachments_flag()",
                "DROP TRIGGER IF EXISTS trigger_update_attachments_flag_delete ON feedback_attachments",
                "CREATE TRIGGER trigger_update_attachments_flag_delete AFTER DELETE ON feedback_attachments FOR EACH ROW EXECUTE FUNCTION update_attachments_flag()"
            ]
            
            for trigger_sql in feedback_triggers:
                execute_query(trigger_sql, fetch=False)
            
            print("âœ… åé¦ˆç³»ç»Ÿè§¦å‘å™¨åˆ›å»ºæˆåŠŸ")
            
        except Exception as e:
            print(f"âš ï¸ åé¦ˆç³»ç»Ÿè§¦å‘å™¨åˆ›å»ºå¤±è´¥: {str(e)}")
        
        print("æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        
      
        
        
        # ç¡®ä¿GeoServerå·¥ä½œç©ºé—´å­˜åœ¨
        try:
            from config import GEOSERVER_CONFIG
            workspace_name = GEOSERVER_CONFIG.get('workspace', 'shpservice')
            
            # æ£€æŸ¥geoserver_workspacesè¡¨ä¸­æ˜¯å¦å·²å­˜åœ¨è¯¥å·¥ä½œç©ºé—´
            workspace_check_sql = """
            SELECT id FROM geoserver_workspaces WHERE name = %s
            """
            workspace_result = execute_query(workspace_check_sql, (workspace_name,))
            
            if not workspace_result:
                print(f"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºGeoServerå·¥ä½œç©ºé—´è®°å½•: {workspace_name}")
                # åœ¨æ•°æ®åº“ä¸­åˆ›å»ºå·¥ä½œç©ºé—´è®°å½•
                insert_workspace_sql = """
                INSERT INTO geoserver_workspaces 
                (id,name, namespace_uri, namespace_prefix, description, is_default, created_at, updated_at)
                VALUES (%s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                RETURNING id
                """
                # ç”Ÿæˆé›ªèŠ±ç®—æ³•ID
                from utils.snowflake import get_snowflake_id
                id=get_snowflake_id()
                result = execute_query(insert_workspace_sql, (
                    id,
                    workspace_name,
                    f"http://{workspace_name}",
                    workspace_name,
                    f"Default workspace for {workspace_name}",
                    True
                ))
                
                workspace_id = result[0]['id']
                print(f"âœ… æ•°æ®åº“ä¸­GeoServerå·¥ä½œç©ºé—´è®°å½•åˆ›å»ºæˆåŠŸï¼ŒID: {workspace_id}")
                
                # å°è¯•åœ¨GeoServerä¸­åˆ›å»ºå·¥ä½œç©ºé—´
                try:
                    # å¯¼å…¥GeoServerServiceå¹¶åˆ›å»ºå·¥ä½œç©ºé—´
                    from services.geoserver_service import GeoServerService
                    geoserver = GeoServerService()
                    geoserver._create_workspace_in_geoserver()
                    print(f"âœ… GeoServerä¸­å·¥ä½œç©ºé—´ {workspace_name} åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ GeoServerä¸­åˆ›å»ºå·¥ä½œç©ºé—´å¤±è´¥: {str(e)}")
                    print("è¯·ç¡®ä¿GeoServeræœåŠ¡æ­£åœ¨è¿è¡Œï¼Œå¹¶æ£€æŸ¥è¿æ¥é…ç½®")
            else:
                print(f"âœ… æ•°æ®åº“ä¸­GeoServerå·¥ä½œç©ºé—´ {workspace_name} å·²å­˜åœ¨ï¼ŒID: {workspace_result[0]['id']}")
                
                # æ£€æŸ¥GeoServerä¸­æ˜¯å¦å­˜åœ¨è¯¥å·¥ä½œç©ºé—´
                try:
                    from services.geoserver_service import GeoServerService
                    geoserver = GeoServerService()
                    # æ£€æŸ¥å·¥ä½œç©ºé—´
                    geoserver._ensure_workspace_exists()
                    print(f"âœ… GeoServerä¸­å·¥ä½œç©ºé—´ {workspace_name} å·²å­˜åœ¨")
                except Exception as e:
                    print(f"âš ï¸ GeoServerå·¥ä½œç©ºé—´æ£€æŸ¥å¤±è´¥: {str(e)}")
        except Exception as e:
            print(f"âš ï¸ GeoServerå·¥ä½œç©ºé—´åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        
        # åˆå§‹åŒ–ç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿ
        try:
            # åˆ›å»ºç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿçš„å‡½æ•°
            # æ›´æ–°æ—¶é—´æˆ³è§¦å‘å™¨å‡½æ•°
            update_timestamp_function_sql = """
            CREATE OR REPLACE FUNCTION update_updated_at_column()
            RETURNS TRIGGER AS $$
            BEGIN
                NEW.updated_at = CURRENT_TIMESTAMP;
                RETURN NEW;
            END;
            $$ LANGUAGE plpgsql;
            """
            
            # ç«¯å£åˆ†é…å‡½æ•°
            allocate_port_function_sql = """
            CREATE OR REPLACE FUNCTION allocate_available_port(p_user_id BIGINT, p_service_config_id BIGINT)
            RETURNS INTEGER AS $$
            DECLARE
                available_port INTEGER;
            BEGIN
                -- æŸ¥æ‰¾æœ€å°çš„å¯ç”¨ç«¯å£ï¼ˆä»8081å¼€å§‹ï¼‰
                SELECT port_number INTO available_port
                FROM generate_series(8081, 65535) AS port_number
                WHERE port_number NOT IN (
                    SELECT port_number 
                    FROM service_port_allocations 
                    WHERE allocation_status IN ('allocated', 'reserved')
                    AND port_number IS NOT NULL
                )
                ORDER BY port_number
                LIMIT 1;
                
                IF available_port IS NULL THEN
                    RAISE EXCEPTION 'æ²¡æœ‰å¯ç”¨çš„ç«¯å£';
                END IF;
                
                -- åˆ†é…ç«¯å£
                INSERT INTO service_port_allocations (
                    id, port_number, user_id, service_config_id, allocation_status
                ) VALUES (
                    available_port, available_port, p_user_id, p_service_config_id, 'allocated'
                );
                
                RETURN available_port;
            END;
            $$ LANGUAGE plpgsql;
            """
            
            # é‡Šæ”¾ç«¯å£å‡½æ•°
            release_port_function_sql = """
            CREATE OR REPLACE FUNCTION release_port(p_port_number INTEGER)
            RETURNS BOOLEAN AS $$
            BEGIN
                UPDATE service_port_allocations 
                SET allocation_status = 'released',
                    released_at = CURRENT_TIMESTAMP,
                    user_id = NULL,
                    service_config_id = NULL
                WHERE port_number = p_port_number 
                AND allocation_status = 'allocated';
                
                RETURN FOUND;
            END;
            $$ LANGUAGE plpgsql;
            """
            
            execute_query(update_timestamp_function_sql, fetch=False)
            execute_query(allocate_port_function_sql, fetch=False)
            execute_query(release_port_function_sql, fetch=False)
            
            # åˆ›å»ºè§¦å‘å™¨
            create_service_triggers_sql = """
            DO $$
            BEGIN
                -- ä¸ºç”¨æˆ·æœåŠ¡é…ç½®è¡¨åˆ›å»ºæ›´æ–°æ—¶é—´æˆ³è§¦å‘å™¨
                IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'user_service_configs') THEN
                    DROP TRIGGER IF EXISTS update_user_service_configs_updated_at ON user_service_configs;
                    CREATE TRIGGER update_user_service_configs_updated_at 
                        BEFORE UPDATE ON user_service_configs 
                        FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
                END IF;
                
                -- ä¸ºèµ„æºé…é¢è¡¨åˆ›å»ºæ›´æ–°æ—¶é—´æˆ³è§¦å‘å™¨
                IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'system_resource_quotas') THEN
                    DROP TRIGGER IF EXISTS update_system_resource_quotas_updated_at ON system_resource_quotas;
                    CREATE TRIGGER update_system_resource_quotas_updated_at 
                        BEFORE UPDATE ON system_resource_quotas 
                        FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
                END IF;
            END $$;
            """
            
            execute_query(create_service_triggers_sql, fetch=False)
            
            # ä¸ºç°æœ‰ç”¨æˆ·åˆ›å»ºé»˜è®¤èµ„æºé…é¢
            init_quotas_sql = """
            INSERT INTO system_resource_quotas (
                id,
                user_id, 
                max_geoserver_services, 
                max_martin_services, 
                max_memory_mb, 
                max_storage_mb, 
                concurrent_requests, 
                quota_type
            )
            SELECT 
                COALESCE((SELECT MAX(id) FROM system_resource_quotas), 0) + ROW_NUMBER() OVER(),
                u.id,
                CASE 
                    WHEN u.username = 'admin' THEN 10
                    ELSE 3 
                END,
                CASE 
                    WHEN u.username = 'admin' THEN 20
                    ELSE 5 
                END,
                CASE 
                    WHEN u.username = 'admin' THEN 8192
                    ELSE 2048 
                END,
                CASE 
                    WHEN u.username = 'admin' THEN 51200
                    ELSE 10240 
                END,
                CASE 
                    WHEN u.username = 'admin' THEN 500
                    ELSE 100 
                END,
                CASE 
                    WHEN u.username = 'admin' THEN 'premium'
                    ELSE 'standard' 
                END
            FROM users u
            WHERE NOT EXISTS (
                SELECT 1 FROM system_resource_quotas srq 
                WHERE srq.user_id = u.id AND srq.is_active = TRUE
            )
            """
            
            execute_query(init_quotas_sql, fetch=False)
            print("âœ… ç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ ç”¨æˆ·æœåŠ¡ç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        
        print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
    except Exception as e:
        print(f"åˆå§‹åŒ–æ•°æ®åº“å¤±è´¥: {str(e)}")
        raise

def insert_with_snowflake_id(table_name, data):
    """
    ä½¿ç”¨é›ªèŠ±ç®—æ³•ç”ŸæˆIDå¹¶æ’å…¥æ•°æ®
    
    Args:
        table_name: è¡¨å
        data: è¦æ’å…¥çš„æ•°æ®å­—å…¸
        
    Returns:
        æ’å…¥çš„è®°å½•ID
    """
    try:
        # ç”Ÿæˆé›ªèŠ±ç®—æ³•ID
        from utils.snowflake import get_snowflake_id
        snowflake_id = get_snowflake_id()
        
        # æ·»åŠ IDåˆ°æ•°æ®ä¸­
        data['id'] = snowflake_id
        
        # å¤„ç†ç‰¹æ®Šå€¼ï¼ˆå¦‚NOW()å‡½æ•°ï¼‰
        processed_data = {}
        for key, value in data.items():
            if value == 'NOW()':
                # è·³è¿‡NOW()å‡½æ•°ï¼Œè®©SQLç›´æ¥å¤„ç†
                continue
            processed_data[key] = value
        
        # æ„å»ºSQLè¯­å¥
        columns = list(processed_data.keys())
        values = list(processed_data.values())
        placeholders = ['%s'] * len(columns)
        
        # å¤„ç†NOW()å‡½æ•°
        if 'created_at' in data and data['created_at'] == 'NOW()':
            columns.append('created_at')
            placeholders.append('NOW()')
        
        query = f"""
        INSERT INTO {table_name} ({', '.join(columns)})
        VALUES ({', '.join(placeholders)})
        RETURNING id
        """
        
        # æ‰§è¡Œæ’å…¥
        result = execute_query(query, values)
        
        # è¿”å›æ’å…¥çš„ID
        if result and len(result) > 0:
            return result[0]['id']
        return snowflake_id
    except Exception as e:
        error_msg = f"æ’å…¥æ•°æ®åˆ°{table_name}å¤±è´¥: {str(e)}"
        print(error_msg)
        print(f"æ•°æ®: {data}")
        print(f"é›ªèŠ±ID: {snowflake_id}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ•´æ•°èŒƒå›´é”™è¯¯
        if "integer out of range" in str(e).lower():
            print("é”™è¯¯: é›ªèŠ±ç®—æ³•IDè¶…å‡ºäº†INTEGERèŒƒå›´ï¼Œè¯·ç¡®ä¿æ•°æ®åº“è¡¨çš„IDå­—æ®µç±»å‹æ˜¯BIGINT")
            print("è§£å†³æ–¹æ¡ˆ: è¯·æ‰§è¡Œä»¥ä¸‹SQLä¿®æ”¹è¡¨ç»“æ„:")
            print(f"ALTER TABLE {table_name} ALTER COLUMN id TYPE BIGINT;")
        
        raise

if __name__ == "__main__":
    init_database() 