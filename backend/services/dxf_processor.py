#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
DXFæ–‡ä»¶å¤„ç†æœåŠ¡
ä½¿ç”¨GDAL/OGRæ–¹æ³•å¯¼å…¥PostGIS
"""

import os
import tempfile
import uuid
import subprocess
import json
from pathlib import Path
from osgeo import ogr, osr, gdal
from sqlalchemy import create_engine, text
from config import DB_CONFIG
import logging

logger = logging.getLogger(__name__)

class DXFProcessor:
    """DXFæ–‡ä»¶å¤„ç†å™¨ï¼Œä¸“é—¨å¤„ç†AutoCAD DXFæ–‡ä»¶"""
    
    def __init__(self):
        """åˆå§‹åŒ–DXFå¤„ç†å™¨"""
        # å¯ç”¨GDALå¼‚å¸¸
        gdal.UseExceptions()
        
        # æ•°æ®åº“è¿æ¥
        db_url = f"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
        self.engine = create_engine(db_url)
        
        logger.info("âœ… DXFå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def process_dxf_file(self, file_path, table_name, coordinate_system='EPSG:4326'):
        """
        å¤„ç†DXFæ–‡ä»¶å¹¶å¯¼å…¥PostGIS
        
        Args:
            file_path: DXFæ–‡ä»¶è·¯å¾„
            table_name: ç›®æ ‡è¡¨å
            coordinate_system: åæ ‡ç³»ï¼Œé»˜è®¤EPSG:4326
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹å¤„ç†DXFæ–‡ä»¶: {file_path}")
            
            # 1. éªŒè¯æ–‡ä»¶
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"DXFæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # 2. åˆ†æDXFæ–‡ä»¶ç»“æ„
            dxf_info = self._analyze_dxf_file(file_path)
            logger.info(f"DXFæ–‡ä»¶åˆ†æç»“æœ: {dxf_info}")
            
            # 3. ä½¿ç”¨GDALå¯¼å…¥PostGIS
            result = self._import_with_gdal(file_path, table_name, coordinate_system)
            
            # 4. åˆ›å»ºç©ºé—´ç´¢å¼•
            self._create_spatial_index(table_name)
            
            # 5. é‡å‘½ålayerå­—æ®µä¸ºcad_layerï¼ˆè§£å†³MVTæœåŠ¡layerå±æ€§å†²çªï¼‰
            rename_result = self._rename_layer_field_to_cad_layer(table_name)
            if rename_result['success']:
                logger.info(f"âœ… å­—æ®µé‡å‘½åå®Œæˆ: {rename_result['message']}")
            else:
                logger.warning(f"âš ï¸ å­—æ®µé‡å‘½åå¤±è´¥: {rename_result['error']}")
            
            return {
                'success': True,
                'table_name': table_name,
                'coordinate_system': coordinate_system,
                'dxf_info': dxf_info,
                'import_result': result,
                'rename_result': rename_result
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†DXFæ–‡ä»¶å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _analyze_dxf_file(self, file_path):
        """åˆ†æDXFæ–‡ä»¶ç»“æ„"""
        try:
            # ä½¿ç”¨GDALæ‰“å¼€DXFæ–‡ä»¶
            driver = ogr.GetDriverByName('DXF')
            datasource = driver.Open(file_path, 0)
            
            if not datasource:
                raise Exception("æ— æ³•æ‰“å¼€DXFæ–‡ä»¶")
            
            layers_info = []
            total_features = 0
            
            # éå†æ‰€æœ‰å›¾å±‚
            for i in range(datasource.GetLayerCount()):
                layer = datasource.GetLayer(i)
                layer_name = layer.GetName()
                feature_count = layer.GetFeatureCount()
                
                # è·å–å‡ ä½•ç±»å‹
                geom_type = ogr.GeometryTypeToName(layer.GetGeomType())
                
                # è·å–å­—æ®µä¿¡æ¯
                layer_defn = layer.GetLayerDefn()
                fields = []
                for j in range(layer_defn.GetFieldCount()):
                    field_defn = layer_defn.GetFieldDefn(j)
                    fields.append({
                        'name': field_defn.GetName(),
                        'type': field_defn.GetFieldTypeName(field_defn.GetType())
                    })
                
                layers_info.append({
                    'name': layer_name,
                    'feature_count': feature_count,
                    'geometry_type': geom_type,
                    'fields': fields
                })
                
                total_features += feature_count
            
            datasource = None
            
            return {
                'total_layers': len(layers_info),
                'total_features': total_features,
                'layers': layers_info
            }
            
        except Exception as e:
            logger.error(f"åˆ†æDXFæ–‡ä»¶å¤±è´¥: {str(e)}")
            return {
                'error': str(e)
            }
    
    def _import_with_gdal(self, file_path, table_name, coordinate_system):
        """ä½¿ç”¨GDALå¯¼å…¥DXFåˆ°PostGIS"""
        try:
            # æ„å»ºogr2ogrå‘½ä»¤
            pg_connection = (
                f"PG:host={DB_CONFIG['host']} "
                f"port={DB_CONFIG['port']} "
                f"dbname={DB_CONFIG['database']} "
                f"user={DB_CONFIG['user']} "
                f"password={DB_CONFIG['password']}"
            )
            
            cmd = [
                'ogr2ogr',
                '-f', 'PostgreSQL',
                pg_connection,
                file_path,
                '-nln', table_name,  # æŒ‡å®šè¡¨å
                '-overwrite',  # è¦†ç›–å·²å­˜åœ¨çš„è¡¨
                '-lco', 'GEOMETRY_NAME=geom',  # å‡ ä½•å­—æ®µå
                '-lco', 'FID=gid',  # ä¸»é”®å­—æ®µå
                '-t_srs', coordinate_system,  # ç›®æ ‡åæ ‡ç³»
                '-dim', 'XY',  # å¼ºåˆ¶2D
                '--config', 'DXF_ENCODING', 'UTF-8',  # è®¾ç½®ç¼–ç 
                '--config', 'SHAPE_ENCODING', 'UTF-8',  # é¢å¤–çš„ç¼–ç è®¾ç½®
                '--config', 'GDAL_DATA_ENCODING', 'UTF-8',  # GDALæ•°æ®ç¼–ç 
                # ğŸ”§ è§£å†³MVT layerå±æ€§å†²çªï¼šå°†DXFçš„layerå­—æ®µé‡å‘½åä¸ºcad_layer
                # åŸå› ï¼šMVTè§„èŒƒä¼šè‡ªåŠ¨æ·»åŠ layerå±æ€§ï¼ˆå€¼ä¸ºè¡¨åï¼‰ï¼Œä¸DXFçš„layerå­—æ®µå†²çª
                # è§£å†³æ–¹æ¡ˆï¼šå¯¼å…¥æ—¶ä¿æŒåŸå§‹å­—æ®µåï¼Œå¯¼å…¥åé€šè¿‡SQLé‡å‘½åå­—æ®µ
                '-select', 'layer,paperspace,subclasses,linetype,entityhandle,text,rawcodevalues',
                '--config', 'DXF_FEATURE_LIMIT_PER_BLOCK', '-1'  # ä¸é™åˆ¶blockä¸­çš„è¦ç´ æ•°é‡
            ]
            
            logger.info(f"æ‰§è¡Œogr2ogrå‘½ä»¤: {' '.join(cmd)}")
            
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            if result.returncode != 0:
                error_msg = result.stderr or result.stdout
                raise Exception(f"ogr2ogræ‰§è¡Œå¤±è´¥: {error_msg}")
            
            logger.info("âœ… GDALå¯¼å…¥å®Œæˆ")
            
            return {
                'method': 'ogr2ogr',
                'command': ' '.join(cmd),
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
        except subprocess.TimeoutExpired:
            raise Exception("DXFå¯¼å…¥è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰")
        except Exception as e:
            logger.error(f"GDALå¯¼å…¥å¤±è´¥: {str(e)}")
            raise
    
    def _create_spatial_index(self, table_name):
        """åˆ›å»ºç©ºé—´ç´¢å¼•"""
        try:
            with self.engine.connect() as conn:
                # åˆ›å»ºç©ºé—´ç´¢å¼•
                index_sql = f"""
                CREATE INDEX IF NOT EXISTS {table_name}_geom_idx 
                ON {table_name} USING GIST (geom);
                """
                conn.execute(text(index_sql))
                conn.commit()
                
                logger.info(f"âœ… ç©ºé—´ç´¢å¼•åˆ›å»ºå®Œæˆ: {table_name}_geom_idx")
                
        except Exception as e:
            logger.error(f"åˆ›å»ºç©ºé—´ç´¢å¼•å¤±è´¥: {str(e)}")
            raise

    def process_dxf_with_geopandas(self, file_path, table_name, coordinate_system='EPSG:4326'):
        """
        ä½¿ç”¨GeoPandaså¤„ç†DXFæ–‡ä»¶ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        æ³¨æ„ï¼šGeoPandaså¯¹DXFæ”¯æŒæœ‰é™
        """
        try:
            import geopandas as gpd
            import fiona
            
            logger.info(f"å°è¯•ä½¿ç”¨GeoPandasè¯»å–DXF: {file_path}")
            
            # æ£€æŸ¥fionaæ˜¯å¦æ”¯æŒDXF
            if 'DXF' not in fiona.supported_drivers:
                raise Exception("å½“å‰fionaç‰ˆæœ¬ä¸æ”¯æŒDXFæ ¼å¼")
            
            # è¯»å–DXFæ–‡ä»¶
            gdf = gpd.read_file(file_path, driver='DXF')
            
            if gdf.empty:
                raise Exception("DXFæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–å‡ ä½•æ•°æ®")
            
            # è®¾ç½®åæ ‡ç³»
            if gdf.crs is None:
                gdf.set_crs(coordinate_system, inplace=True)
            else:
                gdf = gdf.to_crs(coordinate_system)
            
            # å¯¼å…¥PostGIS
            db_url = f"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
            
            gdf.to_postgis(
                table_name,
                con=self.engine,
                if_exists='replace',
                index=True,
                chunksize=1000
            )
            
            logger.info("âœ… GeoPandaså¯¼å…¥å®Œæˆ")
            
            return {
                'success': True,
                'method': 'geopandas',
                'rows_imported': len(gdf),
                'columns': list(gdf.columns),
                'geometry_types': gdf.geom_type.unique().tolist()
            }
            
        except ImportError:
            raise Exception("GeoPandasæˆ–ç›¸å…³ä¾èµ–æœªå®‰è£…")
        except Exception as e:
            logger.error(f"GeoPandaså¤„ç†å¤±è´¥: {str(e)}")
            raise

    def import_dxf_to_postgis(self, file_path, table_name, source_srs='EPSG:4326', target_srs='EPSG:3857'):
        """
        ä½¿ç”¨ogr2ogrå°†DXFæ–‡ä»¶å¯¼å…¥PostGISï¼Œæ”¯æŒåæ ‡ç³»è½¬æ¢
        
        Args:
            file_path: DXFæ–‡ä»¶è·¯å¾„
            table_name: ç›®æ ‡è¡¨å
            source_srs: æºåæ ‡ç³»ï¼Œé»˜è®¤EPSG:4326
            target_srs: ç›®æ ‡åæ ‡ç³»ï¼Œé»˜è®¤EPSG:3857 (Web Mercator)
            
        Returns:
            dict: å¯¼å…¥ç»“æœ
        """
        try:
            import subprocess
            import time
            from models.db import execute_query
            
            logger.info(f"å¼€å§‹å¯¼å…¥DXFåˆ°PostGIS: {file_path} -> {table_name}")
            logger.info(f"åæ ‡ç³»è½¬æ¢: {source_srs} -> {target_srs}")
            
            start_time = time.time()
            
            # 1. éªŒè¯æ–‡ä»¶
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"DXFæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # 2. åˆ†æDXFæ–‡ä»¶
            dxf_info = self._analyze_dxf_file(file_path)
            logger.info(f"DXFæ–‡ä»¶åˆ†æç»“æœ: {dxf_info}")
            
            # 3. æ„å»ºogr2ogrå‘½ä»¤
            pg_connection = (
                f"PG:host={DB_CONFIG['host']} "
                f"port={DB_CONFIG['port']} "
                f"dbname={DB_CONFIG['database']} "
                f"user={DB_CONFIG['user']} "
                f"password={DB_CONFIG['password']}"
            )
            
            cmd = [
                'ogr2ogr',
                '-f', 'PostgreSQL',
                pg_connection,
                file_path,
                '-nln', table_name,  # æŒ‡å®šè¡¨å
                '-overwrite',        # è¦†ç›–å·²å­˜åœ¨çš„è¡¨
                '-lco', 'GEOMETRY_NAME=geom',     # å‡ ä½•å­—æ®µå
                '-lco', 'FID=gid',               # ä¸»é”®å­—æ®µå
                '-lco', 'SPATIAL_INDEX=ON',      # åˆ›å»ºç©ºé—´ç´¢å¼•ï¼Œä½¿ç”¨ONè€Œä¸æ˜¯YES
                '-s_srs', source_srs,            # æºåæ ‡ç³»
                '-t_srs', target_srs,            # ç›®æ ‡åæ ‡ç³»
                '-dim', 'XY',                    # å¼ºåˆ¶2D
                '-skipfailures',                 # è·³è¿‡å¤±è´¥çš„è¦ç´ ï¼Œç»§ç»­å¤„ç†
                '--config', 'DXF_ENCODING', 'UTF-8',  # è®¾ç½®ç¼–ç 
                '--config', 'DXF_MERGE_BLOCK_GEOMETRIES', 'YES',  # åˆå¹¶å—å‡ ä½•
                '--config', 'DXF_INCLUDE_RAW_CODE_VALUES', 'TRUE',  # åŒ…å«åŸå§‹ä»£ç å€¼ï¼ˆåŒ…æ‹¬é¢œè‰²ï¼‰
                '--config', 'SHAPE_ENCODING', 'UTF-8',  # é¢å¤–çš„ç¼–ç è®¾ç½®
                '--config', 'GDAL_DATA_ENCODING', 'UTF-8',  # GDALæ•°æ®ç¼–ç 
                # ğŸ”§ è§£å†³MVT layerå±æ€§å†²çªï¼šå°†DXFçš„layerå­—æ®µé‡å‘½åä¸ºcad_layer
                # åŸå› ï¼šMVTè§„èŒƒä¼šè‡ªåŠ¨æ·»åŠ layerå±æ€§ï¼ˆå€¼ä¸ºè¡¨åï¼‰ï¼Œä¸DXFçš„layerå­—æ®µå†²çª
                # è§£å†³æ–¹æ¡ˆï¼šå¯¼å…¥æ—¶ä¿æŒåŸå§‹å­—æ®µåï¼Œå¯¼å…¥åé€šè¿‡SQLé‡å‘½åå­—æ®µ
                '-select', 'layer,paperspace,subclasses,linetype,entityhandle,text,rawcodevalues',
                '--config', 'DXF_FEATURE_LIMIT_PER_BLOCK', '-1'  # ä¸é™åˆ¶blockä¸­çš„è¦ç´ æ•°é‡
            ]
            
            # å¦‚æœæºåæ ‡ç³»å’Œç›®æ ‡åæ ‡ç³»ç›¸åŒï¼Œåˆ™ä¸éœ€è¦åæ ‡è½¬æ¢
            if source_srs == target_srs:
                # ç§»é™¤åæ ‡è½¬æ¢å‚æ•°
                cmd = [arg for arg in cmd if arg not in ['-s_srs', source_srs, '-t_srs', target_srs]]
                # åªè®¾ç½®ç›®æ ‡åæ ‡ç³»
                cmd.extend(['-a_srs', target_srs])
                logger.info(f"ä¸éœ€è¦åæ ‡è½¬æ¢ï¼Œç›´æ¥è®¾ç½®åæ ‡ç³»ä¸º: {target_srs}")
            
            logger.info(f"æ‰§è¡Œogr2ogrå‘½ä»¤: {' '.join(cmd)}")
            
            # 4. æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            
            # ç”±äºä½¿ç”¨äº†-skipfailuresï¼Œå³ä½¿æœ‰éƒ¨åˆ†è¦ç´ å¤±è´¥ï¼Œè¿”å›ç ä¹Ÿå¯èƒ½æ˜¯0
            # æˆ‘ä»¬éœ€è¦æ£€æŸ¥stderrä¸­æ˜¯å¦æœ‰è‡´å‘½é”™è¯¯
            if result.returncode != 0:
                error_msg = result.stderr or result.stdout
                # æ£€æŸ¥æ˜¯å¦æ˜¯è‡´å‘½é”™è¯¯è¿˜æ˜¯åªæ˜¯è­¦å‘Š/è·³è¿‡çš„è¦ç´ 
                if 'Terminating translation prematurely' in error_msg or 'FAILURE' in error_msg:
                    logger.error(f"ogr2ogræ‰§è¡Œå¤±è´¥: {error_msg}")
                    raise Exception(f"DXFå¯¼å…¥å¤±è´¥: {error_msg}")
                else:
                    # åªæ˜¯è­¦å‘Šï¼Œå¯ä»¥ç»§ç»­
                    logger.warning(f"ogr2ogræœ‰è­¦å‘Šä½†ç»§ç»­æ‰§è¡Œ: {error_msg}")
            
            # æ£€æŸ¥stderrä¸­çš„è­¦å‘Šå’Œè·³è¿‡ä¿¡æ¯
            if result.stderr:
                logger.info(f"ogr2ogrè¾“å‡ºä¿¡æ¯: {result.stderr}")
            
            logger.info("âœ… ogr2ogræ‰§è¡Œå®Œæˆ")
            
            # 5. éªŒè¯å¯¼å…¥ç»“æœ
            validation_result = self._validate_imported_table(table_name, target_srs)
            
            if not validation_result['success']:
                raise Exception(f"å¯¼å…¥éªŒè¯å¤±è´¥: {validation_result['error']}")
            
            # 6. è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯
            stats = self._get_table_statistics(table_name)
            
            # 7. é‡å‘½ålayerå­—æ®µä¸ºcad_layerï¼ˆè§£å†³MVTæœåŠ¡layerå±æ€§å†²çªï¼‰
            rename_result = self._rename_layer_field_to_cad_layer(table_name)
            if rename_result['success']:
                logger.info(f"âœ… å­—æ®µé‡å‘½åå®Œæˆ: {rename_result['message']}")
            else:
                logger.warning(f"âš ï¸ å­—æ®µé‡å‘½åå¤±è´¥: {rename_result['error']}")
            
            import_time = time.time() - start_time
            
            logger.info(f"âœ… DXFå¯¼å…¥å®Œæˆ: {table_name}, è€—æ—¶: {import_time:.2f}ç§’")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¦ç´ è¢«è·³è¿‡
            skipped_features = 0
            warnings = []
            error_count = 0
            
            if result.stderr:
                # åˆ†æstderrä¸­çš„è·³è¿‡ä¿¡æ¯
                stderr_lines = result.stderr.split('\n')
                for line in stderr_lines:
                    if 'Unable to write feature' in line:
                        skipped_features += 1
                    elif 'More than' in line and 'errors or warnings' in line:
                        # å¦‚æœè¶…è¿‡1000ä¸ªé”™è¯¯ï¼Œä»æ¶ˆæ¯ä¸­æå–æ•°é‡
                        try:
                            parts = line.split()
                            if len(parts) >= 3 and parts[2].isdigit():
                                error_count = int(parts[2])
                        except:
                            pass
                    elif 'Warning' in line or 'ERROR' in line:
                        warnings.append(line.strip())
            
            # è®¡ç®—æˆåŠŸå¯¼å…¥çš„è¦ç´ æ•°é‡
            original_features = dxf_info.get('total_features', 0)
            imported_features = stats['feature_count']
            
            # å¦‚æœogr2ogråœæ­¢æŠ¥å‘Šé”™è¯¯ï¼Œé€šè¿‡æ•°é‡å·®è®¡ç®—è·³è¿‡çš„è¦ç´ 
            if error_count > 0 or (original_features > imported_features and skipped_features == 0):
                skipped_features = max(skipped_features, original_features - imported_features)
            
            logger.info(f"åŸå§‹è¦ç´ æ•°: {original_features}, æˆåŠŸå¯¼å…¥: {imported_features}, è·³è¿‡: {skipped_features}")
            
            # å¦‚æœæœ‰å¤§é‡é”™è¯¯ï¼Œæ·»åŠ ç‰¹æ®Šè¯´æ˜
            if error_count > 0:
                warnings.insert(0, f"æ£€æµ‹åˆ°å¤§é‡é”™è¯¯ï¼ˆ>{error_count}ä¸ªï¼‰ï¼Œéƒ¨åˆ†è¦ç´ å¯èƒ½å› ç¼–ç æˆ–å‡ ä½•é—®é¢˜è¢«è·³è¿‡")
            
            return {
                'success': True,
                'table_name': table_name,
                'source_srs': source_srs,
                'target_srs': target_srs,
                'import_time': import_time,
                'feature_count': imported_features,
                'original_feature_count': original_features,
                'skipped_features': skipped_features,
                'success_rate': (imported_features / original_features * 100) if original_features > 0 else 0,
                'bbox': stats['bbox'],
                'geometry_types': stats['geometry_types'],
                'layers': dxf_info.get('layers', []),
                'dxf_info': dxf_info,
                'warnings': warnings,
                'ogr_output': {
                    'stdout': result.stdout,
                    'stderr': result.stderr
                }
            }
            
        except subprocess.TimeoutExpired:
            logger.error("DXFå¯¼å…¥è¶…æ—¶ï¼ˆè¶…è¿‡10åˆ†é’Ÿï¼‰")
            return {'success': False, 'error': 'DXFå¯¼å…¥è¶…æ—¶ï¼ˆè¶…è¿‡10åˆ†é’Ÿï¼‰'}
        except Exception as e:
            logger.error(f"DXFå¯¼å…¥å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _validate_imported_table(self, table_name, expected_srs):
        """éªŒè¯å¯¼å…¥çš„è¡¨"""
        try:
            from models.db import execute_query
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            check_table_sql = """
            SELECT COUNT(*) as exists FROM information_schema.tables 
            WHERE table_name = %s AND table_schema = 'public'
            """
            table_exists = execute_query(check_table_sql, [table_name])
            
            if not table_exists or table_exists[0]['exists'] == 0:
                return {'success': False, 'error': f'è¡¨ {table_name} ä¸å­˜åœ¨'}
            
            # æ£€æŸ¥å‡ ä½•å­—æ®µå’Œæ•°æ®
            check_geom_sql = f"""
            SELECT 
                COUNT(*) as total_rows,
                COUNT(geom) as geom_rows,
                ST_SRID(geom) as srid
            FROM {table_name}
            GROUP BY ST_SRID(geom)
            """
            geom_info = execute_query(check_geom_sql, [])
            
            if not geom_info:
                # æ£€æŸ¥è¡¨æ˜¯å¦å®Œå…¨ä¸ºç©º
                check_empty_sql = f"SELECT COUNT(*) as count FROM {table_name}"
                empty_check = execute_query(check_empty_sql, [])
                if empty_check and empty_check[0]['count'] == 0:
                    return {'success': False, 'error': 'è¡¨ä¸­æ²¡æœ‰æ•°æ®ï¼ˆæ‰€æœ‰è¦ç´ å¯èƒ½éƒ½å¯¼å…¥å¤±è´¥ï¼‰'}
                else:
                    return {'success': False, 'error': 'è¡¨ä¸­æ²¡æœ‰æœ‰æ•ˆçš„å‡ ä½•æ•°æ®'}
            
            # éªŒè¯åæ ‡ç³»
            actual_srid = geom_info[0]['srid']
            expected_srid = int(expected_srs.replace('EPSG:', ''))
            
            if actual_srid != expected_srid:
                logger.warning(f"åæ ‡ç³»ä¸åŒ¹é…: æœŸæœ› {expected_srid}, å®é™… {actual_srid}")
            
            total_rows = geom_info[0]['total_rows']
            geom_rows = geom_info[0]['geom_rows']
            
            # å¦‚æœæœ‰å‡ ä½•æ•°æ®å°±è®¤ä¸ºæˆåŠŸï¼Œå³ä½¿æ•°é‡å¯èƒ½æ¯”åŸå§‹æ–‡ä»¶å°‘
            if geom_rows > 0:
                logger.info(f"æˆåŠŸå¯¼å…¥ {geom_rows} ä¸ªæœ‰æ•ˆå‡ ä½•è¦ç´ ï¼ˆå…± {total_rows} è¡Œï¼‰")
                return {
                    'success': True,
                    'total_rows': total_rows,
                    'geom_rows': geom_rows,
                    'srid': actual_srid
                }
            else:
                return {'success': False, 'error': 'æ²¡æœ‰æœ‰æ•ˆçš„å‡ ä½•æ•°æ®è¢«å¯¼å…¥'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _get_table_statistics(self, table_name):
        """è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        try:
            from models.db import execute_query
            
            # è·å–åŸºæœ¬ç»Ÿè®¡
            stats_sql = f"""
            SELECT 
                COUNT(*) as feature_count,
                ST_GeometryType(geom) as geom_type,
                COUNT(DISTINCT ST_GeometryType(geom)) as geom_type_count
            FROM {table_name} 
            WHERE geom IS NOT NULL
            GROUP BY ST_GeometryType(geom)
            """
            
            stats = execute_query(stats_sql, [])
            
            total_features = sum(row['feature_count'] for row in stats)
            geometry_types = [row['geom_type'] for row in stats]
            
            # è·å–è¾¹ç•Œæ¡†
            bbox_sql = f"""
            SELECT 
                ST_XMin(extent) as min_x,
                ST_YMin(extent) as min_y,
                ST_XMax(extent) as max_x,
                ST_YMax(extent) as max_y
            FROM (
                SELECT ST_Extent(geom) as extent 
                FROM {table_name} 
                WHERE geom IS NOT NULL
            ) as bbox_query
            """
            
            bbox_result = execute_query(bbox_sql, [])
            bbox = None
            
            if bbox_result and bbox_result[0]['min_x'] is not None:
                bbox = [
                    bbox_result[0]['min_x'],
                    bbox_result[0]['min_y'],
                    bbox_result[0]['max_x'],
                    bbox_result[0]['max_y']
                ]
            
            return {
                'feature_count': total_features,
                'bbox': bbox,
                'geometry_types': geometry_types
            }
            
        except Exception as e:
            logger.error(f"è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {
                'feature_count': 0,
                'bbox': None,
                'geometry_types': []
            }

    def _rename_layer_field_to_cad_layer(self, table_name):
        """é‡å‘½ålayerå­—æ®µä¸ºcad_layer"""
        try:
            from models.db import execute_query
            
            logger.info(f"å¼€å§‹é‡å‘½ålayerå­—æ®µä¸ºcad_layer: {table_name}")
            
            # 1. æ£€æŸ¥layerå­—æ®µæ˜¯å¦å­˜åœ¨
            check_layer_sql = """
            SELECT column_name FROM information_schema.columns 
            WHERE table_name = %s AND column_name = 'layer'
            """
            layer_exists = execute_query(check_layer_sql, [table_name])
            
            if not layer_exists:
                return {'success': False, 'error': 'layerå­—æ®µä¸å­˜åœ¨ï¼Œæ— æ³•é‡å‘½å'}
            
            # 2. é‡å‘½ålayerå­—æ®µä¸ºcad_layer
            rename_layer_sql = f"""
            ALTER TABLE {table_name} 
            RENAME COLUMN layer TO cad_layer;
            """
            execute_query(rename_layer_sql, [], fetch=False)
            logger.info("âœ… layerå­—æ®µé‡å‘½åå®Œæˆ")
            
            return {
                'success': True,
                'message': f'layerå­—æ®µé‡å‘½åå®Œæˆ: {table_name} è¡¨ä¸­layerå­—æ®µå·²é‡å‘½åä¸ºcad_layer'
            }
            
        except Exception as e:
            logger.error(f"é‡å‘½ålayerå­—æ®µå¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}

# ä½¿ç”¨ç¤ºä¾‹å‡½æ•°
def process_dxf_to_postgis(file_path, table_name=None, coordinate_system='EPSG:4326', method='gdal'):
    """
    å¤„ç†DXFæ–‡ä»¶åˆ°PostGISçš„ä¾¿æ·å‡½æ•°
    
    Args:
        file_path: DXFæ–‡ä»¶è·¯å¾„
        table_name: ç›®æ ‡è¡¨åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        coordinate_system: åæ ‡ç³»
        method: å¤„ç†æ–¹æ³• ('gdal' æˆ– 'geopandas')
    """
    processor = DXFProcessor()
    
    if table_name is None:
        table_name = f"dxf_{uuid.uuid4().hex[:8]}"
    
    if method == 'gdal':
        return processor.process_dxf_file(file_path, table_name, coordinate_system)
    elif method == 'geopandas':
        return processor.process_dxf_with_geopandas(file_path, table_name, coordinate_system)
    else:
        raise ValueError("methodå¿…é¡»æ˜¯'gdal'æˆ–'geopandas'") 