#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import requests
import time
import os
import re
import zipfile
import tempfile
import shutil
import stat
from models.db import execute_query, insert_with_snowflake_id
from config import GEOSERVER_CONFIG, DB_CONFIG
import logging
from datetime import datetime
from pathlib import Path
from urllib.parse import urljoin
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
import traceback
import subprocess
import uuid
import glob
from urllib.parse import urlparse
import os
import sys
import psycopg2
from requests.auth import HTTPBasicAuth
try:
    from osgeo import gdal, osr
    GDAL_AVAILABLE = True
    # é…ç½®GDALä»¥é¿å…è¾“å‡ºè¿‡å¤šä¿¡æ¯
    gdal.UseExceptions()
except ImportError:
    GDAL_AVAILABLE = False
    print("è­¦å‘Š: GDAL Pythonç»‘å®šä¸å¯ç”¨ï¼Œå°†å°è¯•ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·")


# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GeoServerService:
    """GeoServeræœåŠ¡ç±»ï¼Œç”¨äºç®¡ç†GeoServerèµ„æº"""
    
    def __init__(self):
        self.url = GEOSERVER_CONFIG['url']
        self.user = GEOSERVER_CONFIG['user']
        self.password = GEOSERVER_CONFIG['password']
        self.workspace = GEOSERVER_CONFIG['workspace']
        self.rest_url = f"{self.url}/rest"
        self.auth = (self.user, self.password)
        
        # ç¡®ä¿å·¥ä½œç©ºé—´å­˜åœ¨
        self._ensure_workspace_exists()
    
    def _ensure_workspace_exists(self):
        """ç¡®ä¿å·¥ä½œç©ºé—´å­˜åœ¨
        
        æ£€æŸ¥å·¥ä½œç©ºé—´æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        
        Returns:
            å·¥ä½œç©ºé—´ID
        """
        try:
            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰å·¥ä½œç©ºé—´è®°å½•
            workspace_sql = "SELECT id FROM geoserver_workspaces WHERE name = %s"
            workspace_result = execute_query(workspace_sql, (self.workspace,))
            
            if not workspace_result:
                # åœ¨GeoServerä¸­åˆ›å»ºå·¥ä½œç©ºé—´
                self._create_workspace_in_geoserver()
                
                # åœ¨æ•°æ®åº“ä¸­è®°å½•å·¥ä½œç©ºé—´
                workspace_params = {
                    'name': self.workspace,
                    'namespace_uri': f"http://{self.workspace}",
                    'namespace_prefix': self.workspace,
                    'description': f"Workspace for {self.workspace}",
                    'is_default': True
                }
                
                workspace_id = insert_with_snowflake_id('geoserver_workspaces', workspace_params)
                print(f"å·¥ä½œç©ºé—´ {self.workspace} åˆ›å»ºæˆåŠŸï¼ŒID: {workspace_id}")
                return workspace_id
            else:
                workspace_id = workspace_result[0]['id']
                print(f"å·¥ä½œç©ºé—´ {self.workspace} å·²å­˜åœ¨ï¼ŒID: {workspace_id}")
                return workspace_id
                
        except Exception as e:
            error_msg = f"ç¡®ä¿å·¥ä½œç©ºé—´å­˜åœ¨å¤±è´¥: {str(e)}"
            print(error_msg)
            raise Exception(error_msg)
    
    def _create_workspace_in_geoserver(self):
        """åœ¨GeoServerä¸­åˆ›å»ºå·¥ä½œç©ºé—´
        
        ä½¿ç”¨REST APIæ£€æŸ¥å·¥ä½œç©ºé—´æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        """
        print(f"æ£€æŸ¥GeoServerä¸­æ˜¯å¦å­˜åœ¨å·¥ä½œç©ºé—´: {self.workspace}")
        
        # æ£€æŸ¥å·¥ä½œç©ºé—´æ˜¯å¦å­˜åœ¨
        workspace_url = f"{self.rest_url}/workspaces/{self.workspace}"
        print(f"æ£€æŸ¥URL: {workspace_url}")
        
        try:
            check_response = requests.get(
                workspace_url, 
                auth=self.auth,
                headers={'Accept': 'application/json'},
                timeout=30
            )
            
            print(f"æ£€æŸ¥å“åº”çŠ¶æ€ç : {check_response.status_code}")
            
            if check_response.status_code == 200:
                # å·¥ä½œç©ºé—´å·²å­˜åœ¨
                try:
                    workspace_data = check_response.json()
                    print(f"å·¥ä½œç©ºé—´ä¿¡æ¯: {workspace_data}")
                except:
                    pass
                print(f"âœ… å·¥ä½œç©ºé—´ '{self.workspace}' å·²å­˜åœ¨ï¼Œæ— éœ€åˆ›å»º")
                return True
            elif check_response.status_code != 404:
                # é404é”™è¯¯ï¼Œå¯èƒ½æ˜¯è¿æ¥é—®é¢˜
                print(f"âš ï¸ æ£€æŸ¥å·¥ä½œç©ºé—´æ—¶å‡ºç°é404é”™è¯¯: {check_response.status_code}")
                if check_response.text:
                    print(f"å“åº”å†…å®¹: {check_response.text}")
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥å·¥ä½œç©ºé—´æ—¶å‡ºç°å¼‚å¸¸: {str(e)}")
            print("å°è¯•ç›´æ¥åˆ›å»ºå·¥ä½œç©ºé—´...")
        
        # åˆ›å»ºå·¥ä½œç©ºé—´
        print(f"åˆ›å»ºå·¥ä½œç©ºé—´: {self.workspace}")
        workspace_url = f"{self.rest_url}/workspaces"
        headers = {'Content-type': 'application/json'}
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        workspace_data = {
            "workspace": {
                "name": self.workspace
            }
        }
        
        try:
            response = requests.post(
                workspace_url, 
                data=json.dumps(workspace_data), 
                headers=headers, 
                auth=self.auth,
                timeout=30
            )
            
            print(f"åˆ›å»ºå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code in [201, 200]:
                print(f"âœ… å·¥ä½œç©ºé—´ '{self.workspace}' åˆ›å»ºæˆåŠŸ")
                return True
            else:
                print(f"âŒ åˆ›å»ºå·¥ä½œç©ºé—´å¤±è´¥: HTTP {response.status_code}")
                if response.text:
                    print(f"å“åº”å†…å®¹: {response.text}")
                raise Exception(f"åˆ›å»ºå·¥ä½œç©ºé—´å¤±è´¥: HTTP {response.status_code} - {response.text}")
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
            raise Exception(f"åˆ›å»ºå·¥ä½œç©ºé—´è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            print(f"âŒ å…¶ä»–å¼‚å¸¸: {str(e)}")
            raise
    
    def publish_shapefile(self, shp_zip_path, store_name, file_id):
        """å‘å¸ƒShapefileæœåŠ¡ - è§£å‹éªŒè¯ç‰ˆæœ¬
        
        å‘å¸ƒæµç¨‹ï¼š
        1. è§£å‹ZIPæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        2. éªŒè¯Shapefileæ–‡ä»¶å®Œæ•´æ€§
        3. åœ¨GeoServerä¸­åˆ›å»ºæ•°æ®å­˜å‚¨
        4. ä¸Šä¼ è§£å‹åçš„æ–‡ä»¶åˆ°GeoServer
        5. åˆ›å»ºæ•°æ®åº“è®°å½•
        6. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        
        Args:
            shp_zip_path: Shapefile ZIPåŒ…è·¯å¾„
            store_name: æ•°æ®å­˜å‚¨åç§°ï¼ˆå°†è¢«é‡æ–°ç”Ÿæˆä¸º"æ–‡ä»¶å_store"æ ¼å¼ï¼‰
            file_id: æ–‡ä»¶ID
            
        Returns:
            å‘å¸ƒç»“æœä¿¡æ¯
        """
        extracted_folder = None
        try:
            print(f"å¼€å§‹å‘å¸ƒShapefileï¼ˆè§£å‹éªŒè¯ç‰ˆæœ¬ï¼‰: {shp_zip_path}")
            
            # 1. ä¿®å¤æ–‡ä»¶è·¯å¾„é—®é¢˜
            corrected_path = self._correct_path(shp_zip_path)
            print(f"ä¿®æ­£åçš„æ–‡ä»¶è·¯å¾„: {corrected_path}")
            
            # ç¡®ä¿æ˜¯zipæ–‡ä»¶
            if not corrected_path.endswith('.zip'):
                raise ValueError("Shapefileå¿…é¡»æ˜¯zipæ ¼å¼")
            
            # 2. è§£å‹å¹¶éªŒè¯ZIPæ–‡ä»¶
            extracted_folder = self._extract_and_validate_shapefile_simple(corrected_path)
            print(f"âœ… ZIPæ–‡ä»¶è§£å‹å¹¶éªŒè¯æˆåŠŸ: {extracted_folder}")
            
            # 3. æ ¹æ®æ–‡ä»¶åç”Ÿæˆstoreåç§°
            filename = os.path.splitext(os.path.basename(corrected_path))[0]
            clean_filename = re.sub(r'[^a-zA-Z0-9_\-\u4e00-\u9fff]', '_', filename)
            generated_store_name = f"{clean_filename}_store"
            print(f"è‡ªåŠ¨ç”Ÿæˆçš„å­˜å‚¨åç§°: {generated_store_name}")
            
            # 4. è·å–å·¥ä½œç©ºé—´ID
            workspace_id = self._get_workspace_id()
            
            # 5. æ£€æŸ¥æ˜¯å¦å·²ç»å‘å¸ƒ - æ£€æŸ¥æ•°æ®åº“ä¸­çš„è®°å½•
            print(f"æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸å…³å‘å¸ƒè®°å½•...")
            existing_check_sql = """
            SELECT gl.id as layer_id, gl.name as layer_name, 
                   gs.id as store_id, gs.name as store_name,
                   gft.id as featuretype_id
            FROM geoserver_layers gl
            LEFT JOIN geoserver_featuretypes gft ON gl.featuretype_id = gft.id
            LEFT JOIN geoserver_stores gs ON gft.store_id = gs.id
            WHERE gl.file_id = %s OR gs.name = %s
            """
            existing_records = execute_query(existing_check_sql, (file_id, generated_store_name))
            
            if existing_records:
                existing_record = existing_records[0]
                print(f"âš ï¸ å‘ç°å·²å­˜åœ¨çš„å‘å¸ƒè®°å½•:")
                print(f"  å›¾å±‚ID: {existing_record['layer_id']}, å›¾å±‚å: {existing_record['layer_name']}")
                print(f"  å­˜å‚¨ID: {existing_record['store_id']}, å­˜å‚¨å: {existing_record['store_name']}")
                
                # è¿”å›å·²å­˜åœ¨çš„å‘å¸ƒä¿¡æ¯ï¼Œè€Œä¸æ˜¯æŠ¥é”™
                return {
                    "success": True,
                    "message": "æ–‡ä»¶å·²å‘å¸ƒï¼Œè¿”å›ç°æœ‰å‘å¸ƒä¿¡æ¯",
                    "existing": True,
                    "store_name": existing_record['store_name'],
                    "layer_name": existing_record['layer_name'],
                    "layer_id": existing_record['layer_id']
                }
            
            # 6. è·å–SHPæ–‡ä»¶åå¹¶å¤„ç†æ–‡ä»¶é‡å‘½å
            original_shp_name = self._get_shp_name_from_folder(extracted_folder)
            print(f"è§£å‹æ–‡ä»¶å¤¹ä¸­çš„åŸå§‹SHPæ–‡ä»¶å: {original_shp_name}")
            
            # æ£€æŸ¥å¹¶é‡å‘½ååŒ…å«ä¸­æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦çš„æ–‡ä»¶
            safe_shp_name = self._ensure_safe_shapefile_names(extracted_folder, original_shp_name, clean_filename)
            print(f"å¤„ç†åçš„SHPæ–‡ä»¶å: {safe_shp_name}")
            
            # 7. é¢„æ¸…ç†ï¼šåˆ é™¤å¯èƒ½å­˜åœ¨çš„åŒådatastoreï¼ˆGeoServerä¸­çš„æ®‹ç•™ï¼‰
            print(f"é¢„æ¸…ç†ï¼šæ£€æŸ¥å¹¶åˆ é™¤å¯èƒ½å­˜åœ¨çš„åŒådatastore")
            self._cleanup_existing_datastore(generated_store_name)
            
            # 8. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºæ•°æ®å­˜å‚¨è®°å½•
            store_id = self._create_datastore_in_db(generated_store_name, workspace_id, 'Shapefile', file_id)
            print(f"âœ… æ•°æ®å­˜å‚¨è®°å½•åˆ›å»ºæˆåŠŸï¼Œstore_id={store_id}")
            
            # 9. åœ¨GeoServerä¸­åˆ›å»ºç©ºçš„æ•°æ®å­˜å‚¨
            self._create_empty_shapefile_datastore(generated_store_name)
            print(f"âœ… GeoServerä¸­ç©ºæ•°æ®å­˜å‚¨åˆ›å»ºæˆåŠŸ")
            
            # 10. ä¸Šä¼ è§£å‹åçš„Shapefileåˆ°GeoServer
            self._upload_extracted_shapefile_to_geoserver(extracted_folder, generated_store_name)
            print(f"âœ… Shapefileæ–‡ä»¶å·²ä¸Šä¼ åˆ°GeoServer")
            
            # 11. ç­‰å¾…GeoServerå¤„ç†
            time.sleep(3)
            
            # 12. è·å–è¦ç´ ç±»å‹ä¿¡æ¯ï¼ˆè®©GeoServerè‡ªåŠ¨ç¡®å®šè¦ç´ ç±»å‹åç§°ï¼‰
            featuretype_info = self._get_featuretype_info(generated_store_name)
            print(f"âœ… è·å–è¦ç´ ç±»å‹ä¿¡æ¯æˆåŠŸ")
            
            # 13. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦ç´ ç±»å‹è®°å½•
            featuretype_id = self._create_featuretype_in_db(featuretype_info, store_id)
            print(f"âœ… è¦ç´ ç±»å‹è®°å½•åˆ›å»ºæˆåŠŸï¼Œfeaturetype_id={featuretype_id}")
            
            # 14. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºå›¾å±‚è®°å½•
            layer_info = self._create_layer_in_db(featuretype_info, workspace_id, featuretype_id, file_id, 'datastore')
            print(f"âœ… å›¾å±‚è®°å½•åˆ›å»ºæˆåŠŸï¼Œlayer_id={layer_info['id']}")
            
            # 15. è¿”å›æœåŠ¡ä¿¡æ¯
            result = {
                "success": True,
                "store_name": generated_store_name,
                "layer_name": layer_info['full_name'],
                "wms_url": layer_info['wms_url'],
                "wfs_url": layer_info['wfs_url'],
                "layer_info": layer_info,
                "filename": filename
            }
            
            print(f"âœ… ShapefileæœåŠ¡å‘å¸ƒæˆåŠŸ: {result['layer_name']}")
            return result
            
        except Exception as e:
            print(f"âŒ å‘å¸ƒShapefileå¤±è´¥: {str(e)}")
            
            # æ¸…ç†å¯èƒ½åˆ›å»ºçš„GeoServerèµ„æº
            if 'generated_store_name' in locals():
                self._cleanup_failed_publish(generated_store_name, 'datastore')
            
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨æ–¹çŸ¥é“å‘å¸ƒå¤±è´¥
            raise Exception(f"å‘å¸ƒShapefileå¤±è´¥: {str(e)}")
            
        finally:
            # æ¸…ç†è§£å‹çš„ä¸´æ—¶æ–‡ä»¶å¤¹
            if extracted_folder and os.path.exists(extracted_folder):
                import shutil
                try:
                    shutil.rmtree(extracted_folder)
                    print(f"âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹: {extracted_folder}")
                except Exception as cleanup_error:
                    print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹å¤±è´¥: {cleanup_error}")
    
    def publish_geotiff(self, tif_path, store_name, file_id, coordinate_system=None, enable_transparency=True):
        """å‘å¸ƒGeoTIFFæœåŠ¡
        
        æ³¨æ„ï¼šæ¯æ¬¡å‘å¸ƒéƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„storeï¼Œstoreåç§°æ ¼å¼ä¸º"æ–‡ä»¶å_store"
        
        Args:
            tif_path: GeoTIFFæ–‡ä»¶è·¯å¾„
            store_name: æ•°æ®å­˜å‚¨åç§°ï¼ˆå°†è¢«é‡æ–°ç”Ÿæˆä¸º"æ–‡ä»¶å_store"æ ¼å¼ï¼‰
            file_id: æ–‡ä»¶ID
            coordinate_system: æŒ‡å®šçš„åæ ‡ç³»ï¼Œå¦‚'EPSG:2379'ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ–‡ä»¶è‡ªå¸¦çš„åæ ‡ç³»
            enable_transparency: æ˜¯å¦å¯ç”¨é€æ˜åº¦è®¾ç½®ï¼Œé»˜è®¤ä¸ºTrueï¼Œå°†è®¾ç½®é»‘è‰²èƒŒæ™¯ä¸ºé€æ˜
            
        Returns:
            å‘å¸ƒç»“æœä¿¡æ¯
        """
        try:
            print(f"å¼€å§‹å‘å¸ƒGeoTIFF: {tif_path}")
            if coordinate_system:
                print(f"æŒ‡å®šåæ ‡ç³»: {coordinate_system}")
            if enable_transparency:
                print(f"å¯ç”¨é€æ˜åº¦è®¾ç½®ï¼šå°†è®¾ç½®é»‘è‰²èƒŒæ™¯ä¸ºé€æ˜")
            
            # ä¿®å¤æ–‡ä»¶è·¯å¾„é—®é¢˜
            corrected_path = self._correct_path(tif_path)
            print(f"ä¿®æ­£åçš„æ–‡ä»¶è·¯å¾„: {corrected_path}")
            
            # æ ¹æ®æ–‡ä»¶åç”Ÿæˆstoreåç§°ï¼ˆæ–‡ä»¶å_storeæ ¼å¼ï¼‰
            import os
            filename = os.path.splitext(os.path.basename(corrected_path))[0]
            # æ¸…ç†æ–‡ä»¶åï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œä¸­åˆ’çº¿
            import re
            clean_filename = re.sub(r'[^a-zA-Z0-9_\-\u4e00-\u9fff]', '_', filename)
            generated_store_name = f"{clean_filename}_store"
            print(f"è‡ªåŠ¨ç”Ÿæˆçš„å­˜å‚¨åç§°: {generated_store_name}")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºDOMæ–‡ä»¶ï¼Œè‡ªåŠ¨å¯ç”¨é€æ˜åº¦
            is_dom_file = 'dom' in filename.lower()
            if is_dom_file:
                enable_transparency = True
                print(f"æ£€æµ‹åˆ°DOMæ–‡ä»¶ï¼Œè‡ªåŠ¨å¯ç”¨é€æ˜åº¦è®¾ç½®")
            
            # è·å–å·¥ä½œç©ºé—´ID
            workspace_id = self._get_workspace_id()
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»å‘å¸ƒ - æ£€æŸ¥æ•°æ®åº“ä¸­çš„è®°å½•
            print(f"æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸å…³å‘å¸ƒè®°å½•...")
            existing_check_sql = """
            SELECT gl.id as layer_id, gl.name as layer_name, 
                   gs.id as store_id, gs.name as store_name,
                   gcov.id as coverage_id
            FROM geoserver_layers gl
            LEFT JOIN geoserver_coverages gcov ON gl.coverage_id = gcov.id
            LEFT JOIN geoserver_stores gs ON gcov.store_id = gs.id
            WHERE gl.file_id = %s OR gs.name = %s
            """
            existing_records = execute_query(existing_check_sql, (file_id, generated_store_name))
            
            if existing_records:
                existing_record = existing_records[0]
                print(f"âš ï¸ å‘ç°å·²å­˜åœ¨çš„å‘å¸ƒè®°å½•:")
                print(f"  å›¾å±‚ID: {existing_record['layer_id']}, å›¾å±‚å: {existing_record['layer_name']}")
                print(f"  å­˜å‚¨ID: {existing_record['store_id']}, å­˜å‚¨å: {existing_record['store_name']}")
                
                # å¦‚æœéœ€è¦æ›´æ–°é€æ˜åº¦è®¾ç½®ï¼Œå…ˆæ›´æ–°ç°æœ‰çš„å‘å¸ƒ
                if enable_transparency:
                    try:
                        self._update_coverage_transparency(generated_store_name, existing_record['layer_name'])
                        print(f"âœ… å·²æ›´æ–°ç°æœ‰å‘å¸ƒçš„é€æ˜åº¦è®¾ç½®")
                    except Exception as trans_error:
                        print(f"âš ï¸ æ›´æ–°ç°æœ‰å‘å¸ƒé€æ˜åº¦å¤±è´¥: {str(trans_error)}")
                
                # è¿”å›å·²å­˜åœ¨çš„å‘å¸ƒä¿¡æ¯ï¼Œè€Œä¸æ˜¯æŠ¥é”™
                return {
                    "success": True,
                    "message": "æ–‡ä»¶å·²å‘å¸ƒï¼Œè¿”å›ç°æœ‰å‘å¸ƒä¿¡æ¯",
                    "existing": True,
                    "store_name": existing_record['store_name'],
                    "layer_name": existing_record['layer_name'],
                    "layer_id": existing_record['layer_id'],
                    "coordinate_system": coordinate_system,
                    "transparency_enabled": enable_transparency
                }
            
            # é¢„æ¸…ç†ï¼šåˆ é™¤å¯èƒ½å­˜åœ¨çš„åŒåcoveragestoreï¼ˆGeoServerä¸­çš„æ®‹ç•™ï¼‰
            print(f"é¢„æ¸…ç†ï¼šæ£€æŸ¥å¹¶åˆ é™¤å¯èƒ½å­˜åœ¨çš„åŒåcoveragestore")
            self._cleanup_existing_coveragestore(generated_store_name)
            
            # 1. åˆ›å»ºè¦†ç›–å­˜å‚¨è®°å½•
            store_id = self._create_coveragestore_in_db(generated_store_name, workspace_id, 'GeoTIFF', file_id)
            print(f"âœ… è¦†ç›–å­˜å‚¨è®°å½•åˆ›å»ºæˆåŠŸï¼Œstore_id={store_id}")
            
            # 2. ä¸Šä¼ GeoTIFFåˆ°GeoServerï¼ˆå¦‚æœå¯ç”¨é€æ˜åº¦ï¼Œä½¿ç”¨ImageMosaicç±»å‹ï¼‰
            upload_success = False
            max_retries = 2
            
            # å…ˆæ£€æŸ¥GeoServerä¸­æ˜¯å¦å·²å­˜åœ¨coveragestore
            check_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{generated_store_name}"
            check_response = requests.get(check_url, auth=self.auth)
            
            if check_response.status_code == 200:
                print(f"âœ… GeoServerä¸­çš„coveragestoreå·²å­˜åœ¨ï¼Œç›´æ¥ä¸Šä¼ æ–‡ä»¶")
                coveragestore_exists = True
            else:
                print(f"GeoServerä¸­çš„coveragestoreä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»º")
                coveragestore_exists = False
            
            for attempt in range(max_retries):
                try:
                    print(f"å°è¯•ä¸Šä¼ GeoTIFFåˆ°GeoServer (ç¬¬{attempt + 1}æ¬¡)")
                    
                    # åªæœ‰å½“coveragestoreä¸å­˜åœ¨æ—¶æ‰åˆ›å»º
                    if not coveragestore_exists:
                        print(f"åˆ›å»ºç©ºçš„coveragestore")
                        print(f"ä½¿ç”¨æ ‡å‡†GeoTIFFæ–¹æ¡ˆ")
                        self._create_empty_coveragestore_for_existing_file(generated_store_name, corrected_path)
                        
                        print(f"âœ… ç©ºcoveragestoreåˆ›å»ºæˆåŠŸ")
                        coveragestore_exists = True
                    else:
                        print(f"è·³è¿‡coveragestoreåˆ›å»ºæ­¥éª¤ï¼ˆå·²å­˜åœ¨ï¼‰")
                    
                    # ä¸Šä¼ æ–‡ä»¶ - ç»Ÿä¸€ä½¿ç”¨æ ‡å‡†æ–¹å¼
                    print(f"å¼€å§‹ä¸Šä¼ GeoTIFFæ–‡ä»¶...")
                    self._upload_geotiff_to_geoserver(corrected_path, generated_store_name)
                    print(f"âœ… GeoTIFFæ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
                    
                    upload_success = True
                    break
                    
                except Exception as upload_error:
                    print(f"âŒ ç¬¬{attempt + 1}æ¬¡ä¸Šä¼ å¤±è´¥: {str(upload_error)}")
                    if attempt < max_retries - 1:
                        print(f"ç­‰å¾…2ç§’åé‡è¯•...")
                        #time.sleep(2)
                        # é‡è¯•æ—¶ä¸éœ€è¦é‡æ–°åˆ›å»ºcoveragestore
                    else:
                        print(f"æ‰€æœ‰ä¸Šä¼ å°è¯•å‡å¤±è´¥")
                        raise upload_error
            
            if not upload_success:
                raise Exception("GeoTIFFä¸Šä¼ å¤±è´¥")
            
            # 3. ç­‰å¾…GeoServerå¤„ç†
            #time.sleep(3)
            
            # 4. è·å–è¦†ç›–ä¿¡æ¯
            coverage_info = self._get_coverage_info(generated_store_name)
            print(f"âœ… è·å–è¦†ç›–ä¿¡æ¯æˆåŠŸ")
            
            # 5. å¦‚æœç”¨æˆ·æŒ‡å®šäº†åæ ‡ç³»ï¼Œæ›´æ–°è¦†ç›–ä¿¡æ¯ä¸­çš„åæ ‡ç³»
            if coordinate_system:
                print(f"æ›´æ–°åæ ‡ç³»ä¸º: {coordinate_system}")
                # æ›´æ–°coverageä¿¡æ¯ä¸­çš„åæ ‡ç³»
                if 'featureType' in coverage_info:
                    coverage_info['featureType']['srs'] = coordinate_system
                elif 'coverage' in coverage_info:
                    coverage_info['coverage']['srs'] = coordinate_system
                else:
                    # å¦‚æœç»“æ„ä¸æ ‡å‡†ï¼Œåˆ›å»ºæ ‡å‡†ç»“æ„
                    coverage_info = {
                        "featureType": {
                            "name": generated_store_name,
                            "nativeName": generated_store_name,
                            "title": generated_store_name,
                            "abstract": f"ä»è¦†ç›–å­˜å‚¨ {generated_store_name} å‘å¸ƒçš„è¦†ç›–",
                            "enabled": True,
                            "srs": coordinate_system,
                            "store": {
                                "@class": "coverageStore",
                                "name": f"{self.workspace}:{generated_store_name}"
                            }
                        }
                    }
                
                # é€šè¿‡REST APIæ›´æ–°GeoServerä¸­çš„åæ ‡ç³»è®¾ç½®
                try:
                    self._update_coverage_coordinate_system(generated_store_name, coordinate_system)
                    print(f"âœ… GeoServerä¸­çš„åæ ‡ç³»å·²æ›´æ–°ä¸º: {coordinate_system}")
                except Exception as srs_error:
                    print(f"âš ï¸ æ›´æ–°GeoServeråæ ‡ç³»å¤±è´¥: {str(srs_error)}")
                    # ä¸ä¸­æ–­å‘å¸ƒæµç¨‹ï¼Œä»…è®°å½•è­¦å‘Š
            
            # 6. è®¾ç½®é€æ˜åº¦å‚æ•°ï¼ˆåœ¨coverageåˆ›å»ºä¹‹åï¼‰
            if enable_transparency:
                try:
                    self._configure_coverage_transparency(generated_store_name)
                    print(f"âœ… é€æ˜åº¦è®¾ç½®é…ç½®æˆåŠŸ")
                except Exception as trans_error:
                    print(f"âš ï¸ é€æ˜åº¦è®¾ç½®å¤±è´¥: {str(trans_error)}")
                    # ä¸ä¸­æ–­å‘å¸ƒæµç¨‹ï¼Œä»…è®°å½•è­¦å‘Š
            
            # 7. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦†ç›–è®°å½•
            coverage_id = self._create_coverage_in_db(coverage_info, store_id)
            print(f"âœ… è¦†ç›–è®°å½•åˆ›å»ºæˆåŠŸï¼Œcoverage_id={coverage_id}")
            
            # 8. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦†ç›–å›¾å±‚è®°å½•
            layer_info = self._create_layer_in_db(coverage_info, workspace_id, featuretype_id=None, coverage_id=coverage_id, file_id=file_id, store_type='coveragestore')
            print(f"âœ… è¦†ç›–å›¾å±‚è®°å½•åˆ›å»ºæˆåŠŸï¼Œlayer_id={layer_info['id']}")
            
            # 9. è¿”å›æœåŠ¡ä¿¡æ¯
            return {
                "success": True,
                "store_name": generated_store_name,  # è¿”å›ç”Ÿæˆçš„storeåç§°
                "layer_name": layer_info['full_name'],
                "wms_url": layer_info['wms_url'],
                "layer_info": layer_info,
                "filename": filename,
                "coordinate_system": coordinate_system or coverage_info.get('featureType', {}).get('srs', 'EPSG:4326'),
                "transparency_enabled": enable_transparency
            }
            
        except Exception as e:
            print(f"å‘å¸ƒGeoTIFFå¤±è´¥: {str(e)}")
            # æ¸…ç†å¯èƒ½åˆ›å»ºçš„èµ„æº
            cleanup_store_name = generated_store_name if 'generated_store_name' in locals() else store_name
            self._cleanup_failed_publish(cleanup_store_name, 'coveragestore')
            raise Exception(f"å‘å¸ƒGeoTIFFå¤±è´¥: {str(e)}")
    
    def _update_coverage_coordinate_system(self, store_name, coordinate_system):
        """æ›´æ–°è¦†ç›–çš„åæ ‡ç³»è®¾ç½®"""
        try:
            # è·å–è¦†ç›–åç§°
            coverages_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages.json"
            response = requests.get(coverages_url, auth=self.auth)
            
            if response.status_code != 200:
                raise Exception(f"è·å–è¦†ç›–åˆ—è¡¨å¤±è´¥: {response.text}")
                
            coverages_data = response.json()
            coverage_name = None
            
            if 'coverages' in coverages_data and 'coverage' in coverages_data['coverages']:
                coverages = coverages_data['coverages']['coverage']
                if isinstance(coverages, list) and len(coverages) > 0:
                    coverage_name = coverages[0]['name']
                elif isinstance(coverages, dict):
                    coverage_name = coverages['name']
            
            if not coverage_name:
                coverage_name = store_name
            
            # æ›´æ–°è¦†ç›–çš„åæ ‡ç³»
            coverage_update_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages/{coverage_name}.json"
            
            # æ„å»ºæ›´æ–°æ•°æ®
            update_data = {
                "coverage": {
                    "srs": coordinate_system,
                    "enabled": True
                }
            }
            
            headers = {'Content-Type': 'application/json'}
            update_response = requests.put(
                coverage_update_url,
                json=update_data,
                auth=self.auth,
                headers=headers
            )
            
            if update_response.status_code not in [200, 201]:
                print(f"âš ï¸ åæ ‡ç³»æ›´æ–°å“åº”: {update_response.status_code} - {update_response.text}")
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªæ˜¯è®°å½•è­¦å‘Š
            else:
                print(f"âœ… åæ ‡ç³»æ›´æ–°æˆåŠŸ")
                
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°åæ ‡ç³»å¤±è´¥: {str(e)}")
            # ä¸ä¸­æ–­å‘å¸ƒæµç¨‹
    
    def publish_geojson(self, geojson_path, store_name, file_id):
        """å‘å¸ƒGeoJSONæœåŠ¡ - é€šè¿‡PostGISæ•°æ®åº“
        
        é‡‡ç”¨GeoServerå®˜æ–¹æ¨èçš„æœ€ä½³å®è·µï¼š
        1. éªŒè¯GeoJSONæ–‡ä»¶
        2. å°†GeoJSONæ•°æ®å¯¼å…¥PostGISæ•°æ®åº“
        3. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºstoreè®°å½•
        4. åˆ›å»ºPostGISæ•°æ®æºï¼ˆåŒ…å«å®Œæ•´è¿æ¥å‚æ•°ï¼‰
        5. ä»PostGISå‘å¸ƒè¦ç´ ç±»å‹
        6. åˆ›å»ºfeaturetypeå’Œlayeræ•°æ®åº“è®°å½•
        7. éªŒè¯å‘å¸ƒç»“æœ
        
        æ”¯æŒæ··åˆå‡ ä½•ç±»å‹ï¼šå½“GeoJSONåŒ…å«å¤šç§å‡ ä½•ç±»å‹æ—¶ï¼Œ
        ä¼šè‡ªåŠ¨åˆ†ç¦»ä¸ºå¤šä¸ªè¡¨å’Œå›¾å±‚
        
        Args:
            geojson_path: GeoJSONæ–‡ä»¶è·¯å¾„
            store_name: æ•°æ®å­˜å‚¨åç§°ï¼ˆå°†è¢«é‡æ–°ç”Ÿæˆä¸º"æ–‡ä»¶å_store"æ ¼å¼ï¼‰
            file_id: æ–‡ä»¶ID
            
        Returns:
            å‘å¸ƒç»“æœä¿¡æ¯
        """
        try:
            print(f"\n=== å¼€å§‹å‘å¸ƒGeoJSONæœåŠ¡ï¼ˆPostGISæ–¹æ¡ˆï¼‰ ===")
            print(f"æ–‡ä»¶è·¯å¾„: {geojson_path}")
            print(f"æ–‡ä»¶ID: {file_id}")
            
            # 1. ä¿®æ­£å’ŒéªŒè¯æ–‡ä»¶è·¯å¾„
            corrected_path = self._correct_path(geojson_path)
            print(f"ä¿®æ­£åçš„æ–‡ä»¶è·¯å¾„: {corrected_path}")
            
            # 2. æ ¹æ®æ–‡ä»¶åç”Ÿæˆstoreåç§°ï¼ˆæ–‡ä»¶å_storeæ ¼å¼ï¼‰
            import os
            filename = os.path.splitext(os.path.basename(corrected_path))[0]
            # æ¸…ç†æ–‡ä»¶åï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œä¸­åˆ’çº¿
            import re
            clean_filename = re.sub(r'[^a-zA-Z0-9_\-\u4e00-\u9fff]', '_', filename)
            generated_store_name = f"{clean_filename}_store"
            print(f"è‡ªåŠ¨ç”Ÿæˆçš„å­˜å‚¨åç§°: {generated_store_name}")
            
            # 3. éªŒè¯GeoJSONæ–‡ä»¶æ ¼å¼
            self._validate_geojson_file(corrected_path)
            print("âœ… GeoJSONæ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
            
            # 4. è·å–å·¥ä½œç©ºé—´ID
            workspace_id = self._get_workspace_id()
            print(f"å·¥ä½œç©ºé—´ID: {workspace_id}")
            
            # 5. æ£€æŸ¥æ˜¯å¦å·²ç»å‘å¸ƒ - æ£€æŸ¥æ•°æ®åº“ä¸­çš„è®°å½•
            print(f"æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸å…³å‘å¸ƒè®°å½•...")
            existing_check_sql = """
            SELECT gl.id as layer_id, gl.name as layer_name, 
                   gs.id as store_id, gs.name as store_name,
                   gft.id as featuretype_id
            FROM geoserver_layers gl
            LEFT JOIN geoserver_featuretypes gft ON gl.featuretype_id = gft.id
            LEFT JOIN geoserver_stores gs ON gft.store_id = gs.id
            WHERE gl.file_id = %s OR gs.name = %s
            """
            existing_records = execute_query(existing_check_sql, (file_id, generated_store_name))
            
            if existing_records:
                existing_record = existing_records[0]
                print(f"âš ï¸ å‘ç°å·²å­˜åœ¨çš„å‘å¸ƒè®°å½•:")
                print(f"  å›¾å±‚ID: {existing_record['layer_id']}, å›¾å±‚å: {existing_record['layer_name']}")
                print(f"  å­˜å‚¨ID: {existing_record['store_id']}, å­˜å‚¨å: {existing_record['store_name']}")
                
                # è¿”å›å·²å­˜åœ¨çš„å‘å¸ƒä¿¡æ¯ï¼Œè€Œä¸æ˜¯æŠ¥é”™
                return {
                    "success": True,
                    "message": "æ–‡ä»¶å·²å‘å¸ƒï¼Œè¿”å›ç°æœ‰å‘å¸ƒä¿¡æ¯",
                    "existing": True,
                    "store_name": existing_record['store_name'],
                    "layer_name": existing_record['layer_name'],
                    "layer_id": existing_record['layer_id']
                }
            
            # 6. é¢„æ¸…ç†ï¼šåˆ é™¤å¯èƒ½å­˜åœ¨çš„åŒådatastoreï¼ˆGeoServerä¸­çš„æ®‹ç•™ï¼‰
            print(f"é¢„æ¸…ç†ï¼šæ£€æŸ¥å¹¶åˆ é™¤å¯èƒ½å­˜åœ¨çš„åŒådatastore")
            self._cleanup_existing_datastore(generated_store_name)
            
            # 7. å°†GeoJSONå¯¼å…¥PostGISæ•°æ®åº“
            print("\n--- å°†GeoJSONå¯¼å…¥PostGISæ•°æ®åº“ ---")
            from services.postgis_service import PostGISService
            postgis_service = PostGISService()
            
            postgis_result = postgis_service.store_geojson(corrected_path, file_id)
            print(f"âœ… GeoJSONå·²å¯¼å…¥åˆ°PostGIS")
            
            # 8. æ£€æŸ¥æ˜¯å¦ä¸ºæ··åˆå‡ ä½•ç±»å‹
            if postgis_result.get('is_mixed', False):
                print(f"ğŸ”„ å¤„ç†æ··åˆå‡ ä½•ç±»å‹ï¼Œå‘ç° {len(postgis_result['geometry_types'])} ç§å‡ ä½•ç±»å‹: {postgis_result['geometry_types']}")
                # æ–°æ–¹æ¡ˆï¼šæ··åˆå‡ ä½•ç±»å‹ä¹Ÿä½¿ç”¨å•ä¸€è¡¨ï¼Œä¸éœ€è¦ç‰¹æ®Šå¤„ç†
                table_name = postgis_result['table_name']
                print(f"ğŸ“Š æ··åˆå‡ ä½•ç±»å‹ï¼Œå¤„ç†è¡¨: {table_name}")
                result = self._handle_single_geometry_publishing(
                    postgis_result, generated_store_name, workspace_id, file_id, filename, table_name
                )
                # æ·»åŠ æ··åˆå‡ ä½•ç±»å‹æ ‡è®°
                result['is_mixed'] = True
                result['geometry_types'] = postgis_result['geometry_types']
            else:
                # å•ä¸€å‡ ä½•ç±»å‹ï¼ŒæŒ‰åŸæµç¨‹å¤„ç†
                table_name = postgis_result['table_name']
                print(f"ğŸ“Š å•ä¸€å‡ ä½•ç±»å‹ï¼Œå¤„ç†è¡¨: {table_name}")
                result = self._handle_single_geometry_publishing(
                    postgis_result, generated_store_name, workspace_id, file_id, filename, table_name
                )
            
            print(f"\nâœ… GeoJSONæœåŠ¡å‘å¸ƒæˆåŠŸ!")
            return result
            
        except Exception as e:
            print(f"âŒ å‘å¸ƒGeoJSONæœåŠ¡å¤±è´¥: {str(e)}")
            
            # æ¸…ç†å¯èƒ½åˆ›å»ºçš„èµ„æº
            try:
                print("å¼€å§‹æ¸…ç†å¯èƒ½åˆ›å»ºçš„èµ„æº...")
                cleanup_store_name = generated_store_name if 'generated_store_name' in locals() else store_name
                # æ–°æ–¹æ¡ˆï¼šæ— è®ºæ˜¯å¦ä¸ºæ··åˆå‡ ä½•ç±»å‹ï¼Œéƒ½åªæœ‰ä¸€ä¸ªè¡¨éœ€è¦æ¸…ç†
                tables_to_cleanup = []
                if 'postgis_result' in locals() and postgis_result:
                    table_name = postgis_result.get('table_name')
                    if table_name:
                        tables_to_cleanup.append(table_name)
                
                for table_name in tables_to_cleanup:
                    self._cleanup_failed_geojson_publish(cleanup_store_name, table_name)
                    
            except Exception as cleanup_error:
                print(f"âš ï¸ æ¸…ç†èµ„æºå¤±è´¥: {str(cleanup_error)}")
            
            import traceback
            traceback.print_exc()
            raise Exception(f"å‘å¸ƒGeoJSONæœåŠ¡å¤±è´¥: {str(e)}")
    
    def _handle_single_geometry_publishing(self, postgis_result, store_name, workspace_id, file_id, filename, table_name):
        """å¤„ç†å•ä¸€å‡ ä½•ç±»å‹çš„å‘å¸ƒ
        
        Args:
            postgis_result: PostGISå¤„ç†ç»“æœ
            store_name: storeåç§°
            workspace_id: å·¥ä½œç©ºé—´ID
            file_id: æ–‡ä»¶ID
            filename: åŸå§‹æ–‡ä»¶å
            table_name: è¡¨å
            
        Returns:
            å‘å¸ƒç»“æœä¿¡æ¯
        """
        print(f"\n--- å¤„ç†å•ä¸€å‡ ä½•ç±»å‹å‘å¸ƒ: {table_name} ---")
        
        # 1. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºæ•°æ®å­˜å‚¨è®°å½•ï¼ˆå¿…é¡»åœ¨GeoServeræ“ä½œä¹‹å‰ï¼‰
        print("--- åˆ›å»ºæ•°æ®åº“storeè®°å½• ---")
        store_id = self._create_datastore_in_db(store_name, workspace_id, 'PostGIS', file_id)
        print(f"âœ… æ•°æ®å­˜å‚¨è®°å½•åˆ›å»ºæˆåŠŸï¼Œstore_id={store_id}")
        
        # 2. åœ¨GeoServerä¸­åˆ›å»ºPostGISæ•°æ®æº
        print("--- åˆ›å»ºPostGISæ•°æ®æº ---")
        self._create_postgis_datastore(store_name)
        print(f"âœ… PostGISæ•°æ®æºåˆ›å»ºæˆåŠŸ: {store_name}")
        
        # 3. ä»PostGISå‘å¸ƒè¦ç´ ç±»å‹
        print("--- å‘å¸ƒè¦ç´ ç±»å‹ ---")
        featuretype_info = self._publish_featuretype_from_postgis(
            store_name, 
            table_name, 
            table_name  # ä½¿ç”¨è¡¨åä½œä¸ºè¦ç´ ç±»å‹åç§°
        )
        print(f"âœ… è¦ç´ ç±»å‹å‘å¸ƒæˆåŠŸ: {featuretype_info['featureType']['name']}")
        
        # 4. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦ç´ ç±»å‹å’Œå›¾å±‚è®°å½•
        print("--- åˆ›å»ºæ•°æ®åº“featuretypeå’Œlayerè®°å½• ---")
        
        # åˆ›å»ºè¦ç´ ç±»å‹è®°å½•
        featuretype_id = self._create_featuretype_in_db(featuretype_info, store_id)
        print(f"âœ… è¦ç´ ç±»å‹è®°å½•åˆ›å»ºæˆåŠŸï¼Œfeaturetype_id={featuretype_id}")
        
        # åˆ›å»ºå›¾å±‚è®°å½•
        layer_info = self._create_layer_in_db(featuretype_info, workspace_id, featuretype_id,coverage_id=None, file_id=file_id, store_type='datastore')
        print(f"âœ… å›¾å±‚è®°å½•åˆ›å»ºæˆåŠŸï¼Œlayer_id={layer_info['id']}")
        
        # 5. éªŒè¯å‘å¸ƒç»“æœ
        print("--- éªŒè¯å‘å¸ƒç»“æœ ---")
        full_layer_name = layer_info['full_name']
        if self.verify_layer_exists(full_layer_name):
            print(f"âœ… å›¾å±‚éªŒè¯æˆåŠŸ: {full_layer_name}")
        else:
            print(f"âš ï¸ å›¾å±‚éªŒè¯å¤±è´¥ï¼Œä½†å°†ç»§ç»­: {full_layer_name}")
        
        # 6. æ„å»ºè¿”å›ç»“æœ
        result = {
            "success": True,
            "is_mixed": False,
            "store_name": store_name,
            "layer_name": full_layer_name,
            "wms_url": layer_info['wms_url'],
            "wfs_url": layer_info['wfs_url'],
            "layer_info": layer_info,
            "postgis_table": table_name,
            "filename": filename,
            "geometry_type": postgis_result['feature_info']['geometry_type'],
            "feature_count": postgis_result['feature_info']['feature_count'],
            "preview_url": f"{self.url}/wms?service=WMS&version=1.1.0&request=GetMap&layers={full_layer_name}&styles=&bbox=-180,-90,180,90&width=768&height=384&srs=EPSG:4326&format=image/png"
        }
        
        print(f"   - å­˜å‚¨åç§°: {result['store_name']}")
        print(f"   - å›¾å±‚åç§°: {result['layer_name']}")
        print(f"   - WMSæœåŠ¡: {result['wms_url']}")
        print(f"   - WFSæœåŠ¡: {result['wfs_url']}")
        print(f"   - PostGISè¡¨: {result['postgis_table']}")
        
        return result
    
    def _correct_path(self, file_path):
        """ä¿®æ­£æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†è·¨å¹³å°è·¯å¾„åˆ†éš”ç¬¦"""
        import os
        
        print(f"åŸå§‹è·¯å¾„: {file_path}")
        
        # å°†æ‰€æœ‰åæ–œæ æ›¿æ¢ä¸ºæ­£æ–œæ ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
        corrected_path = file_path.replace('\\', '/')
        print(f"æ›¿æ¢åˆ†éš”ç¬¦å: {corrected_path}")
        
        # æ ‡å‡†åŒ–è·¯å¾„
        normalized_path = os.path.normpath(corrected_path)
        print(f"æ ‡å‡†åŒ–è·¯å¾„ {normalized_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(normalized_path):
            print(f"æ–‡ä»¶å­˜åœ¨: {normalized_path}")
            return normalized_path
        else:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨ {normalized_path}")
            # å¦‚æœæ ‡å‡†åŒ–è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨åŸå§‹è·¯å¾„çš„æ ‡å‡†åŒ–ç‰ˆæœ¬
            alt_path = os.path.normpath(file_path)
            print(f"å°è¯•å¤‡ç”¨è·¯å¾„: {alt_path}")
            if os.path.exists(alt_path):
                print(f"å¤‡ç”¨è·¯å¾„å­˜åœ¨: {alt_path}")
                return alt_path
            else:
                print(f"å¤‡ç”¨è·¯å¾„ä¹Ÿä¸å­˜åœ¨: {alt_path}")
                raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ°æ–‡ä»¶: {file_path}")
        
        return normalized_path
    
    def _get_workspace_id(self):
        """è·å–å·¥ä½œç©ºé—´ID"""
        sql = "SELECT id FROM geoserver_workspaces WHERE name = %s"
        result = execute_query(sql, (self.workspace,))
        if not result:
            raise Exception(f"å·¥ä½œç©ºé—´ {self.workspace} ä¸å­˜åœ¨")
        return result[0]['id']
    
    def _create_datastore_in_db(self, store_name, workspace_id, data_type, file_id):
        """åœ¨æ•°æ®åº“ä¸­åˆ›å»ºæ•°æ®å­˜å‚¨è®°å½•
        
        Args:
            store_name: å­˜å‚¨åç§°
            workspace_id: å·¥ä½œç©ºé—´ID
            data_type: æ•°æ®ç±»å‹
            file_id: æ–‡ä»¶ID
            
        Returns:
            å­˜å‚¨ID
        """
        try:
            store_params = {
                'name': store_name,
                'workspace_id': workspace_id,
                'store_type': 'datastore',
                'data_type': data_type,
                'description': f"{data_type} datastore",
                'enabled': True,
                'file_id': file_id,
                'connection_params': json.dumps({'file': store_name})
            }
            
            store_id = insert_with_snowflake_id('geoserver_stores', store_params)
            return store_id
        except Exception as e:
            print(f"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºæ•°æ®å­˜å‚¨è®°å½•å¤±è´¥: {str(e)}")
            raise
    
    def _create_coveragestore_in_db(self, store_name, workspace_id, data_type, file_id):
        """åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦†ç›–å­˜å‚¨è®°å½•
        
        Args:
            store_name: å­˜å‚¨åç§°
            workspace_id: å·¥ä½œç©ºé—´ID
            data_type: æ•°æ®ç±»å‹
            file_id: æ–‡ä»¶ID
            
        Returns:
            å­˜å‚¨ID
        """
        try:
            store_params = {
                'name': store_name,
                'workspace_id': workspace_id,
                'store_type': 'coveragestore',
                'data_type': data_type,
                'description': f"{data_type} coveragestore",
                'enabled': True,
                'file_id': file_id,
                'connection_params': json.dumps({'file': store_name})
            }
            
            store_id = insert_with_snowflake_id('geoserver_stores', store_params)
            return store_id
        except Exception as e:
            print(f"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦†ç›–å­˜å‚¨è®°å½•å¤±è´¥: {str(e)}")
            raise
    
    def _create_coverage_in_db(self, coverage_info, store_id):
        """åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦†ç›–èŒƒå›´è®°å½•
        
        Args:
            coverage_info: è¦†ç›–èŒƒå›´ä¿¡æ¯
            store_id: å­˜å‚¨ID
            
        Returns:
            è¦†ç›–èŒƒå›´ID
        """
        try:
            # å¤„ç†æ•°æ®ç»“æ„ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼šcoverageå’ŒfeatureType
            if 'coverage' in coverage_info:
                coverage_data = coverage_info['coverage']
            elif 'featureType' in coverage_info:
                # ä»featureTypeç»“æ„ä¸­æå–coverageä¿¡æ¯
                coverage_data = coverage_info['featureType']
            else:
                raise Exception("æ— æ•ˆçš„è¦†ç›–ä¿¡æ¯ç»“æ„")
            
            coverage_params = {
                'name': coverage_data['name'],
                'native_name': coverage_data['name'],
                'store_id': store_id,
                'title': coverage_info.get('title', coverage_data['name']),
                'abstract': coverage_info.get('abstract', ''),
                'keywords': coverage_info.get('keywords', []),
                'srs': coverage_info.get('srs', 'EPSG:4326'),
                'enabled': True
            }
            
            coverage_id = insert_with_snowflake_id('geoserver_coverages', coverage_params)
            return coverage_id
        except Exception as e:
            print(f"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦†ç›–èŒƒå›´è®°å½•å¤±è´¥: {str(e)}")
            raise
    
    def publish_dwg_dxf(self, file_path, store_name, coord_system):
        """å‘å¸ƒDWG/DXFæœåŠ¡
        
        Args:
            file_path: DWG/DXFæ–‡ä»¶è·¯å¾„
            store_name: æ•°æ®å­˜å‚¨åç§°
            coord_system: åæ ‡ç³»ç»Ÿ(å¦‚EPSG:4326")
            
        Returns:
            æœåŠ¡URL
        """
        # æš‚æ—¶ä¸æ”¯æŒDWG/DXFæ ¼å¼çš„ç›´æ¥å‘å¸ƒåˆ°GeoServerï¼Œéœ€è¦å¤–éƒ¨å·¥å…·è¿›è¡Œæ ¼å¼è½¬æ¢
        raise Exception("DWG/DXFæ ¼å¼æš‚æ—¶ä¸æ”¯æŒè‡ªåŠ¨å‘å¸ƒåˆ°GeoServerï¼Œè¯·å…ˆè½¬æ¢ä¸ºShapefileæˆ–GeoJSONæ ¼å¼")
    
    def delete_layer(self, store_name, store_type="datastore"):
        """åˆ é™¤å›¾å±‚
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
            store_type: å­˜å‚¨ç±»å‹(datastoreæˆ–coveragestore)
        """
        if store_type == "datastore":
            url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}?recurse=true"
        else:
            url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}?recurse=true"
        
        response = requests.delete(url, auth=self.auth)
        
        if response.status_code not in [200, 404]:
            raise Exception(f"åˆ é™¤å›¾å±‚å¤±è´¥: {response.text}")
        
        return True
    
    def unpublish_layer(self, layer_id):
        """å–æ¶ˆå‘å¸ƒå›¾å±‚
        
        Args:
            layer_id: å›¾å±‚ID
        
        Returns:
            bool: å–æ¶ˆå‘å¸ƒç»“æœ
        """
        try:
            print(f"å¼€å§‹å–æ¶ˆå‘å¸ƒå›¾å±‚: layer_id={layer_id}")
            
            # 1. ä»æ•°æ®åº“è·å–å›¾å±‚ä¿¡æ¯
            layer_sql = """
            SELECT gl.*, gs.name as store_name, gs.data_type as store_type 
            FROM geoserver_layers gl 
            LEFT JOIN geoserver_featuretypes gf ON gl.featuretype_id = gf.id 
            LEFT JOIN geoserver_stores gs ON gf.store_id = gs.id 
            WHERE gl.id = %s
            UNION
            SELECT gl.*, gcs.name as store_name, gcs.data_type as store_type 
            FROM geoserver_layers gl 
            LEFT JOIN geoserver_coverages gc ON gl.coverage_id = gc.id 
            LEFT JOIN geoserver_stores gcs ON gc.store_id = gcs.id 
            WHERE gl.id = %s
            """
            layer_result = execute_query(layer_sql, (layer_id, layer_id))
            
            if not layer_result:
                print(f"âš ï¸ å›¾å±‚ä¸å­˜åœ¨: layer_id={layer_id}")
                return False
            
            layer_info = layer_result[0]
            store_name = layer_info.get('store_name')
            store_type = layer_info.get('store_type', 'Shapefile')
            layer_name = layer_info.get('name')
            
            print(f"å›¾å±‚ä¿¡æ¯: name={layer_name}, store_name={store_name}, store_type={store_type}")
            
            # 2. ä»GeoServerä¸­åˆ é™¤å›¾å±‚å’Œæ•°æ®å­˜å‚¨
            if store_name:
                # æ ¹æ®å­˜å‚¨ç±»å‹ç¡®å®šåˆ é™¤çš„URL
                if store_type in ['GeoTIFF', 'WorldImage']:
                    # æ …æ ¼æ•°æ®ï¼Œä½¿ç”¨coveragestoreï¼Œè°ƒç”¨å¢å¼ºæ¸…ç†æ–¹æ³•
                    print(f"å¼€å§‹åˆ é™¤coveragestore: {store_name}")
                    self._cleanup_existing_coveragestore(store_name)
                else:
                    # çŸ¢é‡æ•°æ®ï¼Œä½¿ç”¨datastoreï¼Œå¢åŠ purge=allå‚æ•°åˆ é™¤ç‰©ç†æ–‡ä»¶
                    delete_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}?recurse=true&purge=all"
                    print(f"åˆ é™¤GeoServerèµ„æº: {delete_url}")
                    response = requests.delete(delete_url, auth=self.auth)
                    
                    # å¦‚æœä½¿ç”¨purge=allå¤±è´¥ï¼Œå°è¯•å…¶ä»–purgeå‚æ•°å€¼
                    if response.status_code not in [200, 404]:
                        print(f"âš ï¸ ä½¿ç”¨purge=allåˆ é™¤å¤±è´¥ï¼Œå°è¯•å…¶ä»–å‚æ•°")
                        for purge_param in ['true', 'metadata']:
                            alt_delete_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}?recurse=true&purge={purge_param}"
                            print(f"å°è¯•: {alt_delete_url}")
                            alt_response = requests.delete(alt_delete_url, auth=self.auth)
                            if alt_response.status_code in [200, 404]:
                                print(f"âœ… ä½¿ç”¨purge={purge_param}åˆ é™¤æˆåŠŸ")
                                break
                        else:
                            # æœ€åå°è¯•ä¸ä½¿ç”¨purgeå‚æ•°
                            simple_delete_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}?recurse=true"
                            simple_response = requests.delete(simple_delete_url, auth=self.auth)
                            if simple_response.status_code in [200, 404]:
                                print(f"âœ… ä½¿ç”¨åŸºæœ¬å‚æ•°åˆ é™¤æˆåŠŸ")
                            else:
                                print(f"âš ï¸ åˆ é™¤GeoServerèµ„æºå¤±è´¥: {simple_response.status_code} - {simple_response.text}")
                    else:
                        print(f"âœ… GeoServerèµ„æºåˆ é™¤æˆåŠŸ")
            else:
                print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°å­˜å‚¨åç§°ï¼Œè·³è¿‡GeoServeråˆ é™¤")
            
            # 3. ä»æ•°æ®åº“ä¸­åˆ é™¤ç›¸å…³è®°å½•
            print(f"åˆ é™¤æ•°æ®åº“è®°å½•...")
            
            # åˆ é™¤å›¾å±‚è®°å½•
            delete_layer_sql = "DELETE FROM geoserver_layers WHERE id = %s"
            execute_query(delete_layer_sql, (layer_id,), fetch=False)
            print(f"âœ… åˆ é™¤å›¾å±‚è®°å½•: layer_id={layer_id}")
            
            # åˆ é™¤ç›¸å…³çš„è¦ç´ ç±»å‹æˆ–è¦†ç›–è®°å½•
            if layer_info.get('featuretype_id'):
                delete_featuretype_sql = "DELETE FROM geoserver_featuretypes WHERE id = %s"
                execute_query(delete_featuretype_sql, (layer_info['featuretype_id'],), fetch=False)
                print(f"âœ… åˆ é™¤è¦ç´ ç±»å‹è®°å½•: featuretype_id={layer_info['featuretype_id']}")
            
            if layer_info.get('coverage_id'):
                delete_coverage_sql = "DELETE FROM geoserver_coverages WHERE id = %s"
                execute_query(delete_coverage_sql, (layer_info['coverage_id'],), fetch=False)
                print(f"âœ… åˆ é™¤è¦†ç›–è®°å½•: coverage_id={layer_info['coverage_id']}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å›¾å±‚ä½¿ç”¨ç›¸åŒçš„å­˜å‚¨ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ é™¤å­˜å‚¨è®°å½•
            if store_name:
                # æŸ¥æ‰¾ä½¿ç”¨ç›¸åŒå­˜å‚¨çš„å…¶ä»–å›¾å±‚
                check_store_usage_sql = """
                SELECT COUNT(*) as count FROM geoserver_layers gl 
                LEFT JOIN geoserver_featuretypes gf ON gl.featuretype_id = gf.id 
                LEFT JOIN geoserver_stores gs ON gf.store_id = gs.id 
                WHERE gs.name = %s
                UNION ALL
                SELECT COUNT(*) as count FROM geoserver_layers gl 
                LEFT JOIN geoserver_coverages gc ON gl.coverage_id = gc.id 
                LEFT JOIN geoserver_stores gcs ON gc.store_id = gcs.id 
                WHERE gcs.name = %s
                """
                usage_result = execute_query(check_store_usage_sql, (store_name, store_name))
                total_usage = sum(row['count'] for row in usage_result)
                
                if total_usage == 0:
                    # æ²¡æœ‰å…¶ä»–å›¾å±‚ä½¿ç”¨æ­¤å­˜å‚¨ï¼Œå¯ä»¥åˆ é™¤å­˜å‚¨è®°å½•
                    delete_store_sql = "DELETE FROM geoserver_stores WHERE name = %s"
                    execute_query(delete_store_sql, (store_name,), fetch=False)
                    print(f"âœ… åˆ é™¤å­˜å‚¨è®°å½•: store_name={store_name}")
                else:
                    print(f"âš ï¸ å­˜å‚¨ {store_name} ä»è¢«å…¶ä»– {total_usage} ä¸ªå›¾å±‚ä½¿ç”¨ï¼Œä¿ç•™å­˜å‚¨è®°å½•")
            
            print(f"âœ… å›¾å±‚å–æ¶ˆå‘å¸ƒæˆåŠŸ: layer_id={layer_id}")
            return True
            
        except Exception as e:
            error_msg = f"å–æ¶ˆå‘å¸ƒå›¾å±‚å¤±è´¥: {str(e)}"
            print(error_msg)
            raise Exception(error_msg)
    
    def get_layer_info(self, layer_name):
        """è·å–å›¾å±‚ä¿¡æ¯
        
        Args:
            layer_name: å›¾å±‚åç§°
            
        Returns:
            å›¾å±‚ä¿¡æ¯
        """
        url = f"{self.rest_url}/layers/{layer_name}"
        response = requests.get(url, auth=self.auth)
        
        if response.status_code != 200:
            raise Exception(f"è·å–å›¾å±‚ä¿¡æ¯å¤±è´¥: {response.text}")
        
        return response.json()
    
    def _get_actual_layer_name(self, store_name):
        """è·å–æ•°æ®å­˜å‚¨ä¸­çš„å®é™…å›¾å±‚åç§°
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
            
        Returns:
            å®é™…çš„å›¾å±‚å"""
        import time
        
        # ç­‰å¾…ä¸€ä¸‹è®©GeoServerå¤„ç†å®Œæˆ
        time.sleep(2)
        
        try:
            # æŸ¥è¯¢æ•°æ®å­˜å‚¨ä¸­çš„è¦ç´ ç±»å‹ï¼ˆå›¾å±‚ï¼‰
            featuretypes_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/featuretypes.json"
            
            print(f"æ­£åœ¨æŸ¥è¯¢æ•°æ®å­˜å‚¨ {store_name} çš„è¦ç´ ç±»å‹..")
            print(f"è¯·æ±‚URL: {featuretypes_url}")
            
            response = requests.get(featuretypes_url, auth=self.auth)
            
            print(f"è¦ç´ ç±»å‹æŸ¥è¯¢å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"è¦ç´ ç±»å‹æŸ¥è¯¢å“åº”å†…å®¹: {response.text}")
            
            if response.status_code == 200:
                data = response.json()
                
                # è·å–è¦ç´ ç±»å‹åˆ—è¡¨
                if 'featureTypes' in data and 'featureType' in data['featureTypes']:
                    feature_types = data['featureTypes']['featureType']
                    
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªï¼›å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                    if isinstance(feature_types, list) and len(feature_types) > 0:
                        actual_name = feature_types[0]['name']
                        print(f"è·å–åˆ°å®é™…å›¾å±‚å: {actual_name}")
                        return actual_name
                    elif isinstance(feature_types, dict):
                        actual_name = feature_types['name']
                        print(f"è·å–åˆ°å®é™…å›¾å±‚å: {actual_name}")
                        return actual_name
                    else:
                        print(f"âš ï¸ è¦ç´ ç±»å‹æ ¼å¼å¼‚å¸¸: {feature_types}")
                else:
                    print(f"âš ï¸ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°è¦ç´ ç±»å‹ä¿¡æ¯")
                    print(f"å®Œæ•´å“åº”æ•°æ®: {data}")
            else:
                print(f"æŸ¥è¯¢è¦ç´ ç±»å‹å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"é”™è¯¯å“åº”: {response.text}")
            
            # å¦‚æœæ— æ³•è·å–å®é™…åç§°ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨store_nameéªŒè¯
            print(f"å°è¯•ä½¿ç”¨store_nameä½œä¸ºå›¾å±‚åç§°: {store_name}")
            test_layer_name = f"{self.workspace}:{store_name}"
            
            # éªŒè¯å›¾å±‚æ˜¯å¦å­˜åœ¨
            layer_info_url = f"{self.rest_url}/layers/{test_layer_name}.json"
            test_response = requests.get(layer_info_url, auth=self.auth)
            
            if test_response.status_code == 200:
                print(f"éªŒè¯æˆåŠŸï¼Œä½¿ç”¨store_nameä½œä¸ºå›¾å±‚åç§°: {store_name}")
                return store_name
            else:
                print(f"ä½¿ç”¨store_nameéªŒè¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {test_response.status_code}")
                
                # å°è¯•åˆ—å‡ºæ‰€æœ‰å›¾å±‚ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰åŒ¹é…çš„
                layers_url = f"{self.rest_url}/workspaces/{self.workspace}/layers.json"
                layers_response = requests.get(layers_url, auth=self.auth)
                
                if layers_response.status_code == 200:
                    layers_data = layers_response.json()
                    print(f"å·¥ä½œç©ºé—´ä¸­çš„æ‰€æœ‰å›¾å±‚ {layers_data}")
                    
                    # æŸ¥æ‰¾åŒ…å«store_nameçš„å›¾å±‚
                    if 'layers' in layers_data and 'layer' in layers_data['layers']:
                        layers = layers_data['layers']['layer']
                        if isinstance(layers, list):
                            for layer in layers:
                                layer_name = layer['name']
                                if store_name in layer_name or layer_name in store_name:
                                    print(f"æ‰¾åˆ°åŒ¹é…çš„å›¾å±‚: {layer_name}")
                                    return layer_name
                        elif isinstance(layers, dict):
                            layer_name = layers['name']
                            if store_name in layer_name or layer_name in store_name:
                                print(f"æ‰¾åˆ°åŒ¹é…çš„å›¾å±‚: {layer_name}")
                                return layer_name
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›store_nameä½œä¸ºæœ€åçš„å¤‡ä»½
            print(f"âš ï¸ æ— æ³•è·å–å®é™…å›¾å±‚åç§°ï¼Œä½¿ç”¨store_nameä½œä¸ºå¤‡ä»½: {store_name}")
            return store_name
            
        except Exception as e:
            print(f"è·å–å®é™…å›¾å±‚åç§°å¼‚å¸¸: {str(e)}")
            # è¿”å›store_nameä½œä¸ºå¤‡ä»½
            return store_name
    
    def verify_layer_exists(self, layer_name):
        """éªŒè¯å›¾å±‚æ˜¯å¦å­˜åœ¨å¹¶å¯è®¿é—®
        
        Args:
            layer_name: å®Œæ•´çš„å›¾å±‚åç§°ï¼ˆåŒ…å«workspace"""
        import time
        
        # ç­‰å¾…ä¸€ä¸‹è®©GeoServerå¤„ç†å®Œæˆ
        time.sleep(1)
        
        try:
            print(f"å¼€å§‹éªŒè¯å›¾å±‚: {layer_name}")
            
            # æ–¹æ³•1: å°è¯•è·å–å›¾å±‚ä¿¡æ¯
            layer_info_url = f"{self.rest_url}/layers/{layer_name}.json"
            print(f"éªŒè¯URL: {layer_info_url}")
            
            response = requests.get(layer_info_url, auth=self.auth)
            print(f"å›¾å±‚ä¿¡æ¯æŸ¥è¯¢å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                print(f"å›¾å±‚ {layer_name} éªŒè¯æˆåŠŸ (æ–¹æ³•1: å›¾å±‚ä¿¡æ¯)")
                return True
            else:
                print(f"âš ï¸ å›¾å±‚ä¿¡æ¯æŸ¥è¯¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text}")
            
            # æ–¹æ³•2: å°è¯•é€šè¿‡WMS GetCapabilitieséªŒè¯
            print(f"å°è¯•æ–¹æ³•2: WMS GetCapabilitieséªŒè¯")
            wms_capabilities_url = f"{self.url}/wms?service=WMS&version=1.1.1&request=GetCapabilities"
            
            wms_response = requests.get(wms_capabilities_url, timeout=15)
            print(f"WMS Capabilitieså“åº”çŠ¶æ€ç : {wms_response.status_code}")
            
            if wms_response.status_code == 200:
                capabilities_text = wms_response.text
                if layer_name in capabilities_text:
                    print(f"å›¾å±‚ {layer_name} åœ¨WMS Capabilitiesä¸­æ‰¾åˆ°")
                    return True
                else:
                    print(f"âš ï¸ å›¾å±‚ {layer_name} ä¸åœ¨WMS Capabilitiesä¸­")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç±»ä¼¼çš„å›¾å±‚å
                    workspace = layer_name.split(':')[0] if ':' in layer_name else ''
                    if workspace and workspace in capabilities_text:
                        print(f"å·¥ä½œç©ºé—´ {workspace} å­˜åœ¨äºWMS Capabilitiesä¸­")
                        
                        # æå–æ‰€æœ‰è¯¥å·¥ä½œç©ºé—´çš„å›¾å±‚
                        import re
                        pattern = f'<Name>{workspace}:([^<]+)</Name>'
                        matches = re.findall(pattern, capabilities_text)
                        if matches:
                            print(f"å·¥ä½œç©ºé—´ä¸­çš„å›¾å±‚: {matches}")
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„å›¾å±‚
                            target_layer = layer_name.split(':')[1] if ':' in layer_name else layer_name
                            for match in matches:
                                if target_layer in match or match in target_layer:
                                    print(f"æ‰¾åˆ°ç›¸ä¼¼å›¾å±‚: {workspace}:{match}")
                                    return True
                    else:
                        print(f"å·¥ä½œç©ºé—´ {workspace} ä¸å­˜åœ¨äºWMS Capabilitiesä¸­")
            else:
                print(f"WMS Capabilitiesè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {wms_response.status_code}")
            
            # æ–¹æ³•3: å°è¯•ç›´æ¥WMS GetMapè¯·æ±‚
            print(f"å°è¯•æ–¹æ³•3: WMS GetMapè¯·æ±‚éªŒè¯")
            wms_getmap_url = f"{self.url}/wms"
            params = {
                'service': 'WMS',
                'version': '1.1.1',
                'request': 'GetMap',
                'layers': layer_name,
                'styles': '',
                'bbox': '-180,-90,180,90',
                'width': '256',
                'height': '256',
                'srs': 'EPSG:4326',
                'format': 'image/png',
                'transparent': 'true'
            }
            
            getmap_response = requests.get(wms_getmap_url, params=params, timeout=15)
            print(f"WMS GetMapå“åº”çŠ¶æ€ç : {getmap_response.status_code}")
            
            if getmap_response.status_code == 200:
                content_type = getmap_response.headers.get('content-type', '')
                print(f"WMS GetMapå“åº”å†…å®¹ç±»å‹: {content_type}")
                
                if 'image' in content_type:
                    print(f"å›¾å±‚ {layer_name} WMS GetMapæˆåŠŸè¿”å›å›¾ç‰‡")
                    return True
                else:
                    print(f"âš ï¸ WMS GetMapè¿”å›éå›¾ç‰‡å†…å®¹")
            else:
                print(f"WMS GetMapè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {getmap_response.status_code}")
            
            print(f"æ‰€æœ‰éªŒè¯æ–¹æ³•éƒ½å¤±è´¥ï¼Œå›¾å±‚{layer_name} ä¸å­˜åœ¨æˆ–ä¸å¯è®¿é—®")
            return False
                
        except Exception as e:
            print(f"éªŒè¯å›¾å±‚ {layer_name} å¼‚å¸¸: {str(e)}")
            return False
    
    def _extract_and_validate_shapefile_simple(self, zip_path):
        """ç®€åŒ–çš„è§£å‹å’ŒéªŒè¯Shapefileæ–‡ä»¶æ–¹æ³•
        
        Args:
            zip_path: ZIPæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: è§£å‹åçš„æ–‡ä»¶å¤¹è·¯å¾„
            
        Raises:
            Exception: å¦‚æœæ–‡ä»¶ä¸å®Œæ•´æˆ–æ ¼å¼ä¸æ­£ç¡®
        """
        import zipfile
        import os
        import tempfile
        
        print(f"å¼€å§‹è§£å‹Shapefile: {zip_path}")
        
        # åˆ›å»ºä¸´æ—¶è§£å‹ç›®å½•
        temp_dir = tempfile.mkdtemp()
        filename = os.path.splitext(os.path.basename(zip_path))[0]
        extracted_folder = os.path.join(temp_dir, filename)
        os.makedirs(extracted_folder, exist_ok=True)
        
        try:
            # è§£å‹ZIPæ–‡ä»¶
            with zipfile.ZipFile(zip_path, 'r') as zip_file:
                zip_file.extractall(extracted_folder)
                print(f"ZIPæ–‡ä»¶è§£å‹å®Œæˆ: {extracted_folder}")
            
            # è·å–è§£å‹åçš„æ–‡ä»¶åˆ—è¡¨
            extracted_files = []
            for root, dirs, files in os.walk(extracted_folder):
                for file in files:
                    extracted_files.append(file.lower())
            
            print(f"è§£å‹åçš„æ–‡ä»¶åˆ—è¡¨: {extracted_files}")
            
            # ç®€å•éªŒè¯ï¼šæ£€æŸ¥å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            has_shp = any(f.endswith('.shp') for f in extracted_files)
            has_dbf = any(f.endswith('.dbf') for f in extracted_files)
            has_shx = any(f.endswith('.shx') for f in extracted_files)
            
            if not has_shp:
                raise Exception("ZIPæ–‡ä»¶ä¸­æœªæ‰¾åˆ°.shpæ–‡ä»¶")
            if not has_dbf:
                raise Exception("ZIPæ–‡ä»¶ä¸­æœªæ‰¾åˆ°.dbfæ–‡ä»¶")
            if not has_shx:
                raise Exception("ZIPæ–‡ä»¶ä¸­æœªæ‰¾åˆ°.shxæ–‡ä»¶")
            
            print(f"âœ… Shapefileæ–‡ä»¶éªŒè¯é€šè¿‡")
            return extracted_folder
            
        except Exception as e:
            # å¦‚æœéªŒè¯å¤±è´¥ï¼Œæ¸…ç†è§£å‹çš„æ–‡ä»¶
            if os.path.exists(extracted_folder):
                import shutil
                shutil.rmtree(extracted_folder)
            raise Exception(f"Shapefileæ–‡ä»¶è§£å‹æˆ–éªŒè¯å¤±è´¥: {str(e)}")
    
    def _get_shp_name_from_folder(self, folder_path):
        """ä»è§£å‹çš„æ–‡ä»¶å¤¹ä¸­è·å–SHPæ–‡ä»¶å
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            str: SHPæ–‡ä»¶çš„åŸºç¡€åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
        """
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                if file.lower().endswith('.shp'):
                    return os.path.splitext(file)[0]
        
        raise Exception("åœ¨è§£å‹æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°.shpæ–‡ä»¶")
    
    def _ensure_safe_shapefile_names(self, folder_path, original_name, safe_base_name):
        """ç¡®ä¿Shapefileæ–‡ä»¶åæ˜¯GeoServerå‹å¥½çš„
        
        å¦‚æœåŸå§‹æ–‡ä»¶ååŒ…å«ä¸­æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦ï¼Œå°±é‡å‘½åä¸ºå®‰å…¨çš„è‹±æ–‡åç§°
        
        Args:
            folder_path: è§£å‹åçš„æ–‡ä»¶å¤¹è·¯å¾„
            original_name: åŸå§‹SHPæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            safe_base_name: å®‰å…¨çš„åŸºç¡€åç§°
            
        Returns:
            str: æœ€ç»ˆçš„SHPæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        """
        import re
        import os
        
        # æ£€æŸ¥åŸå§‹æ–‡ä»¶åæ˜¯å¦åŒ…å«ä¸­æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦
        has_chinese = re.search(r'[\u4e00-\u9fff]', original_name)
        has_special_chars = any(char in original_name for char in ['(', ')', ' ', 'ï¼ˆ', 'ï¼‰', '-', '+', '=', '@', '#', '$', '%', '^', '&', '*'])
        
        if not (has_chinese or has_special_chars):
            print(f"æ–‡ä»¶åå®‰å…¨ï¼Œæ— éœ€é‡å‘½å: {original_name}")
            return original_name
        
        print(f"æ£€æµ‹åˆ°ä¸å®‰å…¨çš„æ–‡ä»¶åï¼Œéœ€è¦é‡å‘½å: {original_name}")
        print(f"ä½¿ç”¨å®‰å…¨åç§°: {safe_base_name}")
        
        # éœ€è¦é‡å‘½åçš„æ–‡ä»¶æ‰©å±•å
        extensions = ['.shp', '.shx', '.dbf', '.prj', '.cpg', '.sbn', '.sbx', '.qix']
        
        renamed_count = 0
        for ext in extensions:
            original_file = os.path.join(folder_path, f"{original_name}{ext}")
            new_file = os.path.join(folder_path, f"{safe_base_name}{ext}")
            
            if os.path.exists(original_file):
                try:
                    os.rename(original_file, new_file)
                    print(f"âœ… é‡å‘½åæ–‡ä»¶: {original_name}{ext} -> {safe_base_name}{ext}")
                    renamed_count += 1
                except Exception as e:
                    print(f"âš ï¸ é‡å‘½åæ–‡ä»¶å¤±è´¥: {original_file} -> {new_file}, é”™è¯¯: {e}")
        
        if renamed_count > 0:
            print(f"âœ… æˆåŠŸé‡å‘½å {renamed_count} ä¸ªæ–‡ä»¶")
            return safe_base_name
        else:
            print(f"âš ï¸ æ²¡æœ‰æ–‡ä»¶è¢«é‡å‘½åï¼Œä½¿ç”¨åŸå§‹åç§°")
            return original_name
    
    def _upload_extracted_shapefile_to_geoserver(self, folder_path, store_name):
        """ä¸Šä¼ è§£å‹åçš„Shapefileæ–‡ä»¶åˆ°GeoServer
        
        ç›´æ¥ä¸Šä¼ .shpæ–‡ä»¶ï¼ŒGeoServerä¼šè‡ªåŠ¨æ‰¾åˆ°åŒç›®å½•ä¸‹çš„é…å¥—æ–‡ä»¶
        
        Args:
            folder_path: è§£å‹åçš„æ–‡ä»¶å¤¹è·¯å¾„
            store_name: æ•°æ®å­˜å‚¨åç§°
        """
        import os
        
        print(f"å‡†å¤‡ä¸Šä¼ è§£å‹åçš„Shapefileåˆ°GeoServer: {folder_path}")
        
        # æ‰¾åˆ°.shpæ–‡ä»¶
        shp_file_path = None
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                if file.lower().endswith('.shp'):
                    shp_file_path = os.path.join(root, file)
                    break
            if shp_file_path:
                break
        
        if not shp_file_path:
            raise Exception(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°.shpæ–‡ä»¶: {folder_path}")
        
        print(f"æ‰¾åˆ°SHPæ–‡ä»¶: {shp_file_path}")
        print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(shp_file_path)} å­—èŠ‚")
        
        # ä¸Šä¼ .shpæ–‡ä»¶åˆ°GeoServer
        # GeoServerä¼šè‡ªåŠ¨æŸ¥æ‰¾åŒç›®å½•ä¸‹çš„.dbf, .shx, .prjç­‰é…å¥—æ–‡ä»¶
        datastore_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/file.shp"
        headers = {'Content-Type': 'application/octet-stream'}
        
        print(f"ä¸Šä¼ URL: {datastore_url}")
        
        try:
            with open(shp_file_path, 'rb') as f:
                response = requests.put(
                    datastore_url,
                    data=f,
                    headers=headers,
                    auth=self.auth,
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                )
            
            print(f"Shapefileä¸Šä¼ å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.text:
                print(f"å“åº”å†…å®¹: {response.text[:500]}...")
            
            if response.status_code not in [201, 200]:
                raise Exception(f"ä¸Šä¼ Shapefileå¤±è´¥: HTTP {response.status_code} - {response.text}")
            
            print("âœ… Shapefileä¸Šä¼ æˆåŠŸ")
            
        except requests.exceptions.Timeout:
            raise Exception("ä¸Šä¼ Shapefileè¶…æ—¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å¤§å°å’Œç½‘ç»œè¿æ¥")
        except requests.exceptions.RequestException as e:
            raise Exception(f"ä¸Šä¼ Shapefileç½‘ç»œé”™è¯¯: {str(e)}")
        except Exception as e:
            print(f"âŒ Shapefileä¸Šä¼ å¤±è´¥: {str(e)}")
            raise e
    
    def _upload_geotiff_to_geoserver(self, tif_path, store_name):
        """ä¸Šä¼ GeoTIFFåˆ°GeoServerï¼Œæ ¹æ®REST APIæ–‡æ¡£ä¼˜åŒ–
        
        æ”¯æŒä¸¤ç§æ–¹å¼ï¼š
        1. ä½¿ç”¨æ–‡ä»¶ä¸Šä¼ æ–¹å¼ï¼ˆé€‚ç”¨äºå°æ–‡ä»¶ï¼‰
        2. ä½¿ç”¨å¤–éƒ¨æ–‡ä»¶å¼•ç”¨æ–¹å¼ï¼ˆé€‚ç”¨äºå¤§æ–‡ä»¶ï¼Œé¿å…ä¸Šä¼ ï¼‰
        
        Args:
            tif_path: GeoTIFFæ–‡ä»¶è·¯å¾„
            store_name: å­˜å‚¨åç§°
        """
        import os
        import shutil
        
        # 1. é¦–å…ˆéªŒè¯GeoTIFFæ–‡ä»¶
        print(f"å¼€å§‹éªŒè¯GeoTIFFæ–‡ä»¶...")
        is_valid, validation_msg = self._validate_geotiff_file(tif_path)
        if not is_valid:
            raise Exception(f"GeoTIFFæ–‡ä»¶éªŒè¯å¤±è´¥: {validation_msg}")
        
        print(f"æ£€æŸ¥coveragestoreä¸­æ˜¯å¦å·²æœ‰æ–‡ä»¶: {store_name}")
        
        # 2. æ£€æŸ¥coveragestoreæ˜¯å¦å·²ç»åŒ…å«æœ‰æ•ˆçš„è¦†ç›–æ•°æ®
        try:
            coverages_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages.json"
            check_response = requests.get(coverages_url, auth=self.auth, timeout=30)
            
            if check_response.status_code == 200:
                coverages_data = check_response.json()
                if ('coverages' in coverages_data and 
                    'coverage' in coverages_data['coverages'] and 
                    coverages_data['coverages']['coverage']):
                    print(f"âœ… coveragestoreä¸­å·²å­˜åœ¨æœ‰æ•ˆçš„è¦†ç›–æ•°æ®ï¼Œè·³è¿‡æ–‡ä»¶ä¸Šä¼ ")
                    return
            
            print(f"coveragestoreä¸­æ— è¦†ç›–æ•°æ®ï¼Œå¼€å§‹é…ç½®æ–‡ä»¶")
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥è¦†ç›–æ•°æ®æ—¶å‡ºé”™: {str(e)}ï¼Œç»§ç»­ä¸Šä¼ æµç¨‹")
        
        file_size = os.path.getsize(tif_path)
        print(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        
        # å¦‚æœæ–‡ä»¶å¤§äº10MBï¼Œä½¿ç”¨å¤–éƒ¨æ–‡ä»¶å¼•ç”¨æ–¹å¼
        # è¿™å¯ä»¥é¿å…é€šè¿‡REST APIä¸Šä¼ å¤§æ–‡ä»¶
        if file_size > 10 * 1024 * 1024:  # 10MB
            print(f"æ–‡ä»¶å¤§äº10MBï¼Œä½¿ç”¨å¤–éƒ¨æ–‡ä»¶å¼•ç”¨æ–¹å¼")
            return self._create_external_geotiff_reference(tif_path, store_name)
        
        # 3. å¯¹äºå°æ–‡ä»¶ï¼Œä½¿ç”¨æ ‡å‡†ä¸Šä¼ æ–¹å¼
        print(f"æ–‡ä»¶è¾ƒå°ï¼Œä½¿ç”¨æ ‡å‡†æ–‡ä»¶ä¸Šä¼ æ–¹å¼")
        coveragestore_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/file.geotiff"
        
        # è®¾ç½®æ­£ç¡®çš„Content-Type - æ ¹æ®å®˜æ–¹æ–‡æ¡£
        headers = {
            'Content-Type': 'image/tiff',  # å®˜æ–¹æ–‡æ¡£æ¨èçš„MIMEç±»å‹
            'Accept': 'application/xml'
        }
        
        print(f"ä¸Šä¼ URL: {coveragestore_url}")
        
        try:
            with open(tif_path, 'rb') as f:
                response = requests.put(
                    coveragestore_url,
                    data=f,
                    headers=headers,
                    auth=self.auth,
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶ï¼Œé€‚åˆå¤§æ–‡ä»¶
                )
            
            print(f"GeoTIFFä¸Šä¼ å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.text:
                print(f"GeoTIFFä¸Šä¼ å“åº”å†…å®¹: {response.text[:500]}...")
            
            if response.status_code in [200, 201]:
                print(f"âœ… GeoTIFFæ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
                
                # ç­‰å¾…GeoServerå¤„ç†æ–‡ä»¶
                import time
                time.sleep(2)
                
                # éªŒè¯ä¸Šä¼ ç»“æœ
                verify_response = requests.get(coverages_url, auth=self.auth, timeout=30)
                if verify_response.status_code == 200:
                    verify_data = verify_response.json()
                    if ('coverages' in verify_data and 
                        'coverage' in verify_data['coverages'] and 
                        verify_data['coverages']['coverage']):
                        print(f"âœ… ä¸Šä¼ éªŒè¯æˆåŠŸï¼šè¦†ç›–æ•°æ®å·²å¯ç”¨")
                    else:
                        print(f"âš ï¸ ä¸Šä¼ æˆåŠŸä½†è¦†ç›–æ•°æ®æœªå°±ç»ªï¼Œå¯èƒ½éœ€è¦æ›´å¤šå¤„ç†æ—¶é—´")
                
                return
                
            else:
                # å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤–éƒ¨æ–‡ä»¶å¼•ç”¨æ–¹å¼
                print(f"âš ï¸ æ ‡å‡†ä¸Šä¼ å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤–éƒ¨æ–‡ä»¶å¼•ç”¨æ–¹å¼")
                return self._create_external_geotiff_reference(tif_path, store_name)
                
        except requests.exceptions.Timeout:
            print("ä¸Šä¼ è¶…æ—¶ã€‚æ–‡ä»¶å¯èƒ½è¿‡å¤§æˆ–ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œå°è¯•ä½¿ç”¨å¤–éƒ¨æ–‡ä»¶å¼•ç”¨æ–¹å¼")
            return self._create_external_geotiff_reference(tif_path, store_name)
        except requests.exceptions.ConnectionError:
            print("è¿æ¥GeoServerå¤±è´¥ã€‚è¯·æ£€æŸ¥GeoServeræ˜¯å¦æ­£åœ¨è¿è¡Œ")
            raise Exception("è¿æ¥GeoServerå¤±è´¥ã€‚è¯·æ£€æŸ¥GeoServeræ˜¯å¦æ­£åœ¨è¿è¡Œ")
        except Exception as e:
            print(f"ä¸Šä¼ è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            print("å°è¯•ä½¿ç”¨å¤–éƒ¨æ–‡ä»¶å¼•ç”¨æ–¹å¼")
            return self._create_external_geotiff_reference(tif_path, store_name)
            
    def _create_external_geotiff_reference(self, tif_path, store_name):
        """åˆ›å»ºå¤–éƒ¨GeoTIFFæ–‡ä»¶å¼•ç”¨
        
        ä¸ä¸Šä¼ æ–‡ä»¶ï¼Œè€Œæ˜¯è®©GeoServerç›´æ¥å¼•ç”¨æœåŠ¡å™¨ä¸Šå·²å­˜åœ¨çš„æ–‡ä»¶
        ä¼˜å…ˆä½¿ç”¨GeoServeræ•°æ®ç›®å½•ä¸­å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œé¿å…å¤åˆ¶æºæ–‡ä»¶
        
        Args:
            tif_path: GeoTIFFæ–‡ä»¶è·¯å¾„
            store_name: å­˜å‚¨åç§°
            
        Returns:
            bool: æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        import os
        import shutil
        
        try:
            # 1. ç¡®å®šç›®æ ‡è·¯å¾„ - ä½¿ç”¨GeoServeræ•°æ®ç›®å½•
            geoserver_data_dir = self._get_geoserver_data_dir()
            if not geoserver_data_dir:
                raise Exception("æ— æ³•ç¡®å®šGeoServeræ•°æ®ç›®å½•")
                
            workspace_data_dir = os.path.join(geoserver_data_dir, "data", self.workspace)
            store_data_dir = os.path.join(workspace_data_dir, store_name)
            
            # 2. æ£€æŸ¥GeoServeræ•°æ®ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨å¯¹åº”çš„æ–‡ä»¶
            # è·å–æºæ–‡ä»¶åå’Œå¯èƒ½çš„ç›®æ ‡æ–‡ä»¶å
            source_filename = os.path.basename(tif_path)
            tif_basename = os.path.splitext(source_filename)[0]
            
            # å¯èƒ½çš„æ–‡ä»¶ååˆ—è¡¨ (åŸºäºè§‚å¯Ÿå’ŒGeoServerå‘½åè§„åˆ™)
            possible_filenames = [
                f"{tif_basename}.geotiff",
                f"{store_name}.geotiff",
                f"{source_filename}",
                f"{tif_basename}.tif",
                "file.geotiff",
                "file.tif"
            ]
            
            print(f"æ£€æŸ¥GeoServeræ•°æ®ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨æ–‡ä»¶...")
            
            existing_file_path = None
            # å¦‚æœstoreç›®å½•å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦å·²æœ‰æ–‡ä»¶
            if os.path.exists(store_data_dir):
                print(f"å­˜å‚¨ç›®å½•å·²å­˜åœ¨: {store_data_dir}")
                for filename in possible_filenames:
                    test_path = os.path.join(store_data_dir, filename)
                    if os.path.exists(test_path):
                        existing_file_path = test_path
                        print(f"âœ… æ‰¾åˆ°ç°æœ‰æ–‡ä»¶: {existing_file_path}")
                        break
                
                # å¦‚æœæ‰¾ä¸åˆ°å¯èƒ½çš„æ–‡ä»¶åï¼Œå°è¯•åˆ—å‡ºç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶
                if not existing_file_path:
                    print(f"ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æœç´¢GeoTIFFæ–‡ä»¶...")
                    for filename in os.listdir(store_data_dir):
                        if filename.lower().endswith(('.tif', '.tiff', '.geotiff')):
                            existing_file_path = os.path.join(store_data_dir, filename)
                            print(f"âœ… æ‰¾åˆ°å¤‡ç”¨ç°æœ‰æ–‡ä»¶: {existing_file_path}")
                            break
            
            # 3. ç¡®å®šä½¿ç”¨çš„æ–‡ä»¶å’Œè·¯å¾„
            relative_path = None
            
            if existing_file_path:
                # ä½¿ç”¨å·²å­˜åœ¨çš„æ–‡ä»¶
                print(f"ä½¿ç”¨GeoServeræ•°æ®ç›®å½•ä¸­å·²å­˜åœ¨çš„æ–‡ä»¶: {existing_file_path}")
                tif_filename = os.path.basename(existing_file_path)
                relative_path = f"file:data/{self.workspace}/{store_name}/{tif_filename}"
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç°æœ‰æ–‡ä»¶ï¼Œåˆ™éœ€è¦å¤åˆ¶æºæ–‡ä»¶
                print(f"æœªæ‰¾åˆ°ç°æœ‰æ–‡ä»¶ï¼Œå°†å¤åˆ¶æºæ–‡ä»¶åˆ°GeoServeræ•°æ®ç›®å½•")
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(store_data_dir, exist_ok=True)
                
                # å¤åˆ¶æ–‡ä»¶åˆ°GeoServeræ•°æ®ç›®å½•
                tif_filename = f"{store_name}.geotiff"
                target_file_path = os.path.join(store_data_dir, tif_filename)
                
                print(f"å°†æ–‡ä»¶å¤åˆ¶åˆ°GeoServeræ•°æ®ç›®å½•: {target_file_path}")
                
                # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆå°è¯•åˆ é™¤
                if os.path.exists(target_file_path):
                    self._force_delete_if_exists(target_file_path)
                
                # å¤åˆ¶æ–‡ä»¶
                shutil.copy2(tif_path, target_file_path)
                print(f"âœ… æ–‡ä»¶å¤åˆ¶æˆåŠŸ")
                
                relative_path = f"file:data/{self.workspace}/{store_name}/{tif_filename}"
            
            # 4. åˆ›å»ºå¼•ç”¨è¯¥æ–‡ä»¶çš„coveragestore
            coveragestore_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores"
            
            coveragestore_data = {
                "coverageStore": {
                    "name": store_name,
                    "type": "GeoTIFF",
                    "enabled": True,
                    "workspace": {"name": self.workspace},
                    "url": relative_path
                }
            }
            
            headers = {'Content-Type': 'application/json'}
            
            # é¦–å…ˆæ£€æŸ¥coveragestoreæ˜¯å¦å·²å­˜åœ¨
            check_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}"
            check_response = requests.get(check_url, auth=self.auth)
            
            if check_response.status_code == 200:
                # å¦‚æœå·²å­˜åœ¨ï¼Œä½¿ç”¨PUTæ›´æ–°
                print(f"Coveragestoreå·²å­˜åœ¨ï¼Œæ›´æ–°ç°æœ‰store")
                update_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}"
                response = requests.put(
                    update_url,
                    json=coveragestore_data,
                    headers=headers,
                    auth=self.auth
                )
            else:
                # å¦‚æœä¸å­˜åœ¨ï¼Œä½¿ç”¨POSTåˆ›å»º
                print(f"åˆ›å»ºæ–°çš„coveragestore")
                response = requests.post(
                    coveragestore_url,
                    json=coveragestore_data,
                    headers=headers,
                    auth=self.auth
                )
            
            print(f"Coveragestoreåˆ›å»º/æ›´æ–°å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.text:
                print(f"å“åº”å†…å®¹: {response.text[:500]}...")
            
            if response.status_code not in [200, 201]:
                raise Exception(f"åˆ›å»ºå¤–éƒ¨å¼•ç”¨coveragestoreå¤±è´¥: HTTP {response.status_code} - {response.text}")
            
            # 5. æ£€æŸ¥æ˜¯å¦æœ‰coverageï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»º
            import time
            time.sleep(2)  # ç­‰å¾…GeoServerå¤„ç†
            
            coverage_list_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages"
            coverage_list_response = requests.get(f"{coverage_list_url}.json", auth=self.auth)
            
            coverage_exists = False
            coverage_name = store_name
            
            if coverage_list_response.status_code == 200:
                coverage_data = coverage_list_response.json()
                if 'coverages' in coverage_data and 'coverage' in coverage_data['coverages']:
                    coverages = coverage_data['coverages']['coverage']
                    if isinstance(coverages, list) and len(coverages) > 0:
                        coverage_exists = True
                        coverage_name = coverages[0]['name']
                    elif isinstance(coverages, dict):
                        coverage_exists = True
                        coverage_name = coverages['name']
            
            if not coverage_exists:
                print(f"åˆ›å»ºcoverage")
                coverage_data = {
                    "coverage": {
                        "name": store_name,
                        "nativeName": store_name,
                        "title": store_name,
                        "enabled": True
                    }
                }
                
                coverage_create_response = requests.post(
                    coverage_list_url,
                    json=coverage_data,
                    headers=headers,
                    auth=self.auth
                )
                
                print(f"Coverageåˆ›å»ºå“åº”çŠ¶æ€ç : {coverage_create_response.status_code}")
                if coverage_create_response.text:
                    print(f"å“åº”å†…å®¹: {coverage_create_response.text[:500]}...")
                
                if coverage_create_response.status_code not in [200, 201]:
                    print(f"âš ï¸ åˆ›å»ºcoverageå¤±è´¥: {coverage_create_response.text}")
                else:
                    print(f"âœ… Coverageåˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… Coverageå·²å­˜åœ¨: {coverage_name}")
            
            # 6. è¿”å›æˆåŠŸ
            print(f"âœ… å¤–éƒ¨GeoTIFFå¼•ç”¨åˆ›å»ºæˆåŠŸ: {relative_path}")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå¤–éƒ¨GeoTIFFå¼•ç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"åˆ›å»ºå¤–éƒ¨GeoTIFFå¼•ç”¨å¤±è´¥: {str(e)}")
    
    def _get_geoserver_data_dir(self):
        """è·å–GeoServeræ•°æ®ç›®å½•
        
        å°è¯•å¤šç§æ–¹å¼ç¡®å®šGeoServeræ•°æ®ç›®å½•çš„ä½ç½®
        
        Returns:
            str: GeoServeræ•°æ®ç›®å½•è·¯å¾„
        """
        import os
        
        # å¸¸è§çš„GeoServeræ•°æ®ç›®å½•ä½ç½®
        possible_dirs = [
            r'D:\ProgramData\GeoServer\data',
            r'D:\ProgramData\GeoServer',
            r'C:\ProgramData\GeoServer\data',
            r'C:\ProgramData\GeoServer',
            r'C:\Program Files\GeoServer\data_dir',
            r'C:\Program Files (x86)\GeoServer\data_dir',
            r'/opt/geoserver/data_dir',
            r'/var/lib/geoserver/data'
        ]
        
        # é¦–å…ˆä»ç¯å¢ƒå˜é‡è·å–
        geoserver_data_dir = os.environ.get('GEOSERVER_DATA_DIR')
        if geoserver_data_dir and os.path.exists(geoserver_data_dir):
            print(f"ä»ç¯å¢ƒå˜é‡è·å–GeoServeræ•°æ®ç›®å½•: {geoserver_data_dir}")
            return geoserver_data_dir
            
        # å°è¯•å¸¸è§ä½ç½®
        for dir_path in possible_dirs:
            if os.path.exists(dir_path):
                print(f"åœ¨å¸¸è§ä½ç½®æ‰¾åˆ°GeoServeræ•°æ®ç›®å½•: {dir_path}")
                return dir_path
                
        # ä½¿ç”¨é»˜è®¤ä½ç½®
        default_dir = r'D:\ProgramData\GeoServer\data'
        print(f"æœªæ‰¾åˆ°GeoServeræ•°æ®ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤å€¼: {default_dir}")
        return default_dir
        
    def _force_delete_if_exists(self, file_path):
        """å¦‚æœæ–‡ä»¶å­˜åœ¨å°±å¼ºåˆ¶åˆ é™¤ï¼Œå¤„ç†è¢«å ç”¨çš„æƒ…å†µ"""
        import os
        import stat
        
        if os.path.exists(file_path):
            try:
                # å…ˆå°è¯•æ­£å¸¸åˆ é™¤
                os.remove(file_path)
                print(f"æˆåŠŸåˆ é™¤æ–‡ä»¶: {file_path}")
                return True
            except PermissionError:
                # æ–‡ä»¶è¢«å ç”¨ï¼Œå°è¯•å¼ºåˆ¶åˆ é™¤
                try:
                    print(f"æ–‡ä»¶è¢«å ç”¨ï¼Œå°è¯•å¼ºåˆ¶åˆ é™¤: {file_path}")
                    # ä¿®æ”¹æ–‡ä»¶æƒé™
                    os.chmod(file_path, stat.S_IWRITE)
                    os.remove(file_path)
                    print(f"æˆåŠŸå¼ºåˆ¶åˆ é™¤æ–‡ä»¶: {file_path}")
                    return True
                except Exception as e:
                    print(f"å¼ºåˆ¶åˆ é™¤æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
                    return False
            except Exception as e:
                print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
                return False
        return True
    
    def _create_empty_coveragestore_for_existing_file(self, store_name, file_path):
        """ä¸ºå·²å­˜åœ¨çš„æ–‡ä»¶åˆ›å»ºç©ºçš„coveragestore
        
        å½“æ–‡ä»¶å·²ç»å­˜åœ¨äºGeoServerçš„dataç›®å½•ä¸­æ—¶ï¼Œåˆ›å»ºä¸€ä¸ªæŒ‡å‘è¯¥æ–‡ä»¶çš„coveragestore
        
        Args:
            store_name: å­˜å‚¨åç§°
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºç¡®å®šæ–‡ä»¶åï¼‰
        """
        import os
        
        print(f"ä¸ºå·²å­˜åœ¨æ–‡ä»¶åˆ›å»ºcoveragestore: {store_name}")
        
        # è·å–æ–‡ä»¶å
        filename = os.path.basename(file_path)
        
        # æ„å»ºcoveragestoreé…ç½®ï¼ŒæŒ‡å‘GeoServer dataç›®å½•ä¸­çš„æ–‡ä»¶
        coveragestore_config = {
            "coverageStore": {
                "name": store_name,
                "type": "GeoTIFF",
                "enabled": True,
                "workspace": {
                    "name": self.workspace,
                    "href": f"{self.rest_url}/workspaces/{self.workspace}.json"
                },
                "url": f"file:data/{self.workspace}/{store_name}/{filename}"
            }
        }
        
        # å‘é€è¯·æ±‚åˆ›å»ºcoveragestore
        url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores"
        headers = {'Content-Type': 'application/json'}
        
        response = requests.post(
            url,
            json=coveragestore_config,
            auth=self.auth,
            headers=headers,
            timeout=60
        )
        
        print(f"åˆ›å»ºcoveragestoreå“åº”çŠ¶æ€ç : {response.status_code}")
        if response.text:
            print(f"å“åº”å†…å®¹: {response.text[:500]}...")
        
        if response.status_code not in [201, 200]:
            # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œå°è¯•ç›´æ¥å¼•ç”¨å¯èƒ½å­˜åœ¨çš„æ–‡ä»¶
            print(f"âš ï¸ æ ‡å‡†åˆ›å»ºå¤±è´¥ï¼Œå°è¯•ç›´æ¥å¼•ç”¨æ–‡ä»¶")
            
            # å°è¯•ä¸åŒçš„URLæ ¼å¼
            alt_urls = [
                f"file:data/{self.workspace}/{store_name}/{store_name}.geotiff",
                f"file:data/{filename}"
            ]
            
            for alt_url in alt_urls:
                print(f"  å°è¯•URL: {alt_url}")
                alt_config = {
                    "coverageStore": {
                        "name": store_name,
                        "type": "GeoTIFF",
                        "enabled": True,
                        "workspace": {
                            "name": self.workspace,
                            "href": f"{self.rest_url}/workspaces/{self.workspace}.json"
                        },
                        "url": alt_url
                    }
                }
                
                alt_response = requests.post(
                    url,
                    json=alt_config,
                    auth=self.auth,
                    headers=headers,
                    timeout=60
                )
                
                print(f"  å“åº”çŠ¶æ€ç : {alt_response.status_code}")
                
                if alt_response.status_code in [201, 200]:
                    print(f"  âœ… ä½¿ç”¨URL {alt_url} åˆ›å»ºæˆåŠŸ")
                    break
            else:
                raise Exception(f"åˆ›å»ºcoveragestoreå¤±è´¥: {response.text}")
        
        # ç­‰å¾…GeoServerå¤„ç†
        time.sleep(2)
        
        # éªŒè¯åˆ›å»ºç»“æœ
        verify_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}.json"
        verify_response = requests.get(verify_url, auth=self.auth)
        
        if verify_response.status_code != 200:
            raise Exception(f"Coveragestoreåˆ›å»ºåéªŒè¯å¤±è´¥: {verify_response.text}")
        
        print(f"âœ… Coveragestoreåˆ›å»ºå¹¶éªŒè¯æˆåŠŸ: {store_name}")
    
    def _validate_geojson_file(self, geojson_path):
        """éªŒè¯GeoJSONæ–‡ä»¶"""
        print(f"éªŒè¯GeoJSONæ–‡ä»¶: {geojson_path}")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(geojson_path):
            raise Exception(f"GeoJSONæ–‡ä»¶ä¸å­˜åœ¨: {geojson_path}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(geojson_path)
        print(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        
        if file_size == 0:
            raise Exception("GeoJSONæ–‡ä»¶ä¸ºç©º")
        
        # éªŒè¯JSONæ ¼å¼å’ŒGeoJSONç»“æ„
        try:
            with open(geojson_path, 'r', encoding='utf-8') as f:
                geojson_data = json.load(f)
                
                # æ£€æŸ¥GeoJSONåŸºæœ¬ç»“æ„
                if not isinstance(geojson_data, dict):
                    raise Exception("GeoJSONå¿…é¡»æ˜¯ä¸€ä¸ªå¯¹è±¡")
                
                geojson_type = geojson_data.get('type')
                if geojson_type not in ['FeatureCollection', 'Feature', 'Point', 'LineString', 'Polygon', 'MultiPoint', 'MultiLineString', 'MultiPolygon', 'GeometryCollection']:
                    raise Exception(f"æ— æ•ˆçš„GeoJSONç±»å‹: {geojson_type}")
                
                print(f"GeoJSONç±»å‹: {geojson_type}")
                
                # å¦‚æœæ˜¯FeatureCollectionï¼Œæ£€æŸ¥è¦ç´ æ•°é‡
                if geojson_type == 'FeatureCollection':
                    features = geojson_data.get('features', [])
                    print(f"è¦ç´ æ•°é‡: {len(features)}")
                    
                    if len(features) == 0:
                        print("âš ï¸ GeoJSONä¸­æ²¡æœ‰è¦ç´ ")
                    
                print("GeoJSONæ ¼å¼éªŒè¯é€šè¿‡")
                
        except json.JSONDecodeError as e:
            raise Exception(f"GeoJSONæ–‡ä»¶JSONæ ¼å¼æ— æ•ˆ: {e}")
        except Exception as e:
            if "æ— æ•ˆçš„GeoJSONç±»å‹" in str(e) or "GeoJSONå¿…é¡»æ˜¯ä¸€ä¸ªå¯¹è±¡" in str(e):
                raise e
            else:
                raise Exception(f"GeoJSONæ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
    
    def _cleanup_existing_datastore(self, store_name):
        """æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ•°æ®å­˜å‚¨"""
        try:
            check_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}"
            check_response = requests.get(check_url, auth=self.auth)
            
            if check_response.status_code == 200:
                print(f"æ•°æ®å­˜å‚¨ {store_name} å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤")
                delete_response = requests.delete(f"{check_url}?recurse=true", auth=self.auth)
                if delete_response.status_code not in [200, 404]:
                    print(f"åˆ é™¤ç°æœ‰æ•°æ®å­˜å‚¨å¤±è´¥: {delete_response.text}")
                else:
                    print(f"åˆ é™¤ç°æœ‰æ•°æ®å­˜å‚¨æˆåŠŸ")
                time.sleep(1)
        except Exception as e:
            print(f"æ¸…ç†ç°æœ‰æ•°æ®å­˜å‚¨å¤±è´¥: {e}")
    
    def _get_featuretype_info(self, store_name, featuretype_name=None):
        """è·å–è¦ç´ ç±»å‹ä¿¡æ¯
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
            featuretype_name: è¦ç´ ç±»å‹åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™è·å–ç¬¬ä¸€ä¸ªï¼‰
        
        Returns:
            è¦ç´ ç±»å‹ä¿¡æ¯
        """
        # å¦‚æœæ²¡æœ‰æä¾›featuretype_nameï¼Œå…ˆè·å–æ•°æ®å­˜å‚¨ä¸­çš„è¦ç´ ç±»å‹åˆ—è¡¨
        if not featuretype_name:
            featuretypes_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/featuretypes.json"
            print(f"è·å–è¦ç´ ç±»å‹åˆ—è¡¨URL: {featuretypes_url}")
            
            response = requests.get(featuretypes_url, auth=self.auth)
            print(f"è·å–è¦ç´ ç±»å‹åˆ—è¡¨å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code != 200:
                raise Exception(f"è·å–è¦ç´ ç±»å‹åˆ—è¡¨å¤±è´¥: {response.text}")
            
            # è§£æè¦ç´ ç±»å‹åˆ—è¡¨
            data = response.json()
            print(f"è¦ç´ ç±»å‹åˆ—è¡¨æ•°æ®: {data}")
            
            if 'featureTypes' in data and 'featureType' in data['featureTypes']:
                feature_types = data['featureTypes']['featureType']
                
                if isinstance(feature_types, list) and len(feature_types) > 0:
                    featuretype_name = feature_types[0]['name']
                elif isinstance(feature_types, dict):
                    featuretype_name = feature_types['name']
            
            if not featuretype_name:
                raise Exception(f"æ•°æ®å­˜å‚¨ {store_name} ä¸­æ²¡æœ‰æ‰¾åˆ°è¦ç´ ç±»å‹")
            
            print(f"æ‰¾åˆ°è¦ç´ ç±»å‹åç§°: {featuretype_name}")
        
        # è·å–è¦ç´ ç±»å‹è¯¦ç»†ä¿¡æ¯
        url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/featuretypes/{featuretype_name}.json"
        print(f"è·å–è¦ç´ ç±»å‹ä¿¡æ¯URL: {url}")
        
        response = requests.get(url, auth=self.auth)
        
        print(f"è·å–è¦ç´ ç±»å‹ä¿¡æ¯å“åº”çŠ¶æ€ç : {response.status_code}")
        if response.status_code != 200:
            print(f"è·å–è¦ç´ ç±»å‹ä¿¡æ¯å¤±è´¥å“åº”å†…å®¹: {response.text}")
            # æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_message = f"è·å–è¦ç´ ç±»å‹ä¿¡æ¯å¤±è´¥: No such feature type: {self.workspace},{store_name},{featuretype_name}"
            print(f"é”™è¯¯ä¿¡æ¯: {error_message}")
            raise Exception(error_message)
        
        print(f"æˆåŠŸè·å–è¦ç´ ç±»å‹ä¿¡æ¯: {featuretype_name}")
        return response.json()
    
    def _get_coverage_info(self, store_name):
        """è·å–è¦†ç›–ä¿¡æ¯"""
        # é¦–å…ˆå°è¯•è·å–è¦†ç›–å­˜å‚¨ä¸­çš„è¦†ç›–åˆ—è¡¨
        coverages_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages.json"
        print(f"è·å–è¦†ç›–ä¿¡æ¯URL: {coverages_url}")
        
        response = requests.get(coverages_url, auth=self.auth)
        print(f"è·å–è¦†ç›–åˆ—è¡¨å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code != 200:
            print(f"è·å–è¦†ç›–åˆ—è¡¨å¤±è´¥å“åº”å†…å®¹: {response.text}")
            raise Exception(f"è·å–è¦†ç›–åˆ—è¡¨å¤±è´¥: {response.text}")
        
        # è§£æè¦†ç›–åˆ—è¡¨
        coverages_data = response.json()
        print(f"è¦†ç›–åˆ—è¡¨æ•°æ®: {coverages_data}")
        
        # è·å–ç¬¬ä¸€ä¸ªè¦†ç›–çš„åç§°
        coverage_name = None
        if 'coverages' in coverages_data and 'coverage' in coverages_data['coverages']:
            coverages = coverages_data['coverages']['coverage']
            if isinstance(coverages, list) and len(coverages) > 0:
                coverage_name = coverages[0]['name']
            elif isinstance(coverages, dict):
                coverage_name = coverages['name']
        
        if not coverage_name:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¦†ç›–ï¼Œå°è¯•ä½¿ç”¨store_name
            coverage_name = store_name
            print(f"æœªæ‰¾åˆ°è¦†ç›–ï¼Œä½¿ç”¨store_name: {coverage_name}")
        else:
            print(f"æ‰¾åˆ°è¦†ç›–åç§°: {coverage_name}")
        
        # è·å–å…·ä½“è¦†ç›–çš„è¯¦ç»†ä¿¡æ¯
        coverage_detail_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages/{coverage_name}.json"
        detail_response = requests.get(coverage_detail_url, auth=self.auth)
        
        if detail_response.status_code != 200:
            print(f"è·å–è¦†ç›–è¯¦ç»†ä¿¡æ¯å¤±è´¥ï¼Œæ„é€ åŸºæœ¬ä¿¡æ¯")
            # å¦‚æœè·å–è¯¦ç»†ä¿¡æ¯å¤±è´¥ï¼Œæ„é€ åŸºæœ¬çš„è¦†ç›–ä¿¡æ¯
            return {
                "coverage": {
                    "name": coverage_name,
                    "nativeName": coverage_name,
                    "title": coverage_name,
                    "abstract": f"ä»è¦†ç›–å­˜å‚¨ {store_name} å‘å¸ƒçš„è¦†ç›–",
                    "enabled": True,
                    "srs": "EPSG:4326",
                    "store": {
                        "@class": "coverageStore",
                        "name": f"{self.workspace}:{store_name}"
                    }
                }
            }
        
        print(f"æˆåŠŸè·å–è¦†ç›–è¯¦ç»†ä¿¡æ¯: {coverage_name}")
        coverage_info = detail_response.json()
        
        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç»“æ„ï¼ˆç±»ä¼¼featureTypeï¼‰
        if 'coverage' in coverage_info:
            # å°†coverageä¿¡æ¯åŒ…è£…æˆç±»ä¼¼featureTypeçš„ç»“æ„ï¼Œä»¥ä¾¿å¤ç”¨_create_layer_in_dbæ–¹æ³•
            return {
                "featureType": {
                    "name": coverage_info['coverage']['name'],
                    "nativeName": coverage_info['coverage'].get('nativeName', coverage_info['coverage']['name']),
                    "title": coverage_info['coverage'].get('title', coverage_info['coverage']['name']),
                    "abstract": coverage_info['coverage'].get('abstract', ''),
                    "enabled": coverage_info['coverage'].get('enabled', True),
                    "srs": coverage_info['coverage'].get('srs', 'EPSG:4326'),
                    "store": coverage_info['coverage'].get('store', {"name": f"{self.workspace}:{store_name}"})
                }
            }
        else:
            return coverage_info
    
    def _create_featuretype_in_db(self, featuretype_info, store_id):
        """åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦ç´ ç±»å‹è®°å½•
        
        Args:
            featuretype_info: è¦ç´ ç±»å‹ä¿¡æ¯
            store_id: å­˜å‚¨ID
            
        Returns:
            è¦ç´ ç±»å‹ID
        """
        try:
            # è°ƒè¯•è¾“å‡ºï¼ŒæŸ¥çœ‹å®é™…çš„æ•°æ®ç»“æ„
            print(f"featuretype_infoç»“æ„: {featuretype_info}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰featureTypeé”®
            if 'featureType' in featuretype_info:
                feature_data = featuretype_info['featureType']
            else:
                feature_data = featuretype_info
            
            # æå–è¦ç´ ç±»å‹ä¿¡æ¯ï¼Œæä¾›é»˜è®¤å€¼
            name = feature_data.get('name') or feature_data.get('nativeName') or f"feature_{store_id}"
            native_name = feature_data.get('nativeName') or name
            title = feature_data.get('title') or name
            abstract = feature_data.get('abstract') or ''
            
            # å¤„ç†keywordså­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨ç±»å‹
            keywords_raw = feature_data.get('keywords') or []
            if isinstance(keywords_raw, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–å€¼æˆ–é”®ä½œä¸ºå…³é”®è¯
                keywords = list(keywords_raw.values()) if keywords_raw.values() else list(keywords_raw.keys())
            elif isinstance(keywords_raw, list):
                keywords = keywords_raw
            else:
                keywords = [str(keywords_raw)] if keywords_raw else []
            
            srs = feature_data.get('srs') or 'EPSG:4326'
            
            # ç¡®ä¿nameä¸ä¸ºç©º
            if not name:
                name = f"feature_{store_id}"
                print(f"è­¦å‘Š: è¦ç´ ç±»å‹åç§°ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°: {name}")
            
            featuretype_params = {
                'name': name,
                'native_name': native_name,
                'store_id': store_id,
                'title': title,
                'abstract': abstract,
                'keywords': keywords,
                'srs': srs,
                'enabled': True
            }
            
            print(f"å‡†å¤‡æ’å…¥çš„è¦ç´ ç±»å‹å‚æ•°: {featuretype_params}")
            
            featuretype_id = insert_with_snowflake_id('geoserver_featuretypes', featuretype_params)
            return featuretype_id
        except Exception as e:
            print(f"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºè¦ç´ ç±»å‹è®°å½•å¤±è´¥: {str(e)}")
            raise
    
    def _create_layer_in_db(self, layer_info, workspace_id, featuretype_id=None, coverage_id=None, file_id=None, store_type='datastore'):
        """åœ¨æ•°æ®åº“ä¸­åˆ›å»ºå›¾å±‚è®°å½•
        
        Args:
            layer_info: å›¾å±‚ä¿¡æ¯
            workspace_id: å·¥ä½œç©ºé—´ID
            featuretype_id: è¦ç´ ç±»å‹ID
            coverage_id: è¦†ç›–èŒƒå›´ID
            file_id: æ–‡ä»¶ID
            store_type: å­˜å‚¨ç±»å‹
            
        Returns:
            å›¾å±‚ä¿¡æ¯å­—å…¸
        """
        try:
            # è°ƒè¯•è¾“å‡ºï¼ŒæŸ¥çœ‹å®é™…çš„æ•°æ®ç»“æ„
            print(f"layer_infoç»“æ„: {layer_info}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰featureTypeé”®æˆ–coverageé”®
            if 'featureType' in layer_info:
                layer_data = layer_info['featureType']
            elif 'coverage' in layer_info:
                layer_data = layer_info['coverage']
            else:
                layer_data = layer_info
            
            # æå–å›¾å±‚ä¿¡æ¯ï¼Œæä¾›é»˜è®¤å€¼
            name = layer_data.get('name') or layer_data.get('nativeName') or f"layer_{workspace_id}"
            title = layer_data.get('title') or name
            abstract = layer_data.get('abstract') or ''
            default_style = layer_data.get('default_style') or 'generic'
            layer_name = layer_data['name']
            full_layer_name = f"{self.workspace}:{layer_name}"

            # ç”ŸæˆæœåŠ¡URL
            wms_url = f"{self.url}/wms?service=WMS&version=1.1.0&request=GetCapabilities&layers={full_layer_name}"
            wfs_url = f"{self.url}/wfs?service=WFS&version=1.0.0&request=GetCapabilities&typeName={full_layer_name}"
            wcs_url = f"{self.url}/wcs?service=WCS&version=1.0.0&request=GetCapabilities&coverage={full_layer_name}" if store_type == 'coveragestore' else None
            # ç¡®ä¿nameä¸ä¸ºç©º
            if not name:
                name = f"layer_{workspace_id}_{featuretype_id or coverage_id}"
                print(f"è­¦å‘Š: å›¾å±‚åç§°ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°: {name}")
            
            layer_params = {
                'name': name,
                'workspace_id': workspace_id,
                'featuretype_id': featuretype_id,
                'coverage_id': coverage_id,
                'title': title,
                'abstract': abstract,
                'default_style': default_style,
                'enabled': True,
                'queryable': True,
                'file_id': file_id,
                'wms_url': wms_url,
                'wfs_url': wfs_url,
                'wcs_url': wcs_url
            }
            
            logger.info(f"å‡†å¤‡æ’å…¥çš„å›¾å±‚å‚æ•°: {layer_params}")
            
            layer_id = insert_with_snowflake_id('geoserver_layers', layer_params)
            
            # æ„å»ºå®Œæ•´çš„å›¾å±‚ä¿¡æ¯è¿”å›
            full_layer_name = f"{self.workspace}:{name}"
            layer_result = {
                'id': layer_id,
                'name': name,
                'full_name': full_layer_name,
                'title': title,
                'workspace_id': workspace_id,
                'featuretype_id': featuretype_id if store_type != 'coveragestore' else None,
                'coverage_id': featuretype_id if store_type == 'coveragestore' else None,
                'abstract': abstract,
                'wms_url': wms_url,
                'wfs_url': wfs_url,
                'wcs_url': wcs_url
            }
            
            return layer_result
        except Exception as e:
            print(f"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºå›¾å±‚è®°å½•å¤±è´¥: {str(e)}")
            raise
    
    def _delete_related_records_from_db(self, store_name):
        """ä»æ•°æ®åº“ä¸­åˆ é™¤ç›¸å…³è®°å½•"""
        # åˆ é™¤å›¾å±‚è®°å½•
        layer_sql = "DELETE FROM geoserver_layers WHERE name = %s"
        execute_query(layer_sql, (store_name,), fetch=False)
        
        # åˆ é™¤è¦ç´ ç±»å‹è®°å½•
        featuretype_sql = "DELETE FROM geoserver_featuretypes WHERE name = %s"
        execute_query(featuretype_sql, (store_name,), fetch=False)
        
        # åˆ é™¤æ•°æ®å­˜å‚¨è®°å½•
        store_sql = "DELETE FROM geoserver_stores WHERE name = %s"
        execute_query(store_sql, (store_name,), fetch=False)
    
    def _create_postgis_datastore(self, store_name):
        """åˆ›å»ºPostGISæ•°æ®å­˜å‚¨
        
        æ ¹æ®GeoServerå®˜æ–¹æ–‡æ¡£é…ç½®PostGISæ•°æ®æºï¼ŒåŒ…å«å®Œæ•´çš„è¿æ¥å‚æ•°ï¼š
        - åŸºç¡€è¿æ¥å‚æ•°ï¼ˆhostã€portã€databaseã€schemaã€userã€passwdç­‰ï¼‰
        - æ€§èƒ½ä¼˜åŒ–å‚æ•°ï¼ˆExpose primary keysã€encode functionsã€Loose bboxç­‰ï¼‰
        - è¿æ¥æ± å‚æ•°ï¼ˆvalidate connectionsã€Connection timeoutã€min/max connectionsç­‰ï¼‰
        - å‡ ä½•å¤„ç†å‚æ•°ï¼ˆSupport on the fly geometry simplificationç­‰ï¼‰
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
        """
        
        print(f"åˆ›å»ºPostGISæ•°æ®æº: {store_name}")
        print(f"ä½¿ç”¨å·¥ä½œç©ºé—´: {self.workspace}")
        
        # ç¡®ä¿å·¥ä½œç©ºé—´å­˜åœ¨
        try:
            # å…ˆæ£€æŸ¥GeoServerä¸­æ˜¯å¦å­˜åœ¨è¯¥å·¥ä½œç©ºé—´
            workspace_url = f"{self.rest_url}/workspaces/{self.workspace}"
            check_response = requests.get(workspace_url, auth=self.auth)
            
            if check_response.status_code != 200:
                print(f"âš ï¸ GeoServerä¸­ä¸å­˜åœ¨å·¥ä½œç©ºé—´ {self.workspace}ï¼Œå°è¯•åˆ›å»º...")
                self._create_workspace_in_geoserver()
                print(f"âœ… GeoServerä¸­å·¥ä½œç©ºé—´ {self.workspace} åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… GeoServerä¸­å·¥ä½œç©ºé—´ {self.workspace} å·²å­˜åœ¨")
                
            # åŒæ—¶ç¡®ä¿æ•°æ®åº“ä¸­ä¹Ÿæœ‰å¯¹åº”çš„è®°å½•
            workspace_id = self._get_workspace_id()
            print(f"âœ… æ•°æ®åº“ä¸­å·¥ä½œç©ºé—´è®°å½•å­˜åœ¨ï¼ŒID: {workspace_id}")
        except Exception as e:
            print(f"âš ï¸ å·¥ä½œç©ºé—´æ£€æŸ¥/åˆ›å»ºå¤±è´¥: {str(e)}")
            print("å°è¯•ç»§ç»­åˆ›å»ºæ•°æ®å­˜å‚¨...")
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„åŒåæ•°æ®å­˜å‚¨
        self._cleanup_existing_datastore(store_name)
        
        # æ„å»ºPostGISæ•°æ®å­˜å‚¨é…ç½®ï¼Œå®Œå…¨æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ¨èå‚æ•°
        datastore_config = {
            "dataStore": {
                "name": store_name,
                "type": "PostGIS",
                "enabled": True,
                "workspace": {
                    "name": self.workspace
                },
                "connectionParameters": {
                    "entry": [
                        # === åŸºç¡€è¿æ¥å‚æ•° ===
                        {"@key": "dbtype", "$": "postgis"},
                        {"@key": "host", "$": DB_CONFIG['host']},
                        {"@key": "port", "$": str(DB_CONFIG['port'])},
                        {"@key": "database", "$": DB_CONFIG['database']},
                        {"@key": "schema", "$": DB_CONFIG.get('schema', 'public')},
                        {"@key": "user", "$": DB_CONFIG['user']},
                        {"@key": "passwd", "$": DB_CONFIG['password']},
                        {"@key": "namespace", "$": f"http://{self.workspace}"},
                        
                        # === SQLç”Ÿæˆç®¡ç†å‚æ•° ===
                        {"@key": "Expose primary keys", "$": "true"},
                        {"@key": "preparedStatements", "$": "true"},
                        {"@key": "Max open prepared statements", "$": "50"},
                        
                        # === æ•°æ®åº“äº¤äº’ç®¡ç†å‚æ•° ===
                        {"@key": "Loose bbox", "$": "true"},
                        {"@key": "Estimated extends", "$": "true"},
                        {"@key": "encode functions", "$": "true"},
                        {"@key": "Support on the fly geometry simplification", "$": "true"},
                        {"@key": "Method used to simplify geometries", "$": "PRESERVETOPOLOGY"},
                        
                        # === è¿æ¥æ± å‚æ•° ===
                        {"@key": "validate connections", "$": "true"},
                        {"@key": "Connection timeout", "$": "20"},
                        {"@key": "min connections", "$": "1"},
                        {"@key": "max connections", "$": "10"},
                        {"@key": "fetch size", "$": "1000"},
                        {"@key": "Batch insert size", "$": "1"},
                        
                        # === è¿æ¥æ± ç»´æŠ¤å‚æ•° ===
                        {"@key": "Test while idle", "$": "true"},
                        {"@key": "Evictor run periodicity", "$": "300"},
                        {"@key": "Max connection idle time", "$": "300"},
                        {"@key": "Evictor tests per run", "$": "3"},
                        {"@key": "Min evictable idle time", "$": "300"}
                    ]
                }
            }
        }
        
        # å‘é€è¯·æ±‚åˆ›å»ºæ•°æ®å­˜å‚¨
        url = f"{self.rest_url}/workspaces/{self.workspace}/datastores"
        headers = {'Content-Type': 'application/json'}
        
        print(f"å‘é€è¯·æ±‚åˆ°: {url}")
        
        try:
            response = requests.post(
                url, 
                json=datastore_config,
                auth=self.auth,
                headers=headers,
                timeout=60
            )
            
            print(f"åˆ›å»ºæ•°æ®å­˜å‚¨å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.text:
                print(f"å“åº”å†…å®¹: {response.text[:500]}...")
            
            if response.status_code not in [201, 200]:
                # å°è¯•è·å–æ›´å¤šé”™è¯¯ä¿¡æ¯
                try:
                    error_detail = response.json()
                    print(f"é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail)}")
                except:
                    pass
                
                raise Exception(f"åˆ›å»ºPostGISæ•°æ®å­˜å‚¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
            
            # éªŒè¯æ•°æ®å­˜å‚¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
            time.sleep(2)  # ç­‰å¾…GeoServerå¤„ç†
            
            verify_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}.json"
            print(f"éªŒè¯URL: {verify_url}")
            verify_response = requests.get(verify_url, auth=self.auth)
            
            if verify_response.status_code != 200:
                raise Exception(f"PostGISæ•°æ®å­˜å‚¨åˆ›å»ºåéªŒè¯å¤±è´¥: {verify_response.text}")
            
            print(f"âœ… PostGISæ•°æ®å­˜å‚¨åˆ›å»ºå¹¶éªŒè¯æˆåŠŸ: {store_name}")
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
            raise Exception(f"åˆ›å»ºPostGISæ•°æ®å­˜å‚¨è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            print(f"âŒ å…¶ä»–å¼‚å¸¸: {str(e)}")
            raise
    
    def _publish_featuretype_from_postgis(self, store_name, table_name, featuretype_name):
        """ä»PostGISå‘å¸ƒè¦ç´ ç±»å‹
        
        æ ¹æ®GeoServerå®˜æ–¹æ–‡æ¡£ï¼Œä»å·²å­˜åœ¨çš„PostGISè¡¨å‘å¸ƒè¦ç´ ç±»å‹
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
            table_name: PostGISè¡¨å
            featuretype_name: è¦ç´ ç±»å‹åç§°
            
        Returns:
            è¦ç´ ç±»å‹ä¿¡æ¯
        """
        print(f"ä»PostGISå‘å¸ƒè¦ç´ ç±»å‹: è¡¨={table_name}, è¦ç´ ç±»å‹={featuretype_name}")
        
        # æ„å»ºè¦ç´ ç±»å‹é…ç½®
        featuretype_config = {
            "featureType": {
                "name": featuretype_name,
                "nativeName": table_name,
                "namespace": {
                    "name": self.workspace,
                    "href": f"{self.rest_url}/namespaces/{self.workspace}.json"
                },
                "title": featuretype_name,
                "abstract": f"ä»PostGISè¡¨ {table_name} å‘å¸ƒçš„è¦ç´ ç±»å‹",
                "enabled": True,
                "srs": "EPSG:4326",
                "projectionPolicy": "REPROJECT_TO_DECLARED",
                "store": {
                    "@class": "dataStore",
                    "name": f"{self.workspace}:{store_name}",
                    "href": f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}.json"
                }
            }
        }
        
        # å‘é€è¯·æ±‚å‘å¸ƒè¦ç´ ç±»å‹
        url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/featuretypes"
        headers = {'Content-Type': 'application/json'}
        
        response = requests.post(
            url, 
            json=featuretype_config,
            auth=self.auth,
            headers=headers,
            timeout=60
        )
        
        print(f"å‘å¸ƒè¦ç´ ç±»å‹å“åº”çŠ¶æ€ç : {response.status_code}")
        if response.text:
            print(f"å“åº”å†…å®¹: {response.text[:500]}...")
        
        if response.status_code not in [201, 200]:
            raise Exception(f"å‘å¸ƒè¦ç´ ç±»å‹å¤±è´¥: HTTP {response.status_code} - {response.text}")
        
        # ç­‰å¾…GeoServerå¤„ç†
        time.sleep(3)
        
        # è·å–å‘å¸ƒåçš„è¦ç´ ç±»å‹è¯¦ç»†ä¿¡æ¯
        try:
            featuretype_info = self._get_featuretype_info(store_name, featuretype_name)
            return featuretype_info
        except Exception as e:
            print(f"è·å–è¦ç´ ç±»å‹ä¿¡æ¯å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•: {str(e)}")
            
            # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨è¡¨å
            try:
                featuretype_info = self._get_featuretype_info(store_name, table_name)
                return featuretype_info
            except Exception as e2:
                print(f"ä½¿ç”¨è¡¨åè·å–ä¹Ÿå¤±è´¥ï¼Œè¿”å›åŸºæœ¬é…ç½®: {str(e2)}")
                
                # è¿”å›åŸºæœ¬çš„è¦ç´ ç±»å‹ä¿¡æ¯
                return {
                    "featureType": {
                        "name": featuretype_name,
                        "nativeName": table_name,
                        "namespace": {"name": self.workspace},
                        "title": featuretype_name,
                        "abstract": f"ä»PostGISè¡¨ {table_name} å‘å¸ƒçš„è¦ç´ ç±»å‹",
                        "enabled": True,
                        "srs": "EPSG:4326",
                        "projectionPolicy": "REPROJECT_TO_DECLARED"
                    }
                }
    
    def _cleanup_failed_geojson_publish(self, store_name, table_name=None):
        """æ¸…ç†GeoJSONå‘å¸ƒå¤±è´¥åçš„èµ„æº
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
            table_name: PostGISè¡¨åï¼ˆå¯é€‰ï¼‰
        """
        print(f"æ¸…ç†GeoJSONå‘å¸ƒå¤±è´¥çš„èµ„æº...")
        
        try:
            # 1. æ¸…ç†GeoServerä¸­çš„æ•°æ®å­˜å‚¨
            self._cleanup_existing_datastore(store_name)
            print(f"âœ… æ¸…ç†GeoServeræ•°æ®å­˜å‚¨å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†GeoServeræ•°æ®å­˜å‚¨å¤±è´¥: {str(e)}")
        
        try:
            # 2. æ¸…ç†æ•°æ®åº“ä¸­çš„è®°å½•
            self._delete_related_records_from_db(store_name)
            print(f"âœ… æ¸…ç†æ•°æ®åº“è®°å½•å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ•°æ®åº“è®°å½•å¤±è´¥: {str(e)}")
        
        # 3. å¯é€‰ï¼šæ¸…ç†PostGISè¡¨ï¼ˆè°¨æ…æ“ä½œï¼‰
        if table_name:
            try:
                from services.postgis_service import PostGISService
                postgis_service = PostGISService()
                postgis_service._drop_table_if_exists(table_name)
                print(f"âœ… æ¸…ç†PostGISè¡¨å®Œæˆ: {table_name}")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†PostGISè¡¨å¤±è´¥: {str(e)}")
        
        print(f"âœ… èµ„æºæ¸…ç†å®Œæˆ")

    def _cleanup_failed_publish(self, store_name, store_type='datastore'):
        """æ¸…ç†å‘å¸ƒå¤±è´¥åçš„èµ„æº
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
            store_type: å­˜å‚¨ç±»å‹ ('datastore' æˆ– 'coveragestore')
        """
        print(f"æ¸…ç†{store_type}å‘å¸ƒå¤±è´¥çš„èµ„æº: {store_name}")
        
        try:
            # 1. æ¸…ç†GeoServerä¸­çš„å­˜å‚¨
            if store_type == 'datastore':
                self._cleanup_existing_datastore(store_name)
            elif store_type == 'coveragestore':
                self._cleanup_existing_coveragestore(store_name)
            print(f"âœ… æ¸…ç†GeoServer {store_type}å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†GeoServer {store_type}å¤±è´¥: {str(e)}")
        
        try:
            # 2. æ¸…ç†æ•°æ®åº“ä¸­çš„è®°å½•
            self._delete_related_records_from_db(store_name)
            print(f"âœ… æ¸…ç†æ•°æ®åº“è®°å½•å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ•°æ®åº“è®°å½•å¤±è´¥: {str(e)}")
        
        print(f"âœ… {store_type}èµ„æºæ¸…ç†å®Œæˆ")
    
    def _cleanup_existing_coveragestore(self, store_name):
        """æ¸…ç†å¯èƒ½å­˜åœ¨çš„è¦†ç›–å­˜å‚¨
        
        å¢å¼ºç‰ˆæ¸…ç†æ–¹æ³•ï¼Œç¡®ä¿åˆ é™¤GeoServerä¸­çš„coveragestoreåŠå…¶ç‰©ç†æ–‡ä»¶
        """
        try:
            print(f"æ£€æŸ¥è¦†ç›–å­˜å‚¨æ˜¯å¦å­˜åœ¨: {store_name}")
            check_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}"
            check_response = requests.get(check_url, auth=self.auth)
            
            if check_response.status_code == 200:
                print(f"âš ï¸ è¦†ç›–å­˜å‚¨ {store_name} å·²å­˜åœ¨ï¼Œå¼€å§‹åˆ é™¤")
                
                # æ­¥éª¤1: å…ˆè·å–å¹¶åˆ é™¤æ‰€æœ‰ç›¸å…³çš„coverage
                print(f"æ­¥éª¤1: åˆ é™¤ç›¸å…³çš„coverage")
                try:
                    coverages_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages.json"
                    coverages_response = requests.get(coverages_url, auth=self.auth)
                    
                    if coverages_response.status_code == 200:
                        coverages_data = coverages_response.json()
                        if 'coverages' in coverages_data and 'coverage' in coverages_data['coverages']:
                            coverages = coverages_data['coverages']['coverage']
                            if isinstance(coverages, list):
                                coverage_list = coverages
                            else:
                                coverage_list = [coverages]
                            
                            for coverage in coverage_list:
                                coverage_name = coverage['name']
                                print(f"  åˆ é™¤coverage: {coverage_name}")
                                coverage_delete_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages/{coverage_name}?recurse=true"
                                coverage_delete_response = requests.delete(coverage_delete_url, auth=self.auth)
                                print(f"  coverageåˆ é™¤å“åº”: {coverage_delete_response.status_code}")
                except Exception as e:
                    print(f"  åˆ é™¤coverageæ—¶å‡ºé”™: {str(e)}")
                
                # ç­‰å¾…å¤„ç†
                time.sleep(1)
                
                # æ­¥éª¤2: åˆ é™¤coveragestoreï¼Œä½¿ç”¨purge=allå‚æ•°ç¡®ä¿åˆ é™¤ç‰©ç†æ–‡ä»¶
                print(f"æ­¥éª¤2: åˆ é™¤coveragestoreåŠç‰©ç†æ–‡ä»¶")
                delete_url = f"{check_url}?recurse=true&purge=all"
                print(f"åˆ é™¤URL: {delete_url}")
                
                delete_response = requests.delete(delete_url, auth=self.auth)
                print(f"coveragestoreåˆ é™¤å“åº”çŠ¶æ€ç : {delete_response.status_code}")
                print(f"coveragestoreåˆ é™¤å“åº”å†…å®¹: {delete_response.text}")
                
                if delete_response.status_code in [200, 404]:
                    print(f"âœ… coveragestoreåˆ é™¤æˆåŠŸ")
                else:
                    print(f"âš ï¸ coveragestoreåˆ é™¤å¤±è´¥ï¼Œå°è¯•å…¶ä»–å‚æ•°")
                    
                    # å°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°ç»„åˆ
                    for purge_param in ['true', 'metadata', 'all']:
                        print(f"  å°è¯•purge={purge_param}")
                        alt_delete_url = f"{check_url}?recurse=true&purge={purge_param}"
                        alt_delete_response = requests.delete(alt_delete_url, auth=self.auth)
                        print(f"  å“åº”çŠ¶æ€ç : {alt_delete_response.status_code}")
                        
                        if alt_delete_response.status_code in [200, 404]:
                            print(f"  âœ… ä½¿ç”¨purge={purge_param}åˆ é™¤æˆåŠŸ")
                            break
                    else:
                        # æœ€åå°è¯•ä¸ä½¿ç”¨purgeå‚æ•°
                        print(f"  æœ€åå°è¯•ä¸ä½¿ç”¨purgeå‚æ•°")
                        final_delete_url = f"{check_url}?recurse=true"
                        final_delete_response = requests.delete(final_delete_url, auth=self.auth)
                        print(f"  æœ€ç»ˆåˆ é™¤å“åº”: {final_delete_response.status_code}")
                
                # ç­‰å¾…GeoServerå¤„ç†å®Œæˆ
                time.sleep(3)
                
                # æ­¥éª¤3: éªŒè¯åˆ é™¤ç»“æœ
                print(f"æ­¥éª¤3: éªŒè¯åˆ é™¤ç»“æœ")
                verify_response = requests.get(check_url, auth=self.auth)
                if verify_response.status_code == 404:
                    print(f"âœ… è¦†ç›–å­˜å‚¨åˆ é™¤éªŒè¯æˆåŠŸ")
                else:
                    print(f"âš ï¸ è¦†ç›–å­˜å‚¨å¯èƒ½æœªå®Œå…¨åˆ é™¤ï¼ŒçŠ¶æ€ç : {verify_response.status_code}")
                    print(f"éªŒè¯å“åº”å†…å®¹: {verify_response.text}")
                    
                    # é¢å¤–çš„æ¸…ç†æ­¥éª¤ï¼šç›´æ¥é€šè¿‡å·¥ä½œç©ºé—´åˆ é™¤
                    print(f"å°è¯•é€šè¿‡å·¥ä½œç©ºé—´çº§åˆ«åˆ é™¤")
                    workspace_delete_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}?recurse=true&purge=all"
                    workspace_delete_response = requests.delete(workspace_delete_url, auth=self.auth)
                    print(f"å·¥ä½œç©ºé—´çº§åˆ«åˆ é™¤å“åº”: {workspace_delete_response.status_code}")
                    time.sleep(2)
                
                # æ­¥éª¤4: æ¸…ç†æ•°æ®åº“è®°å½•
                print(f"æ­¥éª¤4: æ¸…ç†æ•°æ®åº“ä¸­çš„ç›¸å…³è®°å½•")
                try:
                    # åˆ é™¤geoserver_storesè¡¨ä¸­çš„è®°å½•
                    self._delete_related_records_from_db(store_name)
                    print(f"âœ… æ¸…ç†æ•°æ®åº“è®°å½•å®Œæˆ")
                except Exception as db_error:
                    print(f"âš ï¸ æ¸…ç†æ•°æ®åº“è®°å½•å¤±è´¥: {str(db_error)}")
                
                print(f"âœ… æ¸…ç†GeoServer coveragestoreå®Œæˆ")
                    
            elif check_response.status_code == 404:
                print(f"âœ… è¦†ç›–å­˜å‚¨ {store_name} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
                
                # å³ä½¿GeoServerä¸­ä¸å­˜åœ¨ï¼Œä¹Ÿæ£€æŸ¥å¹¶æ¸…ç†æ•°æ®åº“è®°å½•
                print(f"æ£€æŸ¥å¹¶æ¸…ç†æ•°æ®åº“ä¸­å¯èƒ½æ®‹ç•™çš„è®°å½•")
                try:
                    self._delete_related_records_from_db(store_name)
                    print(f"âœ… æ¸…ç†æ•°æ®åº“è®°å½•å®Œæˆ")
                except Exception as db_error:
                    print(f"âš ï¸ æ¸…ç†æ•°æ®åº“è®°å½•å¤±è´¥: {str(db_error)}")
            else:
                print(f"âš ï¸ æ£€æŸ¥è¦†ç›–å­˜å‚¨çŠ¶æ€å¼‚å¸¸: {check_response.status_code} - {check_response.text}")
                
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¦†ç›–å­˜å‚¨å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç»§ç»­æ‰§è¡Œå‘å¸ƒæµç¨‹
    
    def _create_empty_shapefile_datastore(self, store_name):
        """åœ¨GeoServerä¸­åˆ›å»ºç©ºçš„Shapefileæ•°æ®å­˜å‚¨
        
        è¿™æ˜¯åˆ›å»ºShapefileæ•°æ®å­˜å‚¨çš„æ¨èæ–¹å¼ï¼š
        1. å…ˆåˆ›å»ºç©ºçš„datastore
        2. ç„¶åä¸Šä¼ æ–‡ä»¶åˆ°å·²å­˜åœ¨çš„datastore
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
        """
        print(f"åœ¨GeoServerä¸­åˆ›å»ºç©ºçš„Shapefileæ•°æ®å­˜å‚¨: {store_name}")
        
        # å…ˆæ¸…ç†å¯èƒ½å­˜åœ¨çš„åŒåæ•°æ®å­˜å‚¨
        self._cleanup_existing_datastore(store_name)
        
        # æ„å»ºShapefileæ•°æ®å­˜å‚¨é…ç½®
        datastore_config = {
            "dataStore": {
                "name": store_name,
                "type": "Shapefile",
                "enabled": True,
                "workspace": {
                    "name": self.workspace,
                    "href": f"{self.rest_url}/workspaces/{self.workspace}.json"
                },
                "connectionParameters": {
                    "entry": [
                        {"@key": "url", "$": f"file:data/{self.workspace}/{store_name}/"},
                        {"@key": "namespace", "$": f"http://{self.workspace}"},
                        {"@key": "create spatial index", "$": "true"},
                        {"@key": "charset", "$": "UTF-8"}
                    ]
                }
            }
        }
        
        # å‘é€è¯·æ±‚åˆ›å»ºæ•°æ®å­˜å‚¨
        url = f"{self.rest_url}/workspaces/{self.workspace}/datastores"
        headers = {'Content-Type': 'application/json'}
        
        response = requests.post(
            url, 
            json=datastore_config,
            auth=self.auth,
            headers=headers,
            timeout=60
        )
        
        print(f"åˆ›å»ºShapefileæ•°æ®å­˜å‚¨å“åº”çŠ¶æ€ç : {response.status_code}")
        if response.text:
            print(f"å“åº”å†…å®¹: {response.text[:500]}...")
        
        if response.status_code not in [201, 200]:
            raise Exception(f"åˆ›å»ºShapefileæ•°æ®å­˜å‚¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
        
        # éªŒè¯æ•°æ®å­˜å‚¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
        time.sleep(1)  # ç­‰å¾…GeoServerå¤„ç†
        
        verify_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}.json"
        verify_response = requests.get(verify_url, auth=self.auth)
        
        if verify_response.status_code != 200:
            raise Exception(f"Shapefileæ•°æ®å­˜å‚¨åˆ›å»ºåéªŒè¯å¤±è´¥: {verify_response.text}")
        
        print(f"âœ… Shapefileæ•°æ®å­˜å‚¨åˆ›å»ºå¹¶éªŒè¯æˆåŠŸ: {store_name}")
    
    def _upload_zip_to_geoserver_datastore(self, zip_path, store_name):
        """ç›´æ¥ä¸Šä¼ ZIPæ–‡ä»¶åˆ°GeoServeræ•°æ®å­˜å‚¨
        
        é‡‡ç”¨GeoServerå®˜æ–¹æ¨èçš„æ–¹å¼ï¼Œé€šè¿‡REST APIç›´æ¥ä¸Šä¼ ZIPæ–‡ä»¶ã€‚
        GeoServerä¼šè‡ªåŠ¨ï¼š
        1. è§£å‹ZIPæ–‡ä»¶
        2. éªŒè¯Shapefileæ–‡ä»¶å®Œæ•´æ€§
        3. å¤„ç†ä¸­æ–‡æ–‡ä»¶åå’Œç‰¹æ®Šå­—ç¬¦
        4. åˆ›å»ºæ•°æ®å­˜å‚¨å’Œè¦ç´ ç±»å‹
        
        Args:
            zip_path: ZIPæ–‡ä»¶è·¯å¾„
            store_name: æ•°æ®å­˜å‚¨åç§°
        """
        print(f"ç›´æ¥ä¸Šä¼ ZIPæ–‡ä»¶åˆ°GeoServeræ•°æ®å­˜å‚¨: {zip_path}")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(zip_path):
            raise Exception(f"ZIPæ–‡ä»¶ä¸å­˜åœ¨: {zip_path}")
        
        # ä½¿ç”¨GeoServer REST APIä¸Šä¼ ZIPæ–‡ä»¶
        # PUT /workspaces/{ws}/datastores/{ds}/file.shp
        datastore_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/file.shp"
        headers = {'Content-Type': 'application/zip'}
        
        print(f"ä¸Šä¼ URL: {datastore_url}")
        print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(zip_path)} å­—èŠ‚")
        
        try:
            with open(zip_path, 'rb') as f:
                response = requests.put(
                    datastore_url,
                    data=f,
                    headers=headers,
                    auth=self.auth,
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶ï¼Œé€‚åˆå¤§æ–‡ä»¶
                )
            
            print(f"ZIPä¸Šä¼ å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.text:
                print(f"å“åº”å†…å®¹: {response.text[:500]}...")
            
            if response.status_code not in [201, 200]:
                raise Exception(f"ä¸Šä¼ ZIPæ–‡ä»¶å¤±è´¥: HTTP {response.status_code} - {response.text}")
            
            print("âœ… ZIPæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ŒGeoServeræ­£åœ¨è‡ªåŠ¨å¤„ç†...")
            
        except requests.exceptions.Timeout:
            raise Exception("ä¸Šä¼ ZIPæ–‡ä»¶è¶…æ—¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å¤§å°å’Œç½‘ç»œè¿æ¥")
        except requests.exceptions.RequestException as e:
            raise Exception(f"ä¸Šä¼ ZIPæ–‡ä»¶ç½‘ç»œé”™è¯¯: {str(e)}")
        except Exception as e:
            raise Exception(f"ä¸Šä¼ ZIPæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _get_auto_created_featuretype_info(self, store_name):
        """è·å–GeoServerè‡ªåŠ¨åˆ›å»ºçš„è¦ç´ ç±»å‹ä¿¡æ¯
        
        å½“ZIPæ–‡ä»¶ä¸Šä¼ æˆåŠŸåï¼ŒGeoServerä¼šè‡ªåŠ¨åˆ›å»ºè¦ç´ ç±»å‹ã€‚
        æ­¤æ–¹æ³•å°è¯•è·å–è¿™äº›è‡ªåŠ¨åˆ›å»ºçš„è¦ç´ ç±»å‹ä¿¡æ¯ã€‚
        
        Args:
            store_name: æ•°æ®å­˜å‚¨åç§°
            
        Returns:
            è¦ç´ ç±»å‹ä¿¡æ¯
        """
        print(f"è·å–æ•°æ®å­˜å‚¨ {store_name} ä¸­è‡ªåŠ¨åˆ›å»ºçš„è¦ç´ ç±»å‹...")
        
        # é¦–å…ˆè·å–æ•°æ®å­˜å‚¨ä¸­çš„è¦ç´ ç±»å‹åˆ—è¡¨
        featuretypes_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/featuretypes.json"
        
        try:
            response = requests.get(featuretypes_url, auth=self.auth)
            
            if response.status_code != 200:
                raise Exception(f"è·å–è¦ç´ ç±»å‹åˆ—è¡¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
            
            data = response.json()
            print(f"è¦ç´ ç±»å‹åˆ—è¡¨å“åº”: {data}")
            
            # è§£æè¦ç´ ç±»å‹åˆ—è¡¨
            featuretype_name = None
            if 'featureTypes' in data and 'featureType' in data['featureTypes']:
                feature_types = data['featureTypes']['featureType']
                
                if isinstance(feature_types, list) and len(feature_types) > 0:
                    featuretype_name = feature_types[0]['name']
                elif isinstance(feature_types, dict):
                    featuretype_name = feature_types['name']
            
            if not featuretype_name:
                raise Exception("æœªæ‰¾åˆ°è‡ªåŠ¨åˆ›å»ºçš„è¦ç´ ç±»å‹")
            
            print(f"æ‰¾åˆ°è‡ªåŠ¨åˆ›å»ºçš„è¦ç´ ç±»å‹: {featuretype_name}")
            
            # è·å–è¦ç´ ç±»å‹çš„è¯¦ç»†ä¿¡æ¯
            featuretype_detail_url = f"{self.rest_url}/workspaces/{self.workspace}/datastores/{store_name}/featuretypes/{featuretype_name}.json"
            detail_response = requests.get(featuretype_detail_url, auth=self.auth)
            
            if detail_response.status_code != 200:
                raise Exception(f"è·å–è¦ç´ ç±»å‹è¯¦ç»†ä¿¡æ¯å¤±è´¥: HTTP {detail_response.status_code} - {detail_response.text}")
            
            featuretype_info = detail_response.json()
            print(f"âœ… æˆåŠŸè·å–è¦ç´ ç±»å‹è¯¦ç»†ä¿¡æ¯: {featuretype_name}")
            
            return featuretype_info
            
        except Exception as e:
            print(f"âŒ è·å–è‡ªåŠ¨åˆ›å»ºçš„è¦ç´ ç±»å‹å¤±è´¥: {str(e)}")
            raise Exception(f"è·å–è‡ªåŠ¨åˆ›å»ºçš„è¦ç´ ç±»å‹å¤±è´¥: {str(e)}")

    def reset_geoserver_caches(self):
        """é‡ç½®GeoServeræ‰€æœ‰ç¼“å­˜å’Œè¿æ¥"""
        try:
            print("=== é‡ç½®GeoServerç¼“å­˜ ===")
            
            # 1. é‡ç½®æ‰€æœ‰ç¼“å­˜çš„REST APIç«¯ç‚¹
            reset_endpoints = [
                '/rest/reset',  # é‡ç½®æ‰€æœ‰ç¼“å­˜
                '/rest/reload',  # é‡æ–°åŠ è½½é…ç½®
            ]
            
            results = []
            for endpoint in reset_endpoints:
                try:
                    url = f"{self.url}{endpoint}"
                    print(f"è°ƒç”¨é‡ç½®API: {url}")
                    
                    response = requests.post(
                        url,
                        auth=self.auth,
                        headers={'Content-Type': 'application/json'},
                        timeout=30
                    )
                    
                    if response.status_code in [200, 201, 202]:
                        results.append({
                            'endpoint': endpoint,
                            'success': True,
                            'status_code': response.status_code,
                            'message': 'OK'
                        })
                        print(f"âœ… {endpoint} é‡ç½®æˆåŠŸ")
                    else:
                        results.append({
                            'endpoint': endpoint,
                            'success': False,
                            'status_code': response.status_code,
                            'message': response.text
                        })
                        print(f"âš ï¸ {endpoint} é‡ç½®å¤±è´¥: {response.status_code}")
                        
                except requests.exceptions.RequestException as e:
                    results.append({
                        'endpoint': endpoint,
                        'success': False,
                        'error': str(e)
                    })
                    print(f"âŒ {endpoint} è¯·æ±‚å¤±è´¥: {str(e)}")
            
            return {
                'success': True,
                'message': 'GeoServerç¼“å­˜é‡ç½®å®Œæˆ',
                'results': results
            }
            
        except Exception as e:
            print(f"é‡ç½®GeoServerç¼“å­˜å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }

    def get_file_cleanup_paths(self, file_id, geoserver_data_dir=None):
        """è·å–éœ€è¦æ¸…ç†çš„GeoServeræ–‡ä»¶è·¯å¾„"""
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®ç›®å½•ï¼Œä»é…ç½®æ–‡ä»¶è·å–
            if not geoserver_data_dir:
                from config import GEOSERVER_CONFIG
                import os
                
                # æ ¹æ®æ“ä½œç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æ•°æ®ç›®å½•
                if os.name == 'nt':  # Windows
                    geoserver_data_dir = GEOSERVER_CONFIG['data_dir']['windows']
                else:  # Linux/Unix
                    geoserver_data_dir = GEOSERVER_CONFIG['data_dir']['linux']
                
                # å¦‚æœé…ç½®çš„ç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
                if not os.path.exists(geoserver_data_dir):
                    geoserver_data_dir = GEOSERVER_CONFIG['data_dir']['default']
                    print(f"âš ï¸ é…ç½®çš„GeoServeræ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {geoserver_data_dir}")
                
                print(f"ä½¿ç”¨GeoServeræ•°æ®ç›®å½•: {geoserver_data_dir}")
            
            cleanup_paths = []
            
            # 1. åŸºäºfile_idç”Ÿæˆå¯èƒ½çš„å­˜å‚¨åç§°
            store_name = f"file_{file_id}"
            
            # 2. è§„èŒƒåŒ–è·¯å¾„åˆ†éš”ç¬¦
            import os
            sep = os.sep
            geoserver_data_dir = geoserver_data_dir.rstrip(sep) + sep
            
            # 3. å¯èƒ½çš„æ–‡ä»¶è·¯å¾„æ¨¡å¼
            possible_paths = [
                # Shapefileç›¸å…³
                f"{geoserver_data_dir}data{sep}{store_name}{sep}*.shp",
                f"{geoserver_data_dir}data{sep}{store_name}{sep}*.shx",
                f"{geoserver_data_dir}data{sep}{store_name}{sep}*.dbf",
                f"{geoserver_data_dir}data{sep}{store_name}{sep}*.prj",
                f"{geoserver_data_dir}data{sep}{store_name}{sep}*.cpg",
                f"{geoserver_data_dir}data{sep}{store_name}{sep}",  # æ•´ä¸ªç›®å½•
                
                # GeoTIFFç›¸å…³
                f"{geoserver_data_dir}coverages{sep}{store_name}{sep}*.tif",
                f"{geoserver_data_dir}coverages{sep}{store_name}{sep}*.tiff",
                f"{geoserver_data_dir}coverages{sep}{store_name}{sep}",  # æ•´ä¸ªç›®å½•
                
                # å…¶ä»–å¯èƒ½çš„ä½ç½®
                f"{geoserver_data_dir}workspaces{sep}shpservice{sep}{store_name}{sep}",
                f"{geoserver_data_dir}tmp{sep}{store_name}{sep}",
                
                # æ–°çš„å¯èƒ½ä½ç½®ï¼ˆåŸºäºGeoServeræ ‡å‡†å¸ƒå±€ï¼‰
                f"{geoserver_data_dir}workspaces{sep}shpservice{sep}*{store_name}*",
                f"{geoserver_data_dir}styles{sep}*{store_name}*",
            ]
            
            # 4. æ£€æŸ¥å®é™…å­˜åœ¨çš„æ–‡ä»¶
            import glob
            import os
            
            for pattern in possible_paths:
                try:
                    if pattern.endswith(sep) and os.path.isdir(pattern.rstrip(sep)):
                        # ç›®å½•å­˜åœ¨
                        cleanup_paths.append(pattern.rstrip(sep))
                    elif '*' in pattern:
                        # é€šé…ç¬¦æ¨¡å¼
                        matches = glob.glob(pattern)
                        cleanup_paths.extend(matches)
                    elif os.path.exists(pattern):
                        # å…·ä½“æ–‡ä»¶å­˜åœ¨
                        cleanup_paths.append(pattern)
                except Exception as e:
                    print(f"æ£€æŸ¥è·¯å¾„ {pattern} æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # 5. å»é‡
            cleanup_paths = list(set(cleanup_paths))
            
            print(f"æ‰¾åˆ° {len(cleanup_paths)} ä¸ªéœ€è¦æ¸…ç†çš„è·¯å¾„")
            for path in cleanup_paths:
                print(f"  - {path}")
            
            return cleanup_paths
            
        except Exception as e:
            print(f"è·å–æ¸…ç†è·¯å¾„å¤±è´¥: {str(e)}")
            return []

    def force_delete_file(self, file_path):
        """å¼ºåˆ¶åˆ é™¤æ–‡ä»¶ï¼ˆå³ä½¿æ˜¯åªè¯»æ–‡ä»¶ï¼‰"""
        try:
            if os.path.exists(file_path):
                # å¦‚æœæ˜¯åªè¯»æ–‡ä»¶ï¼Œå…ˆä¿®æ”¹æƒé™
                if not os.access(file_path, os.W_OK):
                    os.chmod(file_path, stat.S_IWRITE)
                os.remove(file_path)
                print(f"å¼ºåˆ¶åˆ é™¤æ–‡ä»¶æˆåŠŸ: {file_path}")
                return True
        except Exception as e:
            print(f"å¼ºåˆ¶åˆ é™¤æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
            return False
    
        """åˆ›å»ºImageMosaicç±»å‹çš„CoverageStoreä»¥æ”¯æŒé€æ˜åº¦è®¾ç½®
        
        æ ¹æ®GeoServerå®˜æ–¹REST APIæ–‡æ¡£ï¼š
        PUT /workspaces/<ws>/coveragestores/<cs>/file.imagemosaic
        """
        try:
            import os
            import tempfile
            import shutil
            import zipfile
            
            # é¦–å…ˆéªŒè¯TIFæ–‡ä»¶
            print(f"éªŒè¯TIFæ–‡ä»¶ç”¨äºImageMosaic...")
            is_valid, validation_msg = self._validate_geotiff_file(tif_path)
            if not is_valid:
                print(f"âŒ TIFæ–‡ä»¶éªŒè¯å¤±è´¥: {validation_msg}")
                return False
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºImageMosaic
            temp_dir = tempfile.mkdtemp(prefix='geoserver_mosaic_')
            print(f"åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºImageMosaic: {temp_dir}")
            
            try:
                # å¤åˆ¶TIFæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                tif_filename = os.path.basename(tif_path)
                temp_tif_path = os.path.join(temp_dir, tif_filename)
                shutil.copy2(tif_path, temp_tif_path)
                print(f"å¤åˆ¶TIFæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•: {temp_tif_path}")
                
                # åˆ›å»ºç®€åŒ–çš„indexer.propertiesæ–‡ä»¶ï¼ˆæœ€å°é…ç½®ï¼‰
                indexer_content = """# ImageMosaicæœ€å°é…ç½®
Schema=*the_geom:Polygon,location:String
Caching=false
CheckAuxiliaryMetadata=false
CanBeEmpty=false
Recursive=false
AbsolutePath=false
"""
                indexer_path = os.path.join(temp_dir, 'indexer.properties')
                with open(indexer_path, 'w', encoding='utf-8') as f:
                    f.write(indexer_content)
                print(f"åˆ›å»ºindexer.properties: {indexer_path}")
                
                # å‹ç¼©ä¸ºzipæ–‡ä»¶
                zip_path = os.path.join(tempfile.gettempdir(), f"{store_name}_mosaic.zip")
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for root, dirs, files in os.walk(temp_dir):
                        for file in files:
                            file_path = os.path.join(root, file)
                            arc_name = os.path.relpath(file_path, temp_dir)
                            zipf.write(file_path, arc_name)
                print(f"åˆ›å»ºImageMosaicå‹ç¼©åŒ…: {zip_path}")
                
                # é€šè¿‡REST APIåˆ›å»ºImageMosaic coveragestore
                # æ ¹æ®å®˜æ–¹æ–‡æ¡£çš„æ­£ç¡®ç«¯ç‚¹æ ¼å¼
                url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/file.imagemosaic"
                print(f"ImageMosaic coveragestoreåˆ›å»ºURL: {url}")
                
                # è®¾ç½®æ­£ç¡®çš„HTTP headers
                headers = {
                    'Content-Type': 'application/zip',
                    'Accept': 'application/xml'
                }
                
                # è¯»å–zipæ–‡ä»¶å¹¶å‘é€PUTè¯·æ±‚
                with open(zip_path, 'rb') as f:
                    response = requests.put(
                        url,
                        data=f,
                        headers=headers,
                        auth=self.auth,
                        timeout=300
                    )
                
                print(f"ImageMosaic coveragestoreåˆ›å»ºå“åº”çŠ¶æ€ç : {response.status_code}")
                if response.text:
                    print(f"å“åº”å†…å®¹: {response.text[:500] if response.text else 'None'}...")
                
                if response.status_code in [200, 201]:
                    print(f"âœ… ImageMosaic coveragestore '{store_name}' åˆ›å»ºæˆåŠŸ")
                    return True
                else:
                    print(f"âŒ ImageMosaic coveragestoreåˆ›å»ºå¤±è´¥: {response.status_code}")
                    if response.text:
                        print(f"é”™è¯¯è¯¦æƒ…: {response.text}")
                    return False
                    
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if 'zip_path' in locals() and os.path.exists(zip_path):
                        os.remove(zip_path)
                        print(f"æ¸…ç†ä¸´æ—¶zipæ–‡ä»¶: {zip_path}")
                except Exception as cleanup_error:
                    print(f"æ¸…ç†zipæ–‡ä»¶å¤±è´¥: {cleanup_error}")
                    
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                try:
                    shutil.rmtree(temp_dir)
                    print(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
                except Exception as cleanup_error:
                    print(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {cleanup_error}")
                    
        except Exception as e:
            print(f"åˆ›å»ºImageMosaic coveragestoreå¤±è´¥: {str(e)}")
            return False
    
    def _configure_coverage_transparency(self, store_name):
        """é…ç½®Coverageçš„é€æ˜åº¦å‚æ•°"""
        try:
            # è·å–coverageåç§°
            coverages_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages.json"
            response = requests.get(coverages_url, auth=self.auth, timeout=30)
            
            if response.status_code != 200:
                print(f"è·å–coverageåˆ—è¡¨å¤±è´¥: {response.text}")
                return
                
            coverages_data = response.json()
            coverage_name = None
            
            if 'coverages' in coverages_data and 'coverage' in coverages_data['coverages']:
                coverages = coverages_data['coverages']['coverage']
                if isinstance(coverages, list) and len(coverages) > 0:
                    coverage_name = coverages[0]['name']
                elif isinstance(coverages, dict):
                    coverage_name = coverages['name']
            
            if not coverage_name:
                coverage_name = store_name
                
            print(f"é…ç½®coverageé€æ˜åº¦: {coverage_name}")
            
            # é€šè¿‡Coverage Editorå‚æ•°è®¾ç½®é€æ˜åº¦
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£è®¾ç½®èƒŒæ™¯è‰²ä¸ºé€æ˜
            coverage_url = f"{self.rest_url}/workspaces/{self.workspace}/coveragestores/{store_name}/coverages/{coverage_name}.xml"
            
            # è·å–å½“å‰coverageé…ç½®
            get_response = requests.get(coverage_url, auth=self.auth, timeout=30)
            
            if get_response.status_code != 200:
                print(f"è·å–coverageé…ç½®å¤±è´¥: {get_response.text}")
                return
            
            # è®¾ç½®é€æ˜åº¦å‚æ•° - ä½¿ç”¨XMLæ ¼å¼ï¼ŒæŒ‰ç…§GeoServer REST APIæ–‡æ¡£è¦æ±‚
            xml_content = """
<coverage>
  <parameters>
    <entry>
      <string>InputTransparentColor</string>
      <string>#000000</string>
    </entry>
    <entry>
      <string>OutputTransparentColor</string>
      <string>#000000</string>
    </entry>
  </parameters>
</coverage>
"""
            
            headers = {'Content-Type': 'text/xml'}
            put_response = requests.put(
                coverage_url,
                data=xml_content,
                headers=headers,
                auth=self.auth,
                timeout=60
            )
            
            if put_response.status_code in [200, 201]:
                print(f"âœ… é€æ˜åº¦å‚æ•°è®¾ç½®æˆåŠŸ")
            else:
                print(f"é€æ˜åº¦å‚æ•°è®¾ç½®å¤±è´¥: {put_response.status_code} - {put_response.text[:200]}...")
                
        except Exception as e:
            print(f"é…ç½®é€æ˜åº¦å‚æ•°å¤±è´¥: {str(e)}")
    
    def _validate_geotiff_file(self, tif_path):
        """éªŒè¯GeoTIFFæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            tif_path: GeoTIFFæ–‡ä»¶è·¯å¾„
            
        Returns:
            tuple: (is_valid, error_message)
        """
        try:
            import os
            from osgeo import gdal
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(tif_path):
                return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {tif_path}"
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(tif_path)
            if file_size == 0:
                return False, "æ–‡ä»¶å¤§å°ä¸º0å­—èŠ‚"
            
            print(f"éªŒè¯GeoTIFFæ–‡ä»¶: {tif_path} (å¤§å°: {file_size} å­—èŠ‚)")
            
            # ä½¿ç”¨GDALéªŒè¯æ–‡ä»¶
            gdal.UseExceptions()
            dataset = gdal.Open(tif_path, gdal.GA_ReadOnly)
            
            if dataset is None:
                return False, "GDALæ— æ³•æ‰“å¼€æ–‡ä»¶ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„GeoTIFFæ ¼å¼"
            
            # æ£€æŸ¥åŸºæœ¬å±æ€§
            width = dataset.RasterXSize
            height = dataset.RasterYSize
            bands = dataset.RasterCount
            projection = dataset.GetProjection()
            geotransform = dataset.GetGeoTransform()
            
            print(f"  å›¾åƒå°ºå¯¸: {width}x{height}")
            print(f"  æ³¢æ®µæ•°: {bands}")
            print(f"  æŠ•å½±ä¿¡æ¯: {projection[:100] if projection else 'None'}...")
            print(f"  åœ°ç†å˜æ¢: {geotransform}")
            
            # éªŒè¯å¿…è¦çš„åœ°ç†ä¿¡æ¯
            if not projection and not geotransform:
                return False, "æ–‡ä»¶ç¼ºå°‘åœ°ç†å‚è€ƒä¿¡æ¯ï¼ˆæŠ•å½±æˆ–åœ°ç†å˜æ¢ï¼‰"
            
            if width <= 0 or height <= 0:
                return False, f"æ— æ•ˆçš„å›¾åƒå°ºå¯¸: {width}x{height}"
            
            if bands <= 0:
                return False, f"æ— æ•ˆçš„æ³¢æ®µæ•°: {bands}"
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            band1 = dataset.GetRasterBand(1)
            datatype = gdal.GetDataTypeName(band1.DataType)
            print(f"  æ•°æ®ç±»å‹: {datatype}")
            
            # æ£€æŸ¥nodataå€¼
            nodata = band1.GetNoDataValue()
            if nodata is not None:
                print(f"  NoDataå€¼: {nodata}")
            
            dataset = None  # å…³é—­æ•°æ®é›†
            print(f"âœ… GeoTIFFæ–‡ä»¶éªŒè¯é€šè¿‡")
            return True, "æ–‡ä»¶éªŒè¯é€šè¿‡"
            
        except ImportError:
            print("âš ï¸ GDALæœªå®‰è£…ï¼Œè·³è¿‡è¯¦ç»†éªŒè¯")
            # å¦‚æœæ²¡æœ‰GDALï¼ŒåšåŸºæœ¬æ–‡ä»¶éªŒè¯
            try:
                import os
                if not os.path.exists(tif_path):
                    return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {tif_path}"
                
                file_size = os.path.getsize(tif_path)
                if file_size == 0:
                    return False, "æ–‡ä»¶å¤§å°ä¸º0å­—èŠ‚"
                
                # æ£€æŸ¥æ–‡ä»¶å¤´æ˜¯å¦ä¸ºTIFFæ ¼å¼
                with open(tif_path, 'rb') as f:
                    header = f.read(4)
                    # TIFFæ–‡ä»¶å¤´æ ‡è¯†ï¼šMM* (å¤§ç«¯) æˆ– II* (å°ç«¯)
                    if header[:2] not in [b'MM', b'II']:
                        return False, "æ–‡ä»¶å¤´ä¸ç¬¦åˆTIFFæ ¼å¼"
                
                print(f"âœ… åŸºæœ¬æ–‡ä»¶éªŒè¯é€šè¿‡ (å¤§å°: {file_size} å­—èŠ‚)")
                return True, "åŸºæœ¬éªŒè¯é€šè¿‡"
                
            except Exception as basic_error:
                return False, f"åŸºæœ¬æ–‡ä»¶éªŒè¯å¤±è´¥: {str(basic_error)}"
            
        except Exception as e:
            return False, f"éªŒè¯å¤±è´¥: {str(e)}"

    def publish_dom_geotiff(self, tif_path, store_name, file_id, force_epsg=None):
        """å‘å¸ƒDOM.tifæ–‡ä»¶åˆ°GeoServerï¼Œç‰¹åˆ«å¤„ç†åæ ‡ç³»é—®é¢˜
        
        Args:
            tif_path (str): TIFæ–‡ä»¶è·¯å¾„
            store_name (str): å­˜å‚¨åç§°
            file_id (int): æ–‡ä»¶ID
            force_epsg (str, optional): å¼ºåˆ¶ä½¿ç”¨çš„EPSGåæ ‡ç³»ï¼Œä¾‹å¦‚ "EPSG:2343"
        
        Returns:
            dict: å‘å¸ƒç»“æœä¿¡æ¯
        """
        try:
            logger.info(f"å¼€å§‹å¤„ç†DOM.tifæ–‡ä»¶: {tif_path}")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå¤„ç†æ–‡ä»¶
            temp_dir = tempfile.mkdtemp()
            processed_tif_path = os.path.join(temp_dir, f"processed_{os.path.basename(tif_path)}")
            
            try:
                # 1. ä½¿ç”¨Python GDALæ£€æŸ¥æ–‡ä»¶åæ ‡ç³»ä¿¡æ¯
                logger.info("ä½¿ç”¨Python GDALæ£€æŸ¥æ–‡ä»¶åæ ‡ç³»ä¿¡æ¯")
                
                original_srs = None
                epsg_code = None
                
                if GDAL_AVAILABLE:
                    # ä½¿ç”¨Python GDALè·å–æ–‡ä»¶ä¿¡æ¯
                    try:
                        # æ‰“å¼€æ•°æ®é›†
                        dataset = gdal.Open(tif_path)
                        if dataset is None:
                            raise Exception("æ— æ³•æ‰“å¼€TIFæ–‡ä»¶")
                        
                        # è·å–ç©ºé—´å‚è€ƒç³»ç»Ÿ
                        srs = dataset.GetSpatialRef()
                        if srs is not None:
                            original_srs = srs.ExportToWkt()
                            logger.info(f"æ£€æµ‹åˆ°åŸå§‹åæ ‡ç³»: {original_srs[:100]}...")
                            
                            # å°è¯•è·å–EPSGä»£ç 
                            auth_name = srs.GetAuthorityName(None)
                            auth_code = srs.GetAuthorityCode(None)
                            
                            if auth_name == 'EPSG' and auth_code:
                                # æ’é™¤å•ä½ä»£ç ï¼Œé€šå¸¸æ˜¯9001ç­‰
                                if auth_code not in ['9001', '9002', '9003']:
                                    epsg_code = f"EPSG:{auth_code}"
                                    logger.info(f"ä»Python GDALä¸­æå–åˆ°EPSGä»£ç : {epsg_code}")
                                else:
                                    epsg_code = None
                        
                        # å…³é—­æ•°æ®é›†
                        dataset = None
                        
                    except Exception as gdal_error:
                        logger.warning(f"ä½¿ç”¨Python GDALå¤±è´¥: {str(gdal_error)}")
                        # å¦‚æœPython GDALå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·
                        raise gdal_error
                        
                else:
                    # å›é€€åˆ°å‘½ä»¤è¡Œå·¥å…·
                    logger.info("Python GDALä¸å¯ç”¨ï¼Œä½¿ç”¨å‘½ä»¤è¡Œgdalinfo")
                    gdalinfo_cmd = ['gdalinfo', '-json', tif_path]
                    gdalinfo_result = subprocess.run(gdalinfo_cmd, capture_output=True, text=True, check=True)
                    gdalinfo_data = json.loads(gdalinfo_result.stdout)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰åæ ‡å‚è€ƒç³»ç»Ÿ
                    if 'coordinateSystem' in gdalinfo_data and 'wkt' in gdalinfo_data['coordinateSystem']:
                        original_srs = gdalinfo_data['coordinateSystem']['wkt']
                        logger.info(f"æ£€æµ‹åˆ°åŸå§‹åæ ‡ç³»: {original_srs[:100]}...")
                    
                    # æå–EPSGç ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if 'coordinateSystem' in gdalinfo_data and 'wkt' in gdalinfo_data['coordinateSystem']:
                        wkt = gdalinfo_data['coordinateSystem']['wkt']
                        # å°è¯•ä»WKTä¸­æå–EPSGä»£ç 
                        epsg_match = re.search(r'ID\[\"EPSG\",(\d+)\]', wkt)
                        if epsg_match:
                            epsg_code = f"EPSG:{epsg_match.group(1)}"
                            # æ’é™¤å•ä½ä»£ç ï¼Œé€šå¸¸æ˜¯9001ç­‰
                            if epsg_match.group(1) in ['9001', '9002', '9003']:
                                epsg_code = None
                            else:
                                logger.info(f"ä»WKTä¸­æå–åˆ°EPSGä»£ç : {epsg_code}")

                # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†åæ ‡ç³»
                needs_srs_processing = False
                target_epsg = force_epsg
                
                if not epsg_code:
                    logger.info("æœªæ£€æµ‹åˆ°æ ‡å‡†EPSGä»£ç ")
                    needs_srs_processing = True
                elif original_srs and ("unnamed" in original_srs.lower() or "unknown" in original_srs.lower()):
                    logger.info("æ£€æµ‹åˆ°æœªå‘½åæˆ–æœªçŸ¥åæ ‡ç³»")
                    needs_srs_processing = True
                
                # å¦‚æœéœ€è¦å¤„ç†åæ ‡ç³»ä¸”æ²¡æœ‰æŒ‡å®šå¼ºåˆ¶EPSGï¼Œå°è¯•ä»æ•°æ®åº“ä¸­è·å–æ–‡ä»¶åæ ‡ç³»ä¿¡æ¯
                if needs_srs_processing and not target_epsg:
                    # æŸ¥è¯¢filesè¡¨ä¸­çš„åæ ‡ç³»ä¿¡æ¯
                    try:
                        coord_sql = "SELECT coordinate_system FROM files WHERE id = %s"
                        coord_result = execute_query(coord_sql, (file_id,))
                        if coord_result and coord_result[0]['coordinate_system']:
                            db_coord = coord_result[0]['coordinate_system']
                            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„EPSGæ ¼å¼
                            if db_coord.startswith('EPSG:') or re.match(r'^\d+$', db_coord):
                                # å¦‚æœåªæ˜¯æ•°å­—ï¼ŒåŠ ä¸ŠEPSG:å‰ç¼€
                                if re.match(r'^\d+$', db_coord):
                                    target_epsg = f"EPSG:{db_coord}"
                                else:
                                    target_epsg = db_coord
                                logger.info(f"ä»æ•°æ®åº“è·å–åˆ°åæ ‡ç³»: {target_epsg}")
                    except Exception as e:
                        logger.warning(f"è·å–æ•°æ®åº“åæ ‡ç³»ä¿¡æ¯å¤±è´¥: {str(e)}")
                
                # å¦‚æœä»æœªè·å–åˆ°åæ ‡ç³»ï¼Œä½¿ç”¨é»˜è®¤å€¼
                if needs_srs_processing and not target_epsg:
                    # é»˜è®¤ä½¿ç”¨EPSG:2343 (CGCS2000)
                    target_epsg = "EPSG:2343"
                    logger.info(f"æœªæŒ‡å®šå¼ºåˆ¶åæ ‡ç³»ï¼Œé»˜è®¤ä½¿ç”¨ {target_epsg}")
                
                # 3. å¤„ç†æ–‡ä»¶ - å¦‚æœéœ€è¦å¤„ç†åæ ‡ç³»
                if needs_srs_processing and target_epsg:
                    logger.info(f"ä½¿ç”¨Python GDALå¤„ç†åæ ‡ç³»: {target_epsg}")
                    
                    if GDAL_AVAILABLE:
                        # ä½¿ç”¨Python GDALè¿›è¡Œåæ ‡ç³»å¤„ç†
                        try:
                            # è®¾ç½®GDALé€‰é¡¹
                            translate_options = gdal.TranslateOptions(
                                outputSRS=target_epsg,
                                creationOptions=['TILED=YES', 'COMPRESS=DEFLATE']
                            )
                            
                            # æ‰§è¡Œè½¬æ¢
                            result_dataset = gdal.Translate(processed_tif_path, tif_path, options=translate_options)
                            if result_dataset is None:
                                raise Exception("GDALè½¬æ¢å¤±è´¥")
                            
                            # å…³é—­æ•°æ®é›†
                            result_dataset = None
                            
                            logger.info("ä½¿ç”¨Python GDALå¤„ç†åæ ‡ç³»æˆåŠŸ")
                            # ä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶
                            final_tif_path = processed_tif_path
                            
                        except Exception as gdal_error:
                            logger.warning(f"ä½¿ç”¨Python GDALå¤„ç†å¤±è´¥: {str(gdal_error)}")
                            # å›é€€åˆ°å‘½ä»¤è¡Œå·¥å…·
                            logger.info("å›é€€åˆ°å‘½ä»¤è¡Œgdal_translate")
                            gdal_cmd = [
                                'gdal_translate', 
                                '-a_srs', target_epsg,
                                '-co', 'TILED=YES',
                                '-co', 'COMPRESS=DEFLATE',
                                tif_path, 
                                processed_tif_path
                            ]
                            subprocess.run(gdal_cmd, check=True)
                            # ä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶
                            final_tif_path = processed_tif_path
                    else:
                        # ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·
                        logger.info("Python GDALä¸å¯ç”¨ï¼Œä½¿ç”¨å‘½ä»¤è¡Œgdal_translate")
                        gdal_cmd = [
                            'gdal_translate', 
                            '-a_srs', target_epsg,
                            '-co', 'TILED=YES',
                            '-co', 'COMPRESS=DEFLATE',
                            tif_path, 
                            processed_tif_path
                        ]
                        subprocess.run(gdal_cmd, check=True)
                        # ä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶
                        final_tif_path = processed_tif_path
                else:
                    # ä¸éœ€è¦å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡ä»¶
                    logger.info("æ— éœ€å¤„ç†åæ ‡ç³»ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶")
                    final_tif_path = tif_path
                    # å¦‚æœæ²¡æœ‰ä»æ–‡ä»¶ä¸­æå–åˆ°EPSGï¼Œä½†æä¾›äº†force_epsgï¼Œä½¿ç”¨force_epsg
                    if not epsg_code and force_epsg:
                        target_epsg = force_epsg
                
                # 4. ä½¿ç”¨geotiff_publishæ¥å£å‘å¸ƒæ–‡ä»¶
                logger.info(f"ä½¿ç”¨æ ‡å‡†GeoTIFFå‘å¸ƒæ¥å£å‘å¸ƒæ–‡ä»¶")
                
                # è·å–æ–‡ä»¶åä¸ºstore_name
                if not store_name:
                    filename = os.path.splitext(os.path.basename(tif_path))[0]
                    clean_filename = re.sub(r'[^a-zA-Z0-9_\-\u4e00-\u9fff]', '_', filename)
                    store_name = f"{clean_filename}_store"
                
                # ä½¿ç”¨æ ‡å‡†geotiffå‘å¸ƒæ¥å£
                result = self.publish_geotiff(
                    tif_path=final_tif_path,
                    store_name=store_name,
                    file_id=file_id,
                    coordinate_system=target_epsg,
                    enable_transparency=True  # å¯ç”¨é€æ˜åº¦è®¾ç½®
                )
                        
                # 5. ä»…ä½¿ç”¨XMLæ–¹æ³•è®¾ç½®é€æ˜åº¦
                logger.info("ä»…ä½¿ç”¨XMLæ–¹æ³•è®¾ç½®é€æ˜åº¦")
                
                # è·å–coverageåç§°
                workspace_name = self.workspace
                coverages_url = f"{self.rest_url}/workspaces/{workspace_name}/coveragestores/{store_name}/coverages.json"
                cov_response = requests.get(coverages_url, auth=self.auth)
                
                coverage_name = None
                if cov_response.status_code == 200:
                    coverages_data = cov_response.json()
                    if 'coverages' in coverages_data and 'coverage' in coverages_data['coverages']:
                        coverages = coverages_data['coverages']['coverage']
                        if isinstance(coverages, list) and len(coverages) > 0:
                            coverage_name = coverages[0]['name']
                        elif isinstance(coverages, dict):
                            coverage_name = coverages['name']
                
                if not coverage_name:
                    coverage_name = store_name
                
                # ä½¿ç”¨XMLæ ¼å¼è®¾ç½®é€æ˜åº¦å‚æ•°
                logger.info(f"ä½¿ç”¨XMLæ–¹æ³•è®¾ç½®é€æ˜åº¦å‚æ•°: {coverage_name}")
                coverage_url = f"{self.rest_url}/workspaces/{workspace_name}/coveragestores/{store_name}/coverages/{coverage_name}.xml"
                
                xml_content = """
<coverage>
  <parameters>
    <entry>
      <string>InputTransparentColor</string>
      <string>#000000</string>
    </entry>
    <entry>
      <string>OutputTransparentColor</string>
      <string>#000000</string>
    </entry>
  </parameters>
</coverage>
"""
                
                headers = {'Content-Type': 'text/xml'}
                trans_response = requests.put(
                    coverage_url,
                    data=xml_content,
                    headers=headers,
                    auth=self.auth
                )
                
                if trans_response.status_code in [200, 201]:
                    logger.info(f"âœ… é€æ˜åº¦å‚æ•°è®¾ç½®æˆåŠŸ")
                else:
                    logger.warning(f"é€æ˜åº¦å‚æ•°è®¾ç½®å¤±è´¥: {trans_response.status_code} {trans_response.text}")
                
                # è¿”å›å‘å¸ƒç»“æœï¼ŒåŒ…å«æ ‡å‡†æœåŠ¡URL
                layer_name = coverage_name
                full_layer_name = f"{workspace_name}:{layer_name}"
                
                # å¦‚æœresultä¸­å·²æœ‰layerä¿¡æ¯ï¼Œä½¿ç”¨result
                if 'layer_name' in result:
                    return result
                else:
                        # æ„å»ºè¿”å›ç»“æœ
                    return {
                        'success': True,
                        'message': 'æˆåŠŸå‘å¸ƒDOM.tifæ–‡ä»¶',
                        'workspace': workspace_name,
                        'store': store_name,
                        'layer': layer_name,
                        'layer_name': full_layer_name,
                                    'epsg': target_epsg or epsg_code,
                                    'wms_url': f"{self.url}/wms?service=WMS&version=1.1.0&request=GetCapabilities&layers={full_layer_name}",
                                    'wfs_url': f"{self.url}/wfs?service=WFS&version=1.0.0&request=GetCapabilities&typeName={full_layer_name}",
                                    'wcs_url': f"{self.url}/wcs?service=WCS&version=1.0.0&request=GetCapabilities&coverage={full_layer_name}",
                        'preview_url': f"{self.url}/gwc/demo/{full_layer_name}?format=image/png&zoom=0"
                    }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    shutil.rmtree(temp_dir)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        except Exception as e:
            logger.error(f"å‘å¸ƒDOM.tifå¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc())
            raise Exception(f"å‘å¸ƒDOM.tifå¤±è´¥: {str(e)}")
    
    def _update_database_record(self, file_id, workspace, layer_name, epsg_code=None):
        """æ›´æ–°æ•°æ®åº“è®°å½•ï¼Œæ ‡è®°æ–‡ä»¶å·²å‘å¸ƒåˆ°GeoServer"""
        try:
            # æŸ¥æ‰¾æ–‡ä»¶è®°å½•
            check_file_sql = "SELECT id, file_name FROM files WHERE id = %s"
            file_results = execute_query(check_file_sql, (file_id,))
            
            if not file_results:
                logger.warning(f"æœªæ‰¾åˆ°æ–‡ä»¶è®°å½•: ID {file_id}")
                return
            
            # è·å–workspace_id
            workspace_id_sql = "SELECT id FROM geoserver_workspaces WHERE name = %s"
            workspace_results = execute_query(workspace_id_sql, (workspace,))
            
            if not workspace_results:
                logger.warning(f"æœªæ‰¾åˆ°å·¥ä½œç©ºé—´: {workspace}")
                return
                
            workspace_id = workspace_results[0]['id']
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å›¾å±‚è®°å½•
            check_layer_sql = "SELECT id, name FROM geoserver_layers WHERE file_id = %s"
            layer_results = execute_query(check_layer_sql, (file_id,))
            
            # é¦–å…ˆåˆ›å»ºstoreè®°å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            store_check_sql = "SELECT id FROM geoserver_stores WHERE name = %s"
            store_results = execute_query(store_check_sql, (layer_name,))
            
            store_id = None
            if not store_results:
                # åˆ›å»ºcoveragestoreè®°å½•
                create_store_sql = """
                INSERT INTO geoserver_stores (name, workspace_id, store_type, data_type, file_id, enabled, created_at, updated_at)
                VALUES (%s, %s, %s, %s, %s, TRUE, NOW(), NOW())
                RETURNING id
                """
                store_results = execute_query(create_store_sql, (layer_name, workspace_id, 'coveragestore', 'GeoTIFF', file_id))
                if store_results:
                    store_id = store_results[0]['id']
                    logger.info(f"åˆ›å»ºstoreè®°å½•: ID {store_id}")
            else:
                store_id = store_results[0]['id']
                logger.info(f"ä½¿ç”¨ç°æœ‰store: ID {store_id}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºcoverageè®°å½•
            coverage_id = None
            if store_id:
                coverage_check_sql = "SELECT id FROM geoserver_coverages WHERE name = %s AND store_id = %s"
                coverage_results = execute_query(coverage_check_sql, (layer_name, store_id))
                
                if not coverage_results:
                    # åˆ›å»ºcoverageè®°å½•
                    insert_coverage_sql = """
                    INSERT INTO geoserver_coverages (name, store_id, srs, native_name, enabled, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, TRUE, NOW(), NOW())
                    RETURNING id
                    """
                    coverage_result = execute_query(insert_coverage_sql, (layer_name, store_id, epsg_code, layer_name))
                    if coverage_result:
                        coverage_id = coverage_result[0]['id']
                        logger.info(f"åˆ›å»ºcoverageè®°å½•: ID {coverage_id}")
                else:
                    coverage_id = coverage_results[0]['id']
                    logger.info(f"ä½¿ç”¨ç°æœ‰coverage: ID {coverage_id}")
            else:
                logger.error("æ— æ³•åˆ›å»ºæˆ–è·å–store_idï¼Œæ— æ³•ç»§ç»­åˆ›å»ºcoverageè®°å½•")
            
            # å¦‚æœæ²¡æœ‰æˆåŠŸåˆ›å»ºcoverage_idï¼Œåˆ™ä¸èƒ½ç»§ç»­
            if coverage_id is None:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„coverage_idï¼Œæ— æ³•åˆ›å»ºæˆ–æ›´æ–°å›¾å±‚è®°å½•")
                return
                
            if layer_results:
                # æ›´æ–°ç°æœ‰è®°å½• - ç¡®ä¿æœåŠ¡URLä¹Ÿè¢«æ›´æ–°
                # æ„å»ºæ ‡å‡†æœåŠ¡URL
                full_layer_name = f"{workspace}:{layer_name}"
                wms_url = f"{self.url}/wms?service=WMS&version=1.1.0&request=GetCapabilities&layers={full_layer_name}"
                wfs_url = f"{self.url}/wfs?service=WFS&version=1.0.0&request=GetCapabilities&typeName={full_layer_name}"
                wcs_url = f"{self.url}/wcs?service=WCS&version=1.0.0&request=GetCapabilities&coverage={full_layer_name}"
                
                update_sql = """
                UPDATE geoserver_layers 
                SET name = %s, coverage_id = %s, featuretype_id = NULL, 
                    wms_url = %s, wfs_url = %s, wcs_url = %s, updated_at = NOW()
                WHERE file_id = %s
                """
                execute_query(update_sql, (
                    layer_name, coverage_id, 
                    wms_url, wfs_url, wcs_url,
                    file_id
                ))
                logger.info(f"æ›´æ–°å›¾å±‚è®°å½•: ID {layer_results[0]['id']}")
                logger.info(f"æ›´æ–°æœåŠ¡URL: WMS={wms_url}, WFS={wfs_url}, WCS={wcs_url}")
            else:
                # åˆ›å»ºæ–°è®°å½• - ç¡®ä¿featuretype_idä¸ºNULLä»¥ç¬¦åˆcheck_data_sourceçº¦æŸ
                # æ„å»ºæ ‡å‡†æœåŠ¡URL
                full_layer_name = f"{workspace}:{layer_name}"
                wms_url = f"{self.url}/wms?service=WMS&version=1.1.0&request=GetCapabilities&layers={full_layer_name}"
                wfs_url = f"{self.url}/wfs?service=WFS&version=1.0.0&request=GetCapabilities&typeName={full_layer_name}"
                wcs_url = f"{self.url}/wcs?service=WCS&version=1.0.0&request=GetCapabilities&coverage={full_layer_name}"
                
                insert_sql = """
                INSERT INTO geoserver_layers (
                    file_id, name, workspace_id, coverage_id, featuretype_id, 
                    enabled, queryable, opaque, wms_url, wfs_url, wcs_url,
                    created_at, updated_at
                )
                VALUES (%s, %s, %s, %s, NULL, TRUE, TRUE, FALSE, %s, %s, %s, NOW(), NOW())
                RETURNING id
                """
                result = execute_query(insert_sql, (
                    file_id, layer_name, workspace_id, coverage_id,
                    wms_url, wfs_url, wcs_url
                ))
                logger.info(f"åˆ›å»ºå›¾å±‚è®°å½•: ID {result[0]['id']}")
                logger.info(f"æœåŠ¡URL: WMS={wms_url}, WFS={wfs_url}, WCS={wcs_url}")
            
            # æ›´æ–°æ–‡ä»¶çŠ¶æ€ - æ£€æŸ¥filesè¡¨ç»“æ„å¹¶é€‚é…æ›´æ–°
            try:
                # é¦–å…ˆæ£€æŸ¥è¡¨ç»“æ„ï¼ŒæŸ¥è¯¢å­—æ®µåˆ—è¡¨
                check_columns_sql = """
                SELECT column_name FROM information_schema.columns 
                WHERE table_name = 'files' AND table_schema = 'public'
                """
                columns_result = execute_query(check_columns_sql)
                columns = [col['column_name'] for col in columns_result]
                
                if 'publish_status' in columns and 'update_time' in columns:
                    # æ–¹å¼1: ä½¿ç”¨publish_statuså’Œupdate_timeå­—æ®µ
                    update_file_sql = "UPDATE files SET publish_status = 1, update_time = NOW() WHERE id = %s"
                    execute_query(update_file_sql, (file_id,))
                    logger.info("ä½¿ç”¨publish_statuså­—æ®µæ›´æ–°æ–‡ä»¶çŠ¶æ€")
                elif 'status' in columns:
                    # æ–¹å¼2: ä½¿ç”¨statuså­—æ®µ
                    update_file_sql = "UPDATE files SET status = 'published' WHERE id = %s"
                    execute_query(update_file_sql, (file_id,))
                    logger.info("ä½¿ç”¨statuså­—æ®µæ›´æ–°æ–‡ä»¶çŠ¶æ€")
                else:
                    # å¦‚æœæ²¡æœ‰åˆé€‚çš„çŠ¶æ€å­—æ®µï¼Œåªè®°å½•æ—¥å¿—ï¼Œä¸è¿›è¡Œæ›´æ–°
                    logger.warning("filesè¡¨ä¸­æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„çŠ¶æ€å­—æ®µï¼Œè·³è¿‡çŠ¶æ€æ›´æ–°")
            except Exception as update_error:
                logger.warning(f"æ›´æ–°æ–‡ä»¶çŠ¶æ€å¤±è´¥: {str(update_error)}")
                # ä¸ä¸­æ–­ä¸»æµç¨‹
            
            logger.info(f"æ•°æ®åº“è®°å½•æ›´æ–°æˆåŠŸ: æ–‡ä»¶ID {file_id}, å›¾å±‚ {layer_name}")
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ•°æ®åº“è®°å½•å¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc())
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“ä¸»æµç¨‹

    def publish_dem_geotiff(self, tif_path, store_name, file_id, force_epsg=None):
        """å‘å¸ƒDEM.tifæ–‡ä»¶åˆ°GeoServerï¼Œç‰¹åˆ«å¤„ç†åæ ‡ç³»é—®é¢˜å¹¶è®¾ç½®é«˜ç¨‹æ˜¾ç¤ºæ ·å¼
        
        Args:
            tif_path (str): TIFæ–‡ä»¶è·¯å¾„
            store_name (str): å­˜å‚¨åç§°
            file_id (int): æ–‡ä»¶ID
            force_epsg (str, optional): å¼ºåˆ¶ä½¿ç”¨çš„EPSGåæ ‡ç³»ï¼Œä¾‹å¦‚ "EPSG:4326"
        
        Returns:
            dict: å‘å¸ƒç»“æœä¿¡æ¯
        """
        try:
            logger.info(f"å¼€å§‹å¤„ç†DEM.tifæ–‡ä»¶: {tif_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(tif_path):
                raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨: {tif_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºTIFæ ¼å¼
            file_extension = os.path.splitext(tif_path)[1].lower()
            if file_extension not in ['.tif', '.tiff']:
                raise Exception(f"æ–‡ä»¶ä¸æ˜¯TIFæ ¼å¼: {file_extension}")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå¤„ç†æ–‡ä»¶
            temp_dir = tempfile.mkdtemp()
            processed_tif_path = os.path.join(temp_dir, f"processed_{os.path.basename(tif_path)}")
            
            try:
                # 1. ä½¿ç”¨gdalinfoæ£€æŸ¥æ–‡ä»¶åæ ‡ç³»ä¿¡æ¯
                logger.info("ä½¿ç”¨gdalinfoæ£€æŸ¥æ–‡ä»¶åæ ‡ç³»ä¿¡æ¯")
                gdalinfo_cmd = ['gdalinfo', '-json', tif_path]
                gdalinfo_result = subprocess.run(gdalinfo_cmd, capture_output=True, text=True, check=True)
                gdalinfo_data = json.loads(gdalinfo_result.stdout)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åæ ‡å‚è€ƒç³»ç»Ÿ
                original_srs = None
                if 'coordinateSystem' in gdalinfo_data and 'wkt' in gdalinfo_data['coordinateSystem']:
                    original_srs = gdalinfo_data['coordinateSystem']['wkt']
                    logger.info(f"æ£€æµ‹åˆ°åŸå§‹åæ ‡ç³»: {original_srs[:100]}...")
                
                # æå–EPSGç ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                epsg_code = None
                if 'coordinateSystem' in gdalinfo_data and 'wkt' in gdalinfo_data['coordinateSystem']:
                    wkt = gdalinfo_data['coordinateSystem']['wkt']
                    # å°è¯•ä»WKTä¸­æå–EPSGä»£ç 
                    epsg_match = re.search(r'ID\[\"EPSG\",(\d+)\]', wkt)
                    if epsg_match:
                        epsg_code = f"EPSG:{epsg_match.group(1)}"
                        # æ’é™¤å•ä½ä»£ç ï¼Œé€šå¸¸æ˜¯9001ç­‰
                        if epsg_match.group(1) in ['9001', '9002', '9003']:
                            epsg_code = None
                        else:
                            logger.info(f"ä»WKTä¸­æå–åˆ°EPSGä»£ç : {epsg_code}")
                
                # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†åæ ‡ç³»
                needs_srs_processing = False
                target_epsg = force_epsg
                
                if not epsg_code:
                    logger.info("æœªæ£€æµ‹åˆ°æ ‡å‡†EPSGä»£ç ")
                    needs_srs_processing = True
                elif original_srs and ("unnamed" in original_srs.lower() or "unknown" in original_srs.lower()):
                    logger.info("æ£€æµ‹åˆ°æœªå‘½åæˆ–æœªçŸ¥åæ ‡ç³»")
                    needs_srs_processing = True
                
                # å¦‚æœéœ€è¦å¤„ç†åæ ‡ç³»ä¸”æ²¡æœ‰æŒ‡å®šå¼ºåˆ¶EPSGï¼Œå°è¯•ä»æ•°æ®åº“ä¸­è·å–æ–‡ä»¶åæ ‡ç³»ä¿¡æ¯
                if needs_srs_processing and not target_epsg:
                    # æŸ¥è¯¢filesè¡¨ä¸­çš„åæ ‡ç³»ä¿¡æ¯
                    try:
                        coord_sql = "SELECT coordinate_system FROM files WHERE id = %s"
                        coord_result = execute_query(coord_sql, (file_id,))
                        if coord_result and coord_result[0]['coordinate_system']:
                            db_coord = coord_result[0]['coordinate_system']
                            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„EPSGæ ¼å¼
                            if db_coord.startswith('EPSG:') or re.match(r'^\d+$', db_coord):
                                # å¦‚æœåªæ˜¯æ•°å­—ï¼ŒåŠ ä¸ŠEPSG:å‰ç¼€
                                if re.match(r'^\d+$', db_coord):
                                    target_epsg = f"EPSG:{db_coord}"
                                else:
                                    target_epsg = db_coord
                                logger.info(f"ä»æ•°æ®åº“è·å–åˆ°åæ ‡ç³»: {target_epsg}")
                    except Exception as e:
                        logger.warning(f"è·å–æ•°æ®åº“åæ ‡ç³»ä¿¡æ¯å¤±è´¥: {str(e)}")
                
                # å¦‚æœä»æœªè·å–åˆ°åæ ‡ç³»ï¼Œä½¿ç”¨é»˜è®¤å€¼
                if needs_srs_processing and not target_epsg:
                    # é»˜è®¤ä½¿ç”¨EPSG:4326 (WGS84)
                    target_epsg = "EPSG:4326"
                    logger.info(f"æœªæŒ‡å®šå¼ºåˆ¶åæ ‡ç³»ï¼Œé»˜è®¤ä½¿ç”¨ {target_epsg}")
                
                # 3. å¤„ç†æ–‡ä»¶ - å¦‚æœéœ€è¦å¤„ç†åæ ‡ç³»
                if needs_srs_processing and target_epsg:
                    logger.info(f"ä½¿ç”¨Python GDALå¤„ç†åæ ‡ç³»: {target_epsg}")
                    
                    if GDAL_AVAILABLE:
                        # ä½¿ç”¨Python GDALè¿›è¡Œåæ ‡ç³»å¤„ç†
                        try:
                            # è®¾ç½®GDALé€‰é¡¹
                            translate_options = gdal.TranslateOptions(
                                outputSRS=target_epsg,
                                creationOptions=['TILED=YES', 'COMPRESS=DEFLATE']
                            )
                            
                            # æ‰§è¡Œè½¬æ¢
                            result_dataset = gdal.Translate(processed_tif_path, tif_path, options=translate_options)
                            if result_dataset is None:
                                raise Exception("GDALè½¬æ¢å¤±è´¥")
                            
                            # å…³é—­æ•°æ®é›†
                            result_dataset = None
                            
                            logger.info("ä½¿ç”¨Python GDALå¤„ç†åæ ‡ç³»æˆåŠŸ")
                            # ä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶
                            final_tif_path = processed_tif_path
                            
                        except Exception as gdal_error:
                            logger.warning(f"ä½¿ç”¨Python GDALå¤„ç†å¤±è´¥: {str(gdal_error)}")
                            # å›é€€åˆ°å‘½ä»¤è¡Œå·¥å…·
                            logger.info("å›é€€åˆ°å‘½ä»¤è¡Œgdal_translate")
                            gdal_cmd = [
                                'gdal_translate', 
                                '-a_srs', target_epsg,
                                '-co', 'TILED=YES',
                                '-co', 'COMPRESS=DEFLATE',
                                tif_path, 
                                processed_tif_path
                            ]
                            subprocess.run(gdal_cmd, check=True)
                            # ä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶
                            final_tif_path = processed_tif_path
                    else:
                        # ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·
                        logger.info("Python GDALä¸å¯ç”¨ï¼Œä½¿ç”¨å‘½ä»¤è¡Œgdal_translate")
                        gdal_cmd = [
                            'gdal_translate', 
                            '-a_srs', target_epsg,
                            '-co', 'TILED=YES',
                            '-co', 'COMPRESS=DEFLATE',
                            tif_path, 
                            processed_tif_path
                        ]
                        subprocess.run(gdal_cmd, check=True)
                        # ä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶
                        final_tif_path = processed_tif_path
                else:
                    # ä¸éœ€è¦å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡ä»¶
                    logger.info("æ— éœ€å¤„ç†åæ ‡ç³»ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶")
                    final_tif_path = tif_path
                    # å¦‚æœæ²¡æœ‰ä»æ–‡ä»¶ä¸­æå–åˆ°EPSGï¼Œä½†æä¾›äº†force_epsgï¼Œä½¿ç”¨force_epsg
                    if not epsg_code and force_epsg:
                        target_epsg = force_epsg
                
                # 4. ä½¿ç”¨geotiff_publishæ¥å£å‘å¸ƒæ–‡ä»¶
                logger.info(f"ä½¿ç”¨æ ‡å‡†GeoTIFFå‘å¸ƒæ¥å£å‘å¸ƒæ–‡ä»¶")
                
                # è·å–æ–‡ä»¶åä¸ºstore_name
                if not store_name:
                    filename = os.path.splitext(os.path.basename(tif_path))[0]
                    clean_filename = re.sub(r'[^a-zA-Z0-9_\-\u4e00-\u9fff]', '_', filename)
                    store_name = f"{clean_filename}_store"
                
                # ä½¿ç”¨æ ‡å‡†geotiffå‘å¸ƒæ¥å£ï¼Œä½†ä¸å¯ç”¨é€æ˜åº¦
                result = self.publish_geotiff(
                    tif_path=final_tif_path,
                    store_name=store_name,
                    file_id=file_id,
                    coordinate_system=target_epsg,
                    enable_transparency=False  # DEMä¸éœ€è¦é€æ˜åº¦
                )
                
                # 5. ä¸ºDEMåˆ›å»ºå¹¶åº”ç”¨é«˜ç¨‹æ ·å¼
                logger.info("ä¸ºDEMåˆ›å»ºé«˜ç¨‹æ˜¾ç¤ºæ ·å¼")
                
                # è·å–å›¾å±‚åç§°
                workspace_name = self.workspace
                layer_name = None
                
                if 'layer_name' in result:
                    full_layer_name = result['layer_name']
                    if ':' in full_layer_name:
                        layer_name = full_layer_name.split(':')[1]
                
                if not layer_name:
                    layer_name = store_name
                
                # åˆ›å»ºDEMçƒ­åŠ›å›¾æ ·å¼
                style_name = f"dem_heatmap_{layer_name}"
                style_created = self._create_dem_style(style_name)
                
                if style_created:
                    # åº”ç”¨æ ·å¼åˆ°å›¾å±‚
                    style_applied = self._apply_style_to_layer(layer_name, style_name)
                    if style_applied:
                        logger.info(f"âœ… é«˜ç¨‹æ˜¾ç¤ºæ ·å¼å·²åº”ç”¨åˆ°å›¾å±‚: {layer_name}")
                        # åœ¨ç»“æœä¸­æ·»åŠ æ ·å¼ä¿¡æ¯
                        result['style_name'] = style_name
                        result['style_applied'] = True
                    else:
                        logger.warning(f"âš ï¸ æ— æ³•åº”ç”¨é«˜ç¨‹æ ·å¼åˆ°å›¾å±‚: {layer_name}")
                        result['style_applied'] = False
                else:
                    logger.warning("âš ï¸ åˆ›å»ºDEMæ ·å¼å¤±è´¥")
                    result['style_applied'] = False
                
                # è¿”å›å‘å¸ƒç»“æœ
                return result
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    shutil.rmtree(temp_dir)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        except Exception as e:
            logger.error(f"å‘å¸ƒDEM.tifå¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc())
            raise Exception(f"å‘å¸ƒDEM.tifå¤±è´¥: {str(e)}")
    
    def _create_dem_style(self, style_name):
        """åˆ›å»ºDEMé«˜ç¨‹æ˜¾ç¤ºæ ·å¼
        
        Args:
            style_name: æ ·å¼åç§°
            
        Returns:
            bool: æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        try:
            print(f"åˆ›å»ºDEMé«˜ç¨‹æ ·å¼: {style_name}")
            
            # DEMçƒ­åŠ›å›¾æ ·å¼å®šä¹‰
            style_xml = f"""<?xml version="1.0" encoding="UTF-8"?>
<StyledLayerDescriptor xmlns="http://www.opengis.net/sld" xmlns:ogc="http://www.opengis.net/ogc" 
                       xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
                       xsi:schemaLocation="http://www.opengis.net/sld http://schemas.opengis.net/sld/1.0.0/StyledLayerDescriptor.xsd" 
                       version="1.0.0">
  <NamedLayer>
    <Name>DEM-HeatMap</Name>
    <UserStyle>
      <Name>{style_name}</Name>
      <Title>DEM Elevation Style</Title>
      <Abstract>Heat map style for Digital Elevation Model</Abstract>
        <FeatureTypeStyle>
         <Rule>
           <RasterSymbolizer>
              <ColorMap type="ramp">
                <ColorMapEntry color="#2851CC" quantity="0" opacity="0.7" label="0"/>
                <ColorMapEntry color="#211F1F" quantity="50" opacity="0.8" label="50"/>
                <ColorMapEntry color="#EE0F0F" quantity="100" opacity="0.8" label="100"/>
                <ColorMapEntry color="#AAAAAA" quantity="200" opacity="0.8" label="200"/>
                <ColorMapEntry color="#6FEE4F" quantity="300" opacity="0.8" label="300"/>
                <ColorMapEntry color="#3ECC1B" quantity="450" opacity="0.8" label="450"/>
                <ColorMapEntry color="#886363" quantity="700" opacity="0.8" label="700"/>
                <ColorMapEntry color="#5194CC" quantity="1000" opacity="0.8" label="1000"/>
                <ColorMapEntry color="#2C58DD" quantity="1500" opacity="0.8" label="1500"/>
                <ColorMapEntry color="#DDB02C" quantity="2000" opacity="0.8" label="2000"/>
              </ColorMap>
           </RasterSymbolizer>
         </Rule>
       </FeatureTypeStyle>
    </UserStyle>
  </NamedLayer>
</StyledLayerDescriptor>
"""
            
            # æ£€æŸ¥æ ·å¼æ˜¯å¦å­˜åœ¨
            style_check_url = f"{self.rest_url}/styles/{style_name}.xml"
            style_check_response = requests.get(style_check_url, auth=self.auth)
            
            if style_check_response.status_code == 200:
                print(f"æ ·å¼ {style_name} å·²å­˜åœ¨ï¼Œå°†æ›´æ–°")
                # æ›´æ–°æ ·å¼
                style_url = f"{self.rest_url}/styles/{style_name}"
                headers = {'Content-Type': 'application/vnd.ogc.sld+xml'}
                style_response = requests.put(
                    style_url, 
                    data=style_xml, 
                    headers=headers, 
                    auth=self.auth
                )
            else:
                print(f"åˆ›å»ºæ–°æ ·å¼: {style_name}")
                # åˆ›å»ºæ ·å¼
                # 1. å…ˆåˆ›å»ºæ ·å¼å®šä¹‰
                create_style_url = f"{self.rest_url}/styles"
                create_style_data = {
                    "style": {
                        "name": style_name,
                        "filename": f"{style_name}.sld"
                    }
                }
                
                headers_json = {'Content-Type': 'application/json'}
                create_response = requests.post(
                    create_style_url, 
                    json=create_style_data, 
                    headers=headers_json, 
                    auth=self.auth
                )
                
                if create_response.status_code not in [201, 200]:
                    print(f"åˆ›å»ºæ ·å¼å®šä¹‰å¤±è´¥: {create_response.status_code} - {create_response.text}")
                    return False
                
                # 2. ä¸Šä¼ æ ·å¼å†…å®¹
                headers_xml = {'Content-Type': 'application/vnd.ogc.sld+xml'}
                style_content_url = f"{self.rest_url}/styles/{style_name}"
                
                style_response = requests.put(
                    style_content_url, 
                    data=style_xml, 
                    headers=headers_xml, 
                    auth=self.auth
                )
            
            if style_response.status_code not in [200, 201]:
                print(f"ä¸Šä¼ æ ·å¼å†…å®¹å¤±è´¥: {style_response.status_code} - {style_response.text}")
                return False
            
            print(f"âœ… DEMæ ·å¼åˆ›å»º/æ›´æ–°æˆåŠŸ: {style_name}")
            return True
            
        except Exception as e:
            print(f"åˆ›å»ºDEMæ ·å¼å¤±è´¥: {str(e)}")
            return False
    
    def _apply_style_to_layer(self, layer_name, style_name):
        """å°†æ ·å¼åº”ç”¨åˆ°å›¾å±‚
        
        Args:
            layer_name: å›¾å±‚åç§°
            style_name: æ ·å¼åç§°
            
        Returns:
            bool: æ˜¯å¦åº”ç”¨æˆåŠŸ
        """
        try:
            print(f"å°†æ ·å¼ {style_name} åº”ç”¨åˆ°å›¾å±‚ {layer_name}")
            
            # è·å–å®Œæ•´çš„å›¾å±‚åç§°ï¼ˆåŒ…å«å·¥ä½œç©ºé—´å‰ç¼€ï¼‰
            full_layer_name = f"{self.workspace}:{layer_name}" if ':' not in layer_name else layer_name
            
            # å›¾å±‚ä¿¡æ¯æ›´æ–°URL
            layer_url = f"{self.rest_url}/layers/{full_layer_name}"
            
            # æ„å»ºæ›´æ–°è¯·æ±‚æ•°æ®
            update_data = {
                "layer": {
                    "defaultStyle": {
                        "name": style_name
                    }
                }
            }
            
            headers = {'Content-Type': 'application/json'}
            
            # å‘é€æ›´æ–°è¯·æ±‚
            response = requests.put(
                layer_url,
                json=update_data,
                headers=headers,
                auth=self.auth
            )
            
            if response.status_code not in [200, 201]:
                print(f"åº”ç”¨æ ·å¼å¤±è´¥: {response.status_code} - {response.text}")
                return False
            
            print(f"âœ… æ ·å¼åº”ç”¨æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"åº”ç”¨æ ·å¼å¤±è´¥: {str(e)}")
            return False
