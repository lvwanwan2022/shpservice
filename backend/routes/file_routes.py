#!/usr/bin/env python
# -*- coding: utf-8 -*-

from flask import Blueprint, request, jsonify, current_app
from services.file_service import FileService
from models.db import execute_query
from werkzeug.utils import secure_filename
from config import FILE_STORAGE
# ç™»å½•è®¤è¯æ¨¡å— - ä¸€è¡Œä»£ç å®ç°æ–‡ä»¶ä¸Šä¼ æƒé™éªŒè¯
from auth.auth_service import require_auth, get_current_user
import os
import json
import time

file_bp = Blueprint('file', __name__)
file_service = FileService()

@file_bp.route('/upload', methods=['POST'])
@require_auth  # ä¸€è¡Œä»£ç å®ç°ç™»å½•éªŒè¯
def upload_file():
    """ä¸Šä¼ æ–‡ä»¶æ¥å£"""
    print("=== æ–‡ä»¶ä¸Šä¼ è¯·æ±‚å¼€å§‹ ===")
    print("è¯·æ±‚æ–‡ä»¶:", request.files.keys())
    print("è¯·æ±‚è¡¨å•:", dict(request.form))
    
    if 'file' not in request.files:
        print("é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶")
        return jsonify({'error': 'æœªæ‰¾åˆ°æ–‡ä»¶'}), 400
    
    file = request.files['file']
    print(f"æ–‡ä»¶å: {file.filename}")
    
    if file.filename == '':
        print("é”™è¯¯: æœªé€‰æ‹©æ–‡ä»¶")
        return jsonify({'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
    
    try:
        # è·å–å½“å‰ç™»å½•ç”¨æˆ·ä¿¡æ¯
        current_user = get_current_user()
        #current_app.logger.info(f"å½“å‰ç™»å½•ç”¨æˆ·ä¿¡æ¯: {current_user}")
        user_name = current_user.get('username', 'unknown')  
        #ä»æ•°æ®åº“ä¸­è·å–ç”¨æˆ·ID
        user_id = execute_query("SELECT id FROM users WHERE username = %s", (user_name,))
        if user_id:
            user_id = user_id[0]['id']
        else:
            user_id = 'unknown'
        
        # ä»è¡¨å•è·å–å…ƒæ•°æ®
        metadata = {
            'file_name': request.form.get('file_name') or secure_filename(file.filename),
            'original_name': file.filename,  # æ–°å¢åŸå§‹æ–‡ä»¶å
            'discipline': request.form.get('discipline'),
            'dimension': request.form.get('dimension'),
            'is_public': request.form.get('is_public', 'true').lower() == 'true',
            'file_type': request.form.get('file_type'),
            'coordinate_system': request.form.get('coordinate_system'),
            'tags': request.form.get('tags', ''),
            'description': request.form.get('description', ''),
            'user_id': user_id,  # ä½¿ç”¨å½“å‰ç™»å½•ç”¨æˆ·ID
            'status': 'uploaded',  # æ–°å¢çŠ¶æ€å­—æ®µ
            'geometry_type': request.form.get('geometry_type'),  # æ–°å¢å‡ ä½•ç±»å‹
            'feature_count': request.form.get('feature_count'),  # æ–°å¢è¦ç´ æ•°é‡
            'bbox': request.form.get('bbox'),  # æ–°å¢è¾¹ç•Œæ¡†
            'metadata': request.form.get('metadata')  # æ–°å¢å…ƒæ•°æ®JSON
        }
        
        print("å…ƒæ•°æ®:", metadata)
        
        # éªŒè¯å¿…å¡«å­—æ®µ
        required_fields = ['file_name', 'original_name', 'discipline', 'dimension', 'file_type']
        for field in required_fields:
            if not metadata.get(field):
                print(f"é”™è¯¯: ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}")
                return jsonify({'error': f'ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}'}), 400
        
        # éªŒè¯DWG/DXFç±»å‹å¿…é¡»æœ‰åæ ‡ç³»
        if metadata['file_type'].lower() in ['dwg', 'dxf'] and not metadata.get('coordinate_system'):
            print("é”™è¯¯: DWG/DXFæ–‡ä»¶å¿…é¡»æŒ‡å®šåæ ‡ç³»")
            return jsonify({'error': 'DWG/DXFæ–‡ä»¶å¿…é¡»æŒ‡å®šåæ ‡ç³»'}), 400
        
        # ä¿å­˜æ–‡ä»¶å¹¶è®°å½•å…ƒæ•°æ®
        file_id, file_data = file_service.save_file(file, metadata)
        
        print(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ŒID: {file_id}")
        return jsonify({
            'id': str(file_id),  # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            'message': 'æ•°æ®ä¸Šä¼ æˆåŠŸï¼Œå¦‚éœ€å‘å¸ƒæœåŠ¡è¯·æ‰‹åŠ¨ç‚¹å‡»å‘å¸ƒæŒ‰é’®',
            'file': {
                'id': str(file_id),  # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                'file_name': file_data['file_name'],
                'original_name': file_data.get('original_name', ''),
                'file_size': file_data['file_size'],
                'file_type': file_data['file_type'],
                'discipline': file_data.get('discipline', ''),
                'dimension': file_data.get('dimension', ''),
                'coordinate_system': file_data.get('coordinate_system', ''),
                'status': file_data.get('status', 'uploaded'),
                'geometry_type': file_data.get('geometry_type', ''),
                'feature_count': file_data.get('feature_count', 0),
                'bbox': file_data.get('bbox'),
                'upload_date': file_data.get('upload_date', '')
            }
        }), 200
    
    except ValueError as e:
        print(f"å€¼é”™è¯¯: {str(e)}")
        return jsonify({'error': str(e)}), 400
    
    except Exception as e:
        print(f"æœåŠ¡å™¨é”™è¯¯: {str(e)}")
        current_app.logger.error(f"æ–‡ä»¶ä¸Šä¼ é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

# ========== åˆ†ç‰‡ä¸Šä¼ ç›¸å…³è·¯ç”± ==========

# å­˜å‚¨åˆ†ç‰‡ä¸Šä¼ çš„ä¸´æ—¶ä¿¡æ¯
chunked_uploads = {}

@file_bp.route('/upload/chunked/init', methods=['POST'])
@require_auth  # ä¸€è¡Œä»£ç å®ç°ç™»å½•éªŒè¯
def init_chunked_upload():
    """åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ """
    print("=== åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼  ===")
    
    data = request.get_json()
    upload_id = data.get('upload_id')
    file_name = data.get('file_name')
    total_chunks = data.get('total_chunks')
    metadata = data.get('metadata', {})
    
    print(f"ä¸Šä¼ ID: {upload_id}")
    print(f"æ–‡ä»¶å: {file_name}")
    print(f"æ€»åˆ†ç‰‡æ•°: {total_chunks}")
    print(f"å…ƒæ•°æ®: {metadata}")
    
    if not all([upload_id, file_name, total_chunks]):
        return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_base = FILE_STORAGE.get('temp_folder', 'temp')
    temp_dir = os.path.join(temp_base, 'chunks', upload_id)
    os.makedirs(temp_dir, exist_ok=True)
    
    # å­˜å‚¨ä¸Šä¼ ä¿¡æ¯
    chunked_uploads[upload_id] = {
        'file_name': file_name,
        'total_chunks': total_chunks,
        'received_chunks': set(),
        'temp_dir': temp_dir,
        'metadata': metadata,
        'created_at': time.time()
    }
    
    print(f"åˆ†ç‰‡ä¸Šä¼ åˆå§‹åŒ–æˆåŠŸï¼Œä¸´æ—¶ç›®å½•: {temp_dir}")
    return jsonify({'message': 'åˆ†ç‰‡ä¸Šä¼ åˆå§‹åŒ–æˆåŠŸ', 'upload_id': upload_id})

@file_bp.route('/upload/chunked/chunk', methods=['POST'])
@require_auth  # ä¸€è¡Œä»£ç å®ç°ç™»å½•éªŒè¯
def upload_chunk():
    """ä¸Šä¼ å•ä¸ªåˆ†ç‰‡"""
    upload_id = request.form.get('upload_id')
    chunk_index = int(request.form.get('chunk_index'))
    
    if 'chunk' not in request.files:
        return jsonify({'error': 'æœªæ‰¾åˆ°åˆ†ç‰‡æ–‡ä»¶'}), 400
    
    chunk_file = request.files['chunk']
    
    print(f"æ¥æ”¶åˆ†ç‰‡: upload_id={upload_id}, chunk_index={chunk_index}, size={len(chunk_file.read())}B")
    chunk_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
    
    if upload_id not in chunked_uploads:
        return jsonify({'error': 'æ— æ•ˆçš„ä¸Šä¼ ID'}), 400
    
    upload_info = chunked_uploads[upload_id]
    
    # ä¿å­˜åˆ†ç‰‡æ–‡ä»¶
    chunk_path = os.path.join(upload_info['temp_dir'], f'chunk_{chunk_index}')
    chunk_file.save(chunk_path)
    
    # è®°å½•å·²æ¥æ”¶çš„åˆ†ç‰‡
    upload_info['received_chunks'].add(chunk_index)
    
    print(f"åˆ†ç‰‡ {chunk_index} ä¿å­˜æˆåŠŸï¼Œå·²æ¥æ”¶: {len(upload_info['received_chunks'])}/{upload_info['total_chunks']}")
    
    return jsonify({
        'message': 'åˆ†ç‰‡ä¸Šä¼ æˆåŠŸ',
        'chunk_index': chunk_index,
        'received_chunks': len(upload_info['received_chunks']),
        'total_chunks': upload_info['total_chunks']
    })

@file_bp.route('/upload/chunked/complete', methods=['POST'])
@require_auth  # ä¸€è¡Œä»£ç å®ç°ç™»å½•éªŒè¯
def complete_chunked_upload():
    """å®Œæˆåˆ†ç‰‡ä¸Šä¼ ï¼Œåˆå¹¶æ–‡ä»¶"""
    print("=== å®Œæˆåˆ†ç‰‡ä¸Šä¼  ===")
    
    data = request.get_json()
    upload_id = data.get('upload_id')
    
    if upload_id not in chunked_uploads:
        return jsonify({'error': 'æ— æ•ˆçš„ä¸Šä¼ ID'}), 400
    
    upload_info = chunked_uploads[upload_id]
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ†ç‰‡éƒ½å·²æ¥æ”¶
    expected_chunks = set(range(upload_info['total_chunks']))
    if upload_info['received_chunks'] != expected_chunks:
        missing_chunks = expected_chunks - upload_info['received_chunks']
        return jsonify({'error': f'ç¼ºå°‘åˆ†ç‰‡: {list(missing_chunks)}'}), 400
    
    try:
        # åˆå¹¶æ–‡ä»¶
        print("å¼€å§‹åˆå¹¶æ–‡ä»¶...")
        final_file_path = os.path.join(upload_info['temp_dir'], upload_info['file_name'])
        
        with open(final_file_path, 'wb') as final_file:
            for chunk_index in range(upload_info['total_chunks']):
                chunk_path = os.path.join(upload_info['temp_dir'], f'chunk_{chunk_index}')
                with open(chunk_path, 'rb') as chunk_file:
                    final_file.write(chunk_file.read())
                # åˆ é™¤åˆ†ç‰‡æ–‡ä»¶
                os.remove(chunk_path)
        
        print(f"æ–‡ä»¶åˆå¹¶å®Œæˆ: {final_file_path}")
        
        # åˆ›å»ºæ–‡ä»¶å¯¹è±¡ç”¨äºä¿å­˜
        class FileObject:
            def __init__(self, file_path, filename):
                self.file_path = file_path
                self.filename = filename
                with open(file_path, 'rb') as f:
                    f.seek(0, os.SEEK_END)
                    self.size = f.tell()
            
            def save(self, destination):
                import shutil
                shutil.move(self.file_path, destination)
                return destination
            
            def read(self):
                with open(self.file_path, 'rb') as f:
                    return f.read()
        
        file_obj = FileObject(final_file_path, upload_info['file_name'])
        
        # è·å–å½“å‰ç™»å½•ç”¨æˆ·ä¿¡æ¯
        current_user = get_current_user()
        user_id = current_user.get('id', current_user.get('username', 'unknown'))  # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“IDï¼Œå›é€€åˆ°ç”¨æˆ·å
        
        # ä½¿ç”¨ç°æœ‰çš„æ–‡ä»¶ä¿å­˜é€»è¾‘
        metadata = upload_info['metadata']
        metadata['file_name'] = metadata.get('file_name') or secure_filename(upload_info['file_name'])
        metadata['original_name'] = upload_info['file_name']
        metadata['user_id'] = user_id  # ä½¿ç”¨å½“å‰ç™»å½•ç”¨æˆ·ID
        
        # éªŒè¯å¿…å¡«å­—æ®µ
        required_fields = ['file_name', 'original_name', 'discipline', 'dimension', 'file_type']
        for field in required_fields:
            if not metadata.get(field):
                return jsonify({'error': f'ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}'}), 400
        
        # ä¿å­˜æ–‡ä»¶å¹¶è®°å½•å…ƒæ•°æ®
        file_id, file_data = file_service.save_file(file_obj, metadata)
        
        # æ¸…ç†ä¸´æ—¶æ•°æ®
        import shutil
        shutil.rmtree(upload_info['temp_dir'], ignore_errors=True)
        del chunked_uploads[upload_id]
        
        print(f"åˆ†ç‰‡ä¸Šä¼ å®Œæˆï¼Œæ–‡ä»¶ID: {file_id}")
        
        return jsonify({
            'id': file_id,
            'message': 'åˆ†ç‰‡ä¸Šä¼ æˆåŠŸï¼Œå¦‚éœ€å‘å¸ƒæœåŠ¡è¯·æ‰‹åŠ¨ç‚¹å‡»å‘å¸ƒæŒ‰é’®',
            'file': {
                'id': file_id,
                'file_name': file_data['file_name'],
                'original_name': file_data.get('original_name', ''),
                'file_size': file_data['file_size'],
                'file_type': file_data['file_type'],
                'discipline': file_data.get('discipline', ''),
                'dimension': file_data.get('dimension', ''),
                'coordinate_system': file_data.get('coordinate_system', ''),
                'status': file_data.get('status', 'uploaded'),
                'geometry_type': file_data.get('geometry_type', ''),
                'feature_count': file_data.get('feature_count', 0),
                'bbox': file_data.get('bbox'),
                'upload_date': file_data.get('upload_date', '')
            }
        }), 200
    
    except Exception as e:
        print(f"åˆå¹¶æ–‡ä»¶å¤±è´¥: {str(e)}")
        current_app.logger.error(f"åˆ†ç‰‡ä¸Šä¼ åˆå¹¶å¤±è´¥: {str(e)}")
        return jsonify({'error': 'æ–‡ä»¶åˆå¹¶å¤±è´¥'}), 500

@file_bp.route('/upload/chunked/abort', methods=['POST'])
def abort_chunked_upload():
    """å–æ¶ˆåˆ†ç‰‡ä¸Šä¼ """
    print("=== å–æ¶ˆåˆ†ç‰‡ä¸Šä¼  ===")
    
    data = request.get_json()
    upload_id = data.get('upload_id')
    
    if upload_id not in chunked_uploads:
        return jsonify({'error': 'æ— æ•ˆçš„ä¸Šä¼ ID'}), 400
    
    upload_info = chunked_uploads[upload_id]
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    import shutil
    shutil.rmtree(upload_info['temp_dir'], ignore_errors=True)
    del chunked_uploads[upload_id]
    
    print(f"åˆ†ç‰‡ä¸Šä¼ å·²å–æ¶ˆ: {upload_id}")
    return jsonify({'message': 'åˆ†ç‰‡ä¸Šä¼ å·²å–æ¶ˆ'})

@file_bp.route('/files/list', methods=['GET'])
@require_auth  # æ·»åŠ ç”¨æˆ·è®¤è¯è£…é¥°å™¨
def get_files_list():
    """è·å–æ–‡ä»¶åˆ—è¡¨ - /files/list ç«¯ç‚¹
    """
    return get_file_list()

@file_bp.route('/list', methods=['GET'])
@require_auth  # æ·»åŠ ç”¨æˆ·è®¤è¯è£…é¥°å™¨
def get_file_list():
    """è·å–æ–‡ä»¶åˆ—è¡¨
    ---
    tags:
      - æ–‡ä»¶ç®¡ç†
    parameters:
      - name: page
        in: query
        type: integer
        required: false
        default: 1
        description: é¡µç 
      - name: page_size
        in: query
        type: integer
        required: false
        default: 20
        description: æ¯é¡µæ•°é‡
      - name: user_id
        in: query
        type: integer
        required: false
        description: ç”¨æˆ·IDè¿‡æ»¤
      - name: discipline
        in: query
        type: string
        required: false
        description: ä¸“ä¸šè¿‡æ»¤
      - name: file_type
        in: query
        type: string
        required: false
        description: æ–‡ä»¶ç±»å‹è¿‡æ»¤
      - name: dimension
        in: query
        type: string
        required: false
        description: ç»´åº¦è¿‡æ»¤
      - name: status
        in: query
        type: string
        required: false
        description: çŠ¶æ€è¿‡æ»¤
      - name: geometry_type
        in: query
        type: string
        required: false
        description: å‡ ä½•ç±»å‹è¿‡æ»¤
      - name: search
        in: query
        type: string
        required: false
        description: æœç´¢å…³é”®è¯
      - name: sort_by
        in: query
        type: string
        required: false
        default: upload_date
        description: æ’åºå­—æ®µ
      - name: sort_order
        in: query
        type: string
        required: false
        default: desc
        description: æ’åºæ–¹å‘
    responses:
      200:
        description: æ–‡ä»¶åˆ—è¡¨
    """
    try:
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
        current_user = get_current_user()
        if not current_user:
            return jsonify({'error': 'ç”¨æˆ·æœªè®¤è¯'}), 401
        
        current_user_id = current_user.get('id')
        #current_app.logger.info(f"å½“å‰ç”¨æˆ·ID: {current_user_id}")
        # è·å–æŸ¥è¯¢å‚æ•°
        page = int(request.args.get('page', 1))
        page_size = int(request.args.get('page_size', 20))
        user_id = request.args.get('user_id')
        discipline = request.args.get('discipline')
        file_type = request.args.get('file_type')
        dimension = request.args.get('dimension')
        status = request.args.get('status')
        geometry_type = request.args.get('geometry_type')
        search = request.args.get('search')
        sort_by = request.args.get('sort_by', 'upload_date')
        sort_order = request.args.get('sort_order', 'desc')
        
        # æ„å»ºåŸºç¡€æŸ¥è¯¢ - ä½¿ç”¨ç»Ÿä¸€çš„vector_martin_servicesè¡¨
        base_query = """
        SELECT f.*, u.username as uploader,
               gl.id as geoserver_layer_id, 
               CONCAT(gw.name, ':', gl.name) as geoserver_layer_name, 
               gl.wms_url as geoserver_wms_url, 
               gl.wfs_url as geoserver_wfs_url,
               vms.id as martin_service_id,
               vms.file_id as martin_file_id,
               vms.vector_type as martin_vector_type,
               vms.table_name as martin_table_name,
               vms.mvt_url as martin_mvt_url,
               vms.tilejson_url as martin_tilejson_url,
               vms.style as martin_style,
               vms.status as martin_status
        FROM files f
        LEFT JOIN users u ON f.user_id = u.id
        LEFT JOIN geoserver_layers gl ON f.id = gl.file_id
        LEFT JOIN geoserver_workspaces gw ON gl.workspace_id = gw.id
        LEFT JOIN vector_martin_services vms ON f.file_name = vms.original_filename AND vms.status = 'active'
        """
        
        # æ„å»ºWHEREæ¡ä»¶
        where_conditions = []
        params = []
        
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæ·»åŠ æƒé™è¿‡æ»¤æ¡ä»¶ - åªæ˜¾ç¤ºå½“å‰ç”¨æˆ·çš„æ–‡ä»¶æˆ–å…¬å¼€çš„æ–‡ä»¶
        where_conditions.append("(f.user_id = %s OR f.is_public = true)")
        params.append(current_user_id)
        
        if user_id:
            where_conditions.append("f.user_id = %s")
            params.append(user_id)
        
        if discipline:
            where_conditions.append("f.discipline = %s")
            params.append(discipline)
        
        if file_type:
            where_conditions.append("f.file_type = %s")
            params.append(file_type)
        
        if dimension:
            where_conditions.append("f.dimension = %s")
            params.append(dimension)
        
        if status:
            where_conditions.append("f.status = %s")
            params.append(status)
        
        if geometry_type:
            where_conditions.append("f.geometry_type = %s")
            params.append(geometry_type)
        
        if search:
            where_conditions.append("(f.file_name ILIKE %s OR f.description ILIKE %s OR f.tags ILIKE %s)")
            search_param = f"%{search}%"
            params.extend([search_param, search_param, search_param])
        
        # æ·»åŠ WHEREå­å¥
        if where_conditions:
            base_query += " WHERE " + " AND ".join(where_conditions)
        
        # æ·»åŠ æ’åº
        allowed_sort_fields = ['upload_date', 'file_name', 'file_size', 'file_type', 'discipline']
        if sort_by not in allowed_sort_fields:
            sort_by = 'upload_date'
        
        if sort_order.lower() not in ['asc', 'desc']:
            sort_order = 'desc'
        
        base_query += f" ORDER BY f.{sort_by} {sort_order.upper()}"
        
        # æ·»åŠ åˆ†é¡µ
        offset = (page - 1) * page_size
        query = base_query + f" LIMIT {page_size} OFFSET {offset}"
        
        # æ‰§è¡ŒæŸ¥è¯¢
        files = execute_query(query, params)
        #current_app.logger.info(f"æŸ¥è¯¢ç»“æœ: {files}")
        # è·å–æ€»æ•°
        count_query = """
        SELECT COUNT(DISTINCT f.id)
        FROM files f
        LEFT JOIN users u ON f.user_id = u.id
        LEFT JOIN geoserver_layers gl ON f.id = gl.file_id
        LEFT JOIN geoserver_workspaces gw ON gl.workspace_id = gw.id
        LEFT JOIN vector_martin_services vms ON f.file_name = vms.original_filename AND vms.status = 'active'
        """
        
        if where_conditions:
            count_query += " WHERE " + " AND ".join(where_conditions)
        
        total_result = execute_query(count_query, params)
        total = total_result[0]['count'] if total_result else 0
        
        # å¤„ç†ç»“æœ
        for file in files:
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå°†æ‰€æœ‰IDå­—æ®µè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…JavaScriptå¤§æ•´æ•°ç²¾åº¦ä¸¢å¤±
            if file.get('id'):
                file['id'] = str(file['id'])
            if file.get('user_id'):
                file['user_id'] = str(file['user_id'])
            if file.get('martin_service_id'):
                file['martin_service_id'] = str(file['martin_service_id'])
            if file.get('martin_file_id'):
                file['martin_file_id'] = str(file['martin_file_id'])
            if file.get('geoserver_layer_id'):
                file['geoserver_layer_id'] = str(file['geoserver_layer_id'])
            
            # å¤„ç†JSONå­—æ®µ
            if file.get('bbox'):
                try:
                    file['bbox'] = json.loads(file['bbox']) if isinstance(file['bbox'], str) else file['bbox']
                except:
                    file['bbox'] = None
            
            if file.get('metadata'):
                try:
                    file['metadata'] = json.loads(file['metadata']) if isinstance(file['metadata'], str) else file['metadata']
                except:
                    file['metadata'] = {}
            
            # è·å–æœåŠ¡ç±»å‹å’ŒMartinæœåŠ¡ä¿¡æ¯
            martin_service_id = file.get('martin_service_id')
            martin_file_id = file.get('martin_file_id')
            martin_table_name = file.get('martin_table_name')
            martin_status = file.get('martin_status')
            geoserver_layer_id = file.get('geoserver_layer_id')
            
            # æ·»åŠ MartinæœåŠ¡çŠ¶æ€ä¿¡æ¯
            martin_service_info = {
                'is_published': martin_service_id is not None and martin_status == 'active',
                'service_id': martin_service_id,
                'file_id': martin_file_id,
                'table_name': martin_table_name,
                'mvt_url': file.get('martin_mvt_url'),
                'tilejson_url': file.get('martin_tilejson_url'),
                'style': file.get('martin_style'),
                'status': martin_status
            }
            
            # æ·»åŠ GeoServeræœåŠ¡çŠ¶æ€ä¿¡æ¯
            geoserver_service_info = {
                'is_published': geoserver_layer_id is not None,
                'layer_id': geoserver_layer_id,
                'layer_name': file.get('geoserver_layer_name'),
                'wms_url': file.get('geoserver_wms_url'),
                'wfs_url': file.get('geoserver_wfs_url')
            }
            
            # ä¿æŒå‘åå…¼å®¹çš„published_infoå­—æ®µï¼ˆä¼˜å…ˆæ˜¾ç¤ºMartinæœåŠ¡ï¼‰
            if martin_service_info['is_published']:
                published_info = {
                    'is_published': True,
                    'service_type': 'martin',
                    **martin_service_info
                }
            elif geoserver_service_info['is_published']:
                published_info = {
                    'is_published': True,
                    'service_type': 'geoserver',
                    **geoserver_service_info
                }
            else:
                published_info = {
                    'is_published': False,
                    'service_type': None
                }
            
            file['martin_service'] = martin_service_info
            file['geoserver_service'] = geoserver_service_info
            file['published_info'] = published_info
            
            # æ¸…ç†ä¸´æ—¶å­—æ®µ
            for key in ['geoserver_layer_id', 'geoserver_layer_name', 'geoserver_wms_url', 'geoserver_wfs_url', 
                       'martin_service_id', 'martin_file_id', 'martin_table_name', 'martin_mvt_url', 'martin_tilejson_url',
                       'martin_style', 'martin_status', 'is_published', 'service_type']:
                file.pop(key, None)
        #current_app.logger.info(f"æŸ¥è¯¢ç»“æœ: {files}")
        return jsonify({
            'files': files,
            'total': total,
            'page': page,
            'page_size': page_size,
            'total_pages': (total + page_size - 1) // page_size
        }), 200
    
    except Exception as e:
        current_app.logger.error(f"è·å–æ–‡ä»¶åˆ—è¡¨é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/files/<string:file_id>', methods=['GET'])
def get_files_file(file_id):
    """è·å–æ–‡ä»¶è¯¦æƒ… - /files/<file_id> ç«¯ç‚¹"""
    return get_file(file_id)

@file_bp.route('/<string:file_id>', methods=['GET'])
def get_file(file_id):
    """è·å–æ–‡ä»¶è¯¦æƒ…"""
    try:
        # å°†å­—ç¬¦ä¸²file_idè½¬æ¢ä¸ºæ•´æ•°
        try:
            file_id_int = int(file_id)
        except ValueError:
            return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶IDæ ¼å¼'}), 400
            
        file_info = file_service.get_file_by_id(file_id_int)
        if not file_info:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå°†IDå­—æ®µè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…JavaScriptå¤§æ•´æ•°ç²¾åº¦ä¸¢å¤±
        if file_info.get('id'):
            file_info['id'] = str(file_info['id'])
        if file_info.get('user_id'):
            file_info['user_id'] = str(file_info['user_id'])
        
        return jsonify(file_info), 200
    
    except Exception as e:
        current_app.logger.error(f"è·å–æ–‡ä»¶è¯¦æƒ…é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/<string:file_id>', methods=['PUT'])
def update_file(file_id):
    """æ›´æ–°æ–‡ä»¶ä¿¡æ¯"""
    try:
        # å°†å­—ç¬¦ä¸²file_idè½¬æ¢ä¸ºæ•´æ•°
        try:
            file_id_int = int(file_id)
        except ValueError:
            return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶IDæ ¼å¼'}), 400
            
        data = request.json
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_info = file_service.get_file_by_id(file_id_int)
        if not file_info:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # å‡†å¤‡æ›´æ–°æ•°æ®
        update_data = {}
        allowed_fields = [
            'file_name', 'discipline', 'dimension', 'file_type', 
            'coordinate_system', 'tags', 'description', 'is_public',
            'status', 'geometry_type', 'feature_count', 'bbox', 'metadata'
        ]
        
        for field in allowed_fields:
            if field in data:
                update_data[field] = data[field]
        
        # æ›´æ–°æ–‡ä»¶ä¿¡æ¯
        file_service.update_file(file_id_int, update_data)
        
        return jsonify({'message': 'æ–‡ä»¶ä¿¡æ¯æ›´æ–°æˆåŠŸ'}), 200
    
    except Exception as e:
        current_app.logger.error(f"æ›´æ–°æ–‡ä»¶ä¿¡æ¯é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/<string:file_id>', methods=['DELETE'])
def delete_file(file_id):
    """åˆ é™¤æ–‡ä»¶"""
    try:
        # å°†å­—ç¬¦ä¸²file_idè½¬æ¢ä¸ºæ•´æ•°
        try:
            file_id_int = int(file_id)
        except ValueError:
            return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶IDæ ¼å¼'}), 400
            
        file_service.delete_file(file_id_int)
        return jsonify({'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'}), 200
    
    except ValueError as e:
        return jsonify({'error': str(e)}), 404
    
    except Exception as e:
        current_app.logger.error(f"åˆ é™¤æ–‡ä»¶é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/files/users', methods=['GET'])
def get_files_users():
    """è·å–ç”¨æˆ·åˆ—è¡¨ - /files/users ç«¯ç‚¹"""
    return get_users()

@file_bp.route('/users', methods=['GET'])
def get_users():
    """è·å–ç”¨æˆ·åˆ—è¡¨"""
    try:
        sql = "SELECT id, username FROM users ORDER BY username"
        users = execute_query(sql)
        
        return jsonify({
            'users': users
        }), 200
    
    except Exception as e:
        current_app.logger.error(f"è·å–ç”¨æˆ·åˆ—è¡¨é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/statistics', methods=['GET'])
def get_file_statistics():
    """è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = file_service.get_file_statistics()
        return jsonify(stats), 200
    
    except Exception as e:
        current_app.logger.error(f"è·å–æ–‡ä»¶ç»Ÿè®¡é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/disciplines', methods=['GET'])
@require_auth  # æ·»åŠ ç”¨æˆ·è®¤è¯è£…é¥°å™¨
def get_disciplines():
    """è·å–å­¦ç§‘åˆ—è¡¨"""
    try:
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
        current_user = get_current_user()
        if not current_user:
            return jsonify({'error': 'ç”¨æˆ·æœªè®¤è¯'}), 401
        
        current_user_id = current_user.get('id')
        
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šåªè¿”å›å½“å‰ç”¨æˆ·çš„æ–‡ä»¶æˆ–å…¬å¼€æ–‡ä»¶çš„å­¦ç§‘
        sql = """
        SELECT DISTINCT discipline 
        FROM files 
        WHERE discipline IS NOT NULL 
        AND (user_id = %s OR is_public = true)
        ORDER BY discipline
        """
        result = execute_query(sql, (current_user_id,))
        disciplines = [row['discipline'] for row in result]
        
        return jsonify({
            'disciplines': disciplines
        }), 200
    
    except Exception as e:
        current_app.logger.error(f"è·å–å­¦ç§‘åˆ—è¡¨é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/file-types', methods=['GET'])
@require_auth  # æ·»åŠ ç”¨æˆ·è®¤è¯è£…é¥°å™¨
def get_file_types():
    """è·å–æ–‡ä»¶ç±»å‹åˆ—è¡¨"""
    try:
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
        current_user = get_current_user()
        if not current_user:
            return jsonify({'error': 'ç”¨æˆ·æœªè®¤è¯'}), 401
        
        current_user_id = current_user.get('id')
        
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šåªè¿”å›å½“å‰ç”¨æˆ·çš„æ–‡ä»¶æˆ–å…¬å¼€æ–‡ä»¶çš„æ–‡ä»¶ç±»å‹
        sql = """
        SELECT DISTINCT file_type 
        FROM files 
        WHERE file_type IS NOT NULL 
        AND (user_id = %s OR is_public = true)
        ORDER BY file_type
        """
        result = execute_query(sql, (current_user_id,))
        file_types = [row['file_type'] for row in result]
        
        return jsonify({
            'file_types': file_types
        }), 200
    
    except Exception as e:
        current_app.logger.error(f"è·å–æ–‡ä»¶ç±»å‹åˆ—è¡¨é”™è¯¯: {str(e)}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@file_bp.route('/<string:file_id>/publish/martin', methods=['POST'])
def publish_martin_service(file_id):
    """å‘å¸ƒæ–‡ä»¶åˆ°MartinæœåŠ¡"""
    try:
        # å°†å­—ç¬¦ä¸²file_idè½¬æ¢ä¸ºæ•´æ•°
        try:
            file_id_int = int(file_id)
        except ValueError:
            return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶IDæ ¼å¼'}), 400
            
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_info = file_service.get_file_by_id(file_id_int)
        if not file_info:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦æ”¯æŒMartinæœåŠ¡
        file_type = file_info.get('file_type', '').lower()
        if file_type not in ['geojson', 'shp', 'dxf']:
            return jsonify({'error': 'MartinæœåŠ¡ä»…æ”¯æŒGeoJSONã€SHPå’ŒDXFæ–‡ä»¶'}), 400
        
        # æ£€æŸ¥æ˜¯å¦å·²å‘å¸ƒåˆ°Martinï¼ˆç»Ÿä¸€è¡¨æŸ¥è¯¢ï¼‰
        check_sql = """
        SELECT id, file_id, vector_type FROM vector_martin_services 
        WHERE original_filename = %s AND status = 'active'
        """
        existing = execute_query(check_sql, (file_info['file_name'],))
        if existing:
            return jsonify({
                'error': 'æ–‡ä»¶å·²å‘å¸ƒåˆ°MartinæœåŠ¡',
                'martin_file_id': existing[0]['file_id'],
                'vector_type': existing[0]['vector_type']
            }), 400
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å‘å¸ƒæœåŠ¡
        if file_type in ['geojson', 'shp']:
            # ä½¿ç”¨ç»Ÿä¸€çš„Vector MartinæœåŠ¡
            from services.vector_martin_service import VectorMartinService
            martin_service = VectorMartinService()
            
            if file_type == 'geojson':
                result = martin_service.publish_geojson_martin(
                    file_id=str(file_id),
                    file_path=file_info['file_path'],
                    original_filename=file_info['file_name'],
                    user_id=file_info.get('user_id')
                )
            elif file_type == 'shp':
                result = martin_service.publish_shp_martin(
                    file_id=str(file_id),
                    zip_file_path=file_info['file_path'],
                    original_filename=file_info['file_name'],
                    user_id=file_info.get('user_id')
                )
        
        elif file_type == 'dxf':
            # ä½¿ç”¨DXFæœåŠ¡å‘å¸ƒ
            from services.dxf_service import DXFService
            dxf_service = DXFService()
            
            # ä»è¯·æ±‚ä¸­è·å–åæ ‡ç³»å‚æ•°
            coordinate_system = request.json.get('coordinate_system', 'EPSG:4326') if request.is_json else 'EPSG:4326'
            
            result = dxf_service.publish_dxf_martin_service(
                file_id=str(file_id),
                file_path=file_info['file_path'],
                original_filename=file_info['file_name'],
                coordinate_system=coordinate_system,
                user_id=file_info.get('user_id')
            )
        
        if result['success']:
            return jsonify({
                'success': True,
                'message': 'MartinæœåŠ¡å‘å¸ƒæˆåŠŸ',
                'martin_info': result
            }), 200
        else:
            return jsonify({
                'error': f'MartinæœåŠ¡å‘å¸ƒå¤±è´¥: {result.get("error", "æœªçŸ¥é”™è¯¯")}'
            }), 500
    
    except Exception as e:
        current_app.logger.error(f"å‘å¸ƒMartinæœåŠ¡é”™è¯¯: {str(e)}")
        return jsonify({'error': f'å‘å¸ƒMartinæœåŠ¡å¤±è´¥: {str(e)}'}), 500

@file_bp.route('/<string:file_id>/publish/martin-mbtiles', methods=['POST'])
def publish_martin_mbtiles_service(file_id):
    """å‘å¸ƒMBTilesæ–‡ä»¶åˆ°MartinæœåŠ¡"""
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_info = file_service.get_file_by_id(file_id)
        if not file_info:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦æ”¯æŒMartinæœåŠ¡
        file_type = file_info.get('file_type', '').lower()
        if file_type not in ['geojson', 'shp', 'dxf', 'mbtiles', 'vector.mbtiles', 'raster.mbtiles']:
            return jsonify({'error': 'MartinæœåŠ¡ä»…æ”¯æŒGeoJSONã€SHPã€DXFå’ŒMBTilesæ–‡ä»¶'}), 400
        
        # æ£€æŸ¥æ˜¯å¦å·²å‘å¸ƒåˆ°Martinï¼ˆç»Ÿä¸€è¡¨æŸ¥è¯¢ï¼‰
        check_sql = """
        SELECT id, file_id, vector_type FROM vector_martin_services 
        WHERE original_filename = %s AND status = 'active'
        """
        existing = execute_query(check_sql, (file_info['file_name'],))
        if existing:
            return jsonify({
                'error': 'æ–‡ä»¶å·²å‘å¸ƒåˆ°MartinæœåŠ¡',
                'martin_file_id': existing[0]['file_id'],
                'vector_type': existing[0]['vector_type']
            }), 400
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å‘å¸ƒæœåŠ¡
        if file_type in ['geojson', 'shp']:
            # ä½¿ç”¨ç»Ÿä¸€çš„Vector MartinæœåŠ¡
            from services.vector_martin_service import VectorMartinService
            martin_service = VectorMartinService()
            
            if file_type == 'geojson':
                result = martin_service.publish_geojson_martin(
                    file_id=str(file_id),
                    file_path=file_info['file_path'],
                    original_filename=file_info['file_name'],
                    user_id=file_info.get('user_id')
                )
            elif file_type == 'shp':
                result = martin_service.publish_shp_martin(
                    file_id=str(file_id),
                    zip_file_path=file_info['file_path'],
                    original_filename=file_info['file_name'],
                    user_id=file_info.get('user_id')
                )
        
        elif file_type == 'dxf':
            # ä½¿ç”¨DXFæœåŠ¡å‘å¸ƒ
            from services.dxf_service import DXFService
            dxf_service = DXFService()
            
            # ä»è¯·æ±‚ä¸­è·å–åæ ‡ç³»å‚æ•°
            coordinate_system = request.json.get('coordinate_system', 'EPSG:4326') if request.is_json else 'EPSG:4326'
            
            result = dxf_service.publish_dxf_martin_service(
                file_id=str(file_id),
                file_path=file_info['file_path'],
                original_filename=file_info['file_name'],
                coordinate_system=coordinate_system,
                user_id=file_info.get('user_id')
            )
        
        elif file_type in ['mbtiles', 'vector.mbtiles', 'raster.mbtiles']:
            # ä½¿ç”¨æ …æ ¼MartinæœåŠ¡å‘å¸ƒMBTilesæ–‡ä»¶
            from services.raster_martin_service import RasterMartinService
            raster_martin_service = RasterMartinService()
            
            # ç¡®å®šMBTilesç±»å‹
            mbtiles_type = 'vector' if file_type == 'vector.mbtiles' else 'raster.mbtiles'
            
            result = raster_martin_service.publish_mbtiles_martin(
                file_id=str(file_id),
                file_path=file_info['file_path'],
                original_filename=file_info['file_name'],
                user_id=file_info.get('user_id'),
                mbtiles_type=mbtiles_type
            )
        
        if result['success']:
            return jsonify({
                'success': True,
                'message': 'MartinæœåŠ¡å‘å¸ƒæˆåŠŸ',
                'martin_info': result
            }), 200
        else:
            return jsonify({
                'error': f'MartinæœåŠ¡å‘å¸ƒå¤±è´¥: {result.get("error", "æœªçŸ¥é”™è¯¯")}'
            }), 500
    
    except Exception as e:
        current_app.logger.error(f"å‘å¸ƒMartinæœåŠ¡é”™è¯¯: {str(e)}")
        return jsonify({'error': f'å‘å¸ƒMartinæœåŠ¡å¤±è´¥: {str(e)}'}), 500

@file_bp.route('/<string:file_id>/publish/geoserver', methods=['POST'])
def publish_geoserver_service(file_id):
    """å‘å¸ƒæ–‡ä»¶åˆ°GeoServeræœåŠ¡ - ç»Ÿä¸€å¤„ç†çŸ¢é‡å’Œæ …æ ¼æ•°æ®"""
    try:
        # 1. è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = file_service.get_file_by_id(file_id)
        if not file_info:
            return jsonify({'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        file_type = file_info.get('file_type', '').lower()
        file_path = file_info['file_path']
        
        print(f"=== å¼€å§‹å‘å¸ƒGeoServeræœåŠ¡ ===")
        print(f"æ–‡ä»¶ID: {file_id}, æ–‡ä»¶ç±»å‹: {file_type}")
        print(f"æ–‡ä»¶è·¯å¾„: {file_path}")
        
        # 2. æ£€æŸ¥æ˜¯å¦å·²ç»å‘å¸ƒ
        existing_layer_sql = """
        SELECT gl.id, gl.name, gw.name as workspace_name,
               gl.featuretype_id, gl.coverage_id,
               gs.name as store_name, gs.store_type
        FROM geoserver_layers gl
        LEFT JOIN geoserver_workspaces gw ON gl.workspace_id = gw.id
        LEFT JOIN geoserver_featuretypes gft ON gl.featuretype_id = gft.id
        LEFT JOIN geoserver_coverages gcov ON gl.coverage_id = gcov.id
        LEFT JOIN geoserver_stores gs ON (gft.store_id = gs.id OR gcov.store_id = gs.id)
        WHERE gl.file_id = %s
        """
        existing_layers = execute_query(existing_layer_sql, (file_id,))
        
        if existing_layers:
            layer_info = existing_layers[0]
            return jsonify({
                'success': False, 
                'error': f'æ–‡ä»¶å·²å‘å¸ƒä¸ºå›¾å±‚: {layer_info["workspace_name"]}:{layer_info["name"]}',
                'existing_layer': {
                    'id': layer_info['id'],
                    'name': f"{layer_info['workspace_name']}:{layer_info['name']}",
                    'store_name': layer_info['store_name'],
                    'store_type': layer_info['store_type']
                }
            }), 400
        
        # 3. è·å–åæ ‡ç³»ä¿¡æ¯
        coordinate_system = file_info.get('coordinate_system')
        if not coordinate_system and request.is_json:
            data = request.get_json()
            coordinate_system = data.get('coordinate_system')
        elif not coordinate_system and request.form:
            coordinate_system = request.form.get('coordinate_system')
        
        if coordinate_system:
            print(f"ä½¿ç”¨åæ ‡ç³»: {coordinate_system}")
        
        # 4. æ£€æŸ¥æ–‡ä»¶ç±»å‹æ”¯æŒ
        vector_types = ['shp', 'geojson']
        raster_types = ['tif', 'tiff', 'dem', 'dom', 'dem.tif', 'dom.tif']
        
        if file_type not in vector_types + raster_types:
            return jsonify({
                'success': False, 
                'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}ã€‚æ”¯æŒçš„ç±»å‹: {", ".join(vector_types + raster_types)}'
            }), 400
        
        # 5. ç”Ÿæˆå­˜å‚¨åç§°
        store_name = f"file_{file_id}"
        
        # 6. æ ¹æ®æ–‡ä»¶ç±»å‹æ‰§è¡Œå‘å¸ƒ
        from services.geoserver_service import GeoServerService
        geoserver_service = GeoServerService()
        
        print(f"å¼€å§‹å‘å¸ƒåˆ°GeoServerï¼Œå­˜å‚¨åç§°: {store_name}")
        
        if file_type in vector_types:
            print(f"å‘å¸ƒçŸ¢é‡æ•°æ®: {file_type}")
            # çŸ¢é‡æ•°æ®å‘å¸ƒ
            if file_type == 'shp':
                result = geoserver_service.publish_shapefile(file_path, store_name, file_id, coordinate_system)
            elif file_type == 'geojson':
                result = geoserver_service.publish_geojson(file_path, store_name, file_id)
        else:
            print(f"å‘å¸ƒæ …æ ¼æ•°æ®: {file_type}")
            # æ …æ ¼æ•°æ®å‘å¸ƒ
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨é€æ˜åº¦ï¼ˆä»è¯·æ±‚å‚æ•°è·å–ï¼Œé»˜è®¤ä¸å¯ç”¨ï¼‰
            enable_transparency = False
            if file_type== 'dom.tif':                
                enable_transparency = True            
            
            print(f"é€æ˜åº¦è®¾ç½®: {enable_transparency}")
            
            # å¦‚æœæ˜¯DOMæ–‡ä»¶ï¼Œä½¿ç”¨å¢å¼ºç‰ˆçš„å¤„ç†é€»è¾‘
            is_dom_file = file_type.lower() in ['dom', 'dom.tif'] or 'dom' in file_info.get('file_name', '').lower()
            
            if is_dom_file or file_type.lower() in ['tif', 'tiff']:
                print(f"æ£€æµ‹åˆ°DOM/TIFæ–‡ä»¶ï¼Œä½¿ç”¨å¢å¼ºç‰ˆå‘å¸ƒæµç¨‹")
                
                # è·å–å¼ºåˆ¶è®¾ç½®çš„åæ ‡ç³»
                force_epsg = None
                if coordinate_system:
                    force_epsg = coordinate_system
                elif request.is_json:
                    data = request.get_json()
                    force_epsg = data.get('force_epsg')
                elif request.form:
                    force_epsg = request.form.get('force_epsg')
                
                # éªŒè¯åæ ‡ç³»æ ¼å¼
                if force_epsg and not force_epsg.upper().startswith('EPSG:'):
                    return jsonify({
                        'success': False, 
                        'error': f'åæ ‡ç³»æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºEPSG:xxxxæ ¼å¼ï¼Œå½“å‰ä¸º: {force_epsg}'
                    }), 400
                
                if force_epsg:
                    print(f"ä½¿ç”¨å¼ºåˆ¶åæ ‡ç³»: {force_epsg}")
                
                # ä½¿ç”¨å¢å¼ºç‰ˆDOM.tifå‘å¸ƒæ–¹æ³•
                result = geoserver_service.publish_dom_geotiff(
                    tif_path=file_path,
                    store_name=store_name,
                    file_id=file_id,
                    force_epsg=force_epsg
                )
            else:
                # å…¶ä»–æ …æ ¼æ•°æ®ä½¿ç”¨åŸæœ‰æ–¹æ³•
                if coordinate_system:
                    # éªŒè¯åæ ‡ç³»æ ¼å¼
                    if not coordinate_system.upper().startswith('EPSG:'):
                        return jsonify({
                            'success': False, 
                            'error': f'åæ ‡ç³»æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºEPSG:xxxxæ ¼å¼ï¼Œå½“å‰ä¸º: {coordinate_system}'
                        }), 400
                    
                    result = geoserver_service.publish_geotiff(file_path, store_name, file_id, coordinate_system, enable_transparency)
                else:
                    result = geoserver_service.publish_geotiff(file_path, store_name, file_id, None, enable_transparency)
        
        print(f"GeoServerå‘å¸ƒç»“æœ: {result}")
        return jsonify(result)
            
    except Exception as e:
        print(f"å‘å¸ƒGeoServeræœåŠ¡å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'å‘å¸ƒå¤±è´¥: {str(e)}'}), 500

@file_bp.route('/<string:file_id>/unpublish/martin', methods=['DELETE'])
def unpublish_martin_service(file_id):
    """å–æ¶ˆå‘å¸ƒMartinæœåŠ¡"""
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_info = file_service.get_file_by_id(file_id)
        if not file_info:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # æŸ¥æ‰¾MartinæœåŠ¡è®°å½•ï¼ˆç»Ÿä¸€è¡¨æŸ¥è¯¢ï¼‰
        check_sql = """
        SELECT id, file_id, vector_type FROM vector_martin_services 
        WHERE original_filename = %s AND status = 'active'
        """
        existing = execute_query(check_sql, (file_info['file_name'],))
        
        if not existing:
            return jsonify({'error': 'æ–‡ä»¶æœªå‘å¸ƒåˆ°MartinæœåŠ¡'}), 404
        
        service_id = existing[0]['id']
        martin_file_id = existing[0]['file_id']
        vector_type = existing[0]['vector_type']
        
        # æ ¹æ®vector_typeé€‰æ‹©åˆ é™¤æ–¹å¼
        if vector_type == 'dxf':
            from services.dxf_service import DXFService
            dxf_service = DXFService()
            result = dxf_service.delete_dxf_martin_service(service_id)
            success = result.get('success', False)
        elif vector_type == 'mbtiles':
            # ä½¿ç”¨æ …æ ¼MartinæœåŠ¡åˆ é™¤MBTilesæœåŠ¡
            from services.raster_martin_service import RasterMartinService
            raster_martin_service = RasterMartinService()
            success = raster_martin_service.delete_martin_service(service_id)
        else:
            # ä½¿ç”¨ç»Ÿä¸€çš„Vector MartinæœåŠ¡åˆ é™¤
            from services.vector_martin_service import VectorMartinService
            martin_service = VectorMartinService()
            success = martin_service.delete_martin_service(service_id)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'MartinæœåŠ¡å–æ¶ˆå‘å¸ƒæˆåŠŸ',
                'vector_type': vector_type
            }), 200
        else:
            return jsonify({'error': 'MartinæœåŠ¡åˆ é™¤å¤±è´¥'}), 500
    
    except Exception as e:
        current_app.logger.error(f"å–æ¶ˆå‘å¸ƒMartinæœåŠ¡é”™è¯¯: {str(e)}")
        return jsonify({'error': f'å–æ¶ˆå‘å¸ƒMartinæœåŠ¡å¤±è´¥: {str(e)}'}), 500

@file_bp.route('/<string:file_id>/publish/dom', methods=['POST'])
def publish_dom_geoserver_service(file_id):
    """å‘å¸ƒDOM.tifæ–‡ä»¶åˆ°GeoServeræœåŠ¡ - ä¸“é—¨å¤„ç†DOM.tifæ–‡ä»¶
    
    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨gdalinfoæ£€æŸ¥æ–‡ä»¶åæ ‡ç³»ä¿¡æ¯
    2. å¦‚æœåæ ‡ç³»ä¸æ˜¯æ ‡å‡†EPSGï¼Œä½¿ç”¨gdal_translateè®¾ç½®åæ ‡ç³»
    3. ä½¿ç”¨æ ‡å‡†GeoTIFFæ–¹å¼å‘å¸ƒï¼ˆä¸ä½¿ç”¨ImageMosaicï¼‰
    4. è‡ªåŠ¨è®¾ç½®é»‘è‰²èƒŒæ™¯ä¸ºé€æ˜ï¼ˆInput Transparent Color: 000000ï¼‰
    
    å‚æ•°:
    - force_epsg: å¼ºåˆ¶è®¾ç½®çš„EPSGåæ ‡ç³»ï¼Œå¦‚'EPSG:2343'ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›:
    - æˆåŠŸ: {'success': True, 'layer_name': 'å›¾å±‚åç§°', 'wms_url': 'WMSæœåŠ¡åœ°å€', ...}
    - å¤±è´¥: {'success': False, 'error': 'é”™è¯¯ä¿¡æ¯'}
    """
    try:
        # 1. è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = file_service.get_file_by_id(file_id)
        if not file_info:
            return jsonify({'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        file_type = file_info.get('file_type', '').lower()
        file_path = file_info['file_path']
        file_name = file_info['file_name']
        
        print(f"=== å¼€å§‹å‘å¸ƒDOM.tifæ–‡ä»¶åˆ°GeoServer ===")
        print(f"æ–‡ä»¶ID: {file_id}, æ–‡ä»¶ç±»å‹: {file_type}")
        print(f"æ–‡ä»¶è·¯å¾„: {file_path}")
        print(f"æ–‡ä»¶åç§°: {file_name}")
        
        # 2. æ£€æŸ¥æ–‡ä»¶ç±»å‹
        dom_types = ['tif', 'tiff', 'dom', 'dem', 'dom.tif', 'dem.tif']
        if file_type not in dom_types:
            return jsonify({
                'success': False, 
                'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}ã€‚è¯¥æ¥å£ä»…æ”¯æŒDOM/TIFç±»å‹: {", ".join(dom_types)}'
            }), 400
        
        # 3. æ£€æŸ¥æ˜¯å¦å·²ç»å‘å¸ƒ
        existing_layer_sql = """
        SELECT gl.id, gl.name, gw.name as workspace_name,
               gl.featuretype_id, gl.coverage_id,
               gs.name as store_name, gs.store_type
        FROM geoserver_layers gl
        LEFT JOIN geoserver_workspaces gw ON gl.workspace_id = gw.id
        LEFT JOIN geoserver_featuretypes gft ON gl.featuretype_id = gft.id
        LEFT JOIN geoserver_coverages gcov ON gl.coverage_id = gcov.id
        LEFT JOIN geoserver_stores gs ON (gft.store_id = gs.id OR gcov.store_id = gs.id)
        WHERE gl.file_id = %s
        """
        existing_layers = execute_query(existing_layer_sql, (file_id,))
        
        if existing_layers:
            layer_info = existing_layers[0]
            # å¦‚æœè¯·æ±‚å‚æ•°åŒ…å«force=trueï¼Œåˆ™åˆ é™¤ç°æœ‰å‘å¸ƒåé‡æ–°å‘å¸ƒ
            force_republish = False
            if request.is_json:
                data = request.get_json()
                force_republish = data.get('force', False)
            elif request.form:
                force_republish = request.form.get('force', 'false').lower() in ['true', '1', 'yes']
            
            if not force_republish:
                return jsonify({
                    'success': False, 
                    'error': f'æ–‡ä»¶å·²å‘å¸ƒä¸ºå›¾å±‚: {layer_info["workspace_name"]}:{layer_info["name"]}',
                    'existing_layer': {
                        'id': layer_info['id'],
                        'name': f"{layer_info['workspace_name']}:{layer_info['name']}",
                        'store_name': layer_info['store_name'],
                        'store_type': layer_info['store_type']
                    }
                }), 400
            else:
                print(f"å¼ºåˆ¶é‡æ–°å‘å¸ƒï¼šåˆ é™¤ç°æœ‰å›¾å±‚ {layer_info['id']}")
                from services.geoserver_service import GeoServerService
                geoserver_service = GeoServerService()
                # åˆ é™¤ç°æœ‰å›¾å±‚
                geoserver_service.unpublish_layer(layer_info['id'])
                print(f"âœ… ç°æœ‰å›¾å±‚åˆ é™¤æˆåŠŸ")
        
        # 4. è·å–å¼ºåˆ¶è®¾ç½®çš„åæ ‡ç³»ä¿¡æ¯
        force_epsg = None
        if request.is_json:
            data = request.get_json()
            force_epsg = data.get('force_epsg')
        elif request.form:
            force_epsg = request.form.get('force_epsg')
        
        if force_epsg:
            # éªŒè¯åæ ‡ç³»æ ¼å¼
            if not force_epsg.upper().startswith('EPSG:'):
                return jsonify({
                    'success': False, 
                    'error': f'åæ ‡ç³»æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºEPSG:xxxxæ ¼å¼ï¼Œå½“å‰ä¸º: {force_epsg}'
                }), 400
            print(f"å¼ºåˆ¶è®¾ç½®åæ ‡ç³»: {force_epsg}")
        
        # 5. ç”Ÿæˆå­˜å‚¨åç§°
        store_name = f"dom_{file_id}"
        
        # 6. ä½¿ç”¨ä¸“é—¨çš„DOM.tifå‘å¸ƒæ–¹æ³•
        from services.geoserver_service import GeoServerService
        geoserver_service = GeoServerService()
        
        print(f"å¼€å§‹ä½¿ç”¨DOM.tifä¸“ç”¨æ–¹æ³•å‘å¸ƒåˆ°GeoServerï¼Œå­˜å‚¨åç§°: {store_name}")
        result = geoserver_service.publish_dom_geotiff(
            tif_path=file_path,
            store_name=store_name,
            file_id=file_id,
            force_epsg=force_epsg
        )
        
        print(f"DOM.tifå‘å¸ƒç»“æœ: {result}")
        return jsonify(result)
            
    except Exception as e:
        print(f"å‘å¸ƒDOM.tifåˆ°GeoServerå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'å‘å¸ƒå¤±è´¥: {str(e)}'}), 500

@file_bp.route('/<string:file_id>/unpublish/geoserver', methods=['DELETE'])
def unpublish_geoserver_service(file_id):
    """å–æ¶ˆå‘å¸ƒGeoServeræœåŠ¡ - ç»Ÿä¸€å¤„ç†çŸ¢é‡å’Œæ …æ ¼æ•°æ®"""
    try:
        print(f"=== å¼€å§‹å–æ¶ˆå‘å¸ƒGeoServeræœåŠ¡ ===")
        print(f"æ–‡ä»¶ID: {file_id}")
        
        # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_info = file_service.get_file_by_id(file_id)
        if not file_info:
            return jsonify({'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        file_type = file_info.get('file_type', '').lower()
        print(f"æ–‡ä»¶ç±»å‹: {file_type}")
        
        # 2. æŸ¥æ‰¾å‘å¸ƒçš„å›¾å±‚ä¿¡æ¯
        layer_query_sql = """
        SELECT gl.id as layer_id, gl.name as layer_name, 
               gw.name as workspace_name,
               gl.featuretype_id, gl.coverage_id,
               gs.id as store_id, gs.name as store_name, gs.store_type,
               gft.id as featuretype_id_detail,
               gcov.id as coverage_id_detail
        FROM geoserver_layers gl
        LEFT JOIN geoserver_workspaces gw ON gl.workspace_id = gw.id
        LEFT JOIN geoserver_featuretypes gft ON gl.featuretype_id = gft.id
        LEFT JOIN geoserver_coverages gcov ON gl.coverage_id = gcov.id
        LEFT JOIN geoserver_stores gs ON (gft.store_id = gs.id OR gcov.store_id = gs.id)
        WHERE gl.file_id = %s
        """
        
        layer_results = execute_query(layer_query_sql, (file_id,))
        if not layer_results:
            return jsonify({'success': False, 'error': 'æ–‡ä»¶æœªå‘å¸ƒåˆ°GeoServeræœåŠ¡'}), 404
        
        layer_info = layer_results[0]
        layer_id = layer_info['layer_id']
        layer_name = layer_info['layer_name']
        workspace_name = layer_info['workspace_name']
        store_name = layer_info['store_name']
        store_type = layer_info['store_type']
        
        print(f"æ‰¾åˆ°å·²å‘å¸ƒå›¾å±‚: {workspace_name}:{layer_name}")
        print(f"å­˜å‚¨ä¿¡æ¯: {store_name} (ç±»å‹: {store_type})")
        
        # 3. åˆ¤æ–­æ˜¯çŸ¢é‡è¿˜æ˜¯æ …æ ¼æ•°æ®
        is_raster = layer_info['coverage_id'] is not None
        is_vector = layer_info['featuretype_id'] is not None
        
        print(f"æ•°æ®ç±»å‹: {'æ …æ ¼' if is_raster else 'çŸ¢é‡' if is_vector else 'æœªçŸ¥'}")
        
        # 4. ä»GeoServeråˆ é™¤æœåŠ¡
        from services.geoserver_service import GeoServerService
        geoserver_service = GeoServerService()
        
        print(f"--- å¼€å§‹ä»GeoServeråˆ é™¤æœåŠ¡ ---")
        
        try:
            if is_raster:
                print(f"åˆ é™¤æ …æ ¼æ•°æ®å­˜å‚¨: {store_name}")
                # ä½¿ç”¨å¢å¼ºçš„coveragestoreæ¸…ç†æ–¹æ³•
                geoserver_service._cleanup_existing_coveragestore(store_name)
            else:
                print(f"åˆ é™¤çŸ¢é‡æ•°æ®å­˜å‚¨: {store_name}")
                # åˆ é™¤datastore
                geoserver_service._cleanup_existing_datastore(store_name)
                
            print(f"âœ… GeoServeræœåŠ¡åˆ é™¤å®Œæˆ")
        except Exception as geoserver_error:
            print(f"âš ï¸ GeoServeråˆ é™¤å¤±è´¥: {str(geoserver_error)}")
            # ç»§ç»­æ‰§è¡Œæ•°æ®åº“æ¸…ç†ï¼Œä¸é˜»æ–­æµç¨‹
        
        # 5. æ¸…ç†æ•°æ®åº“è®°å½•
        print(f"--- å¼€å§‹æ¸…ç†æ•°æ®åº“è®°å½• ---")
        
        try:
            # 5.1 åˆ é™¤å›¾å±‚è®°å½•
            delete_layer_sql = "DELETE FROM geoserver_layers WHERE id = %s"
            affected_rows = execute_query(delete_layer_sql, (layer_id,), fetch=False)
            print(f"âœ… åˆ é™¤å›¾å±‚è®°å½•: layer_id={layer_id} (å½±å“è¡Œæ•°: {affected_rows})")
            
            # 5.2 åˆ é™¤å…³è”çš„featuretypeæˆ–coverageè®°å½•
            if layer_info['featuretype_id']:
                delete_featuretype_sql = "DELETE FROM geoserver_featuretypes WHERE id = %s"
                affected_rows = execute_query(delete_featuretype_sql, (layer_info['featuretype_id'],), fetch=False)
                print(f"âœ… åˆ é™¤featuretypeè®°å½•: featuretype_id={layer_info['featuretype_id']} (å½±å“è¡Œæ•°: {affected_rows})")
            
            if layer_info['coverage_id']:
                delete_coverage_sql = "DELETE FROM geoserver_coverages WHERE id = %s"
                affected_rows = execute_query(delete_coverage_sql, (layer_info['coverage_id'],), fetch=False)
                print(f"âœ… åˆ é™¤coverageè®°å½•: coverage_id={layer_info['coverage_id']} (å½±å“è¡Œæ•°: {affected_rows})")
            
            # 5.3 æ£€æŸ¥å­˜å‚¨æ˜¯å¦è¿˜è¢«å…¶ä»–å›¾å±‚ä½¿ç”¨
            if layer_info['store_id']:
                check_store_usage_sql = """
                SELECT COUNT(*) as count FROM (
                    SELECT 1 FROM geoserver_featuretypes WHERE store_id = %s
                    UNION ALL
                    SELECT 1 FROM geoserver_coverages WHERE store_id = %s
                ) as usage_count
                """
                usage_result = execute_query(check_store_usage_sql, (layer_info['store_id'], layer_info['store_id']))
                usage_count = usage_result[0]['count']
                
                if usage_count == 0:
                    # æ²¡æœ‰å…¶ä»–å›¾å±‚ä½¿ç”¨æ­¤å­˜å‚¨ï¼Œåˆ é™¤å­˜å‚¨è®°å½•
                    delete_store_sql = "DELETE FROM geoserver_stores WHERE id = %s"
                    affected_rows = execute_query(delete_store_sql, (layer_info['store_id'],), fetch=False)
                    print(f"âœ… åˆ é™¤å­˜å‚¨è®°å½•: store_id={layer_info['store_id']} (å½±å“è¡Œæ•°: {affected_rows})")
                else:
                    print(f"âš ï¸ å­˜å‚¨ {store_name} ä»è¢«å…¶ä»– {usage_count} ä¸ªå›¾å±‚/è¦†ç›–ä½¿ç”¨ï¼Œä¿ç•™å­˜å‚¨è®°å½•")
            
            print(f"âœ… æ•°æ®åº“è®°å½•æ¸…ç†å®Œæˆ")
            
        except Exception as db_error:
            print(f"âŒ æ•°æ®åº“è®°å½•æ¸…ç†å¤±è´¥: {str(db_error)}")
            return jsonify({'success': False, 'error': f'æ•°æ®åº“æ¸…ç†å¤±è´¥: {str(db_error)}'}), 500
        
        print(f"=== å–æ¶ˆå‘å¸ƒGeoServeræœåŠ¡å®Œæˆ ===")
        
        # 6. è‡ªåŠ¨é‡ç½®GeoServerç¼“å­˜ä»¥é‡Šæ”¾æ–‡ä»¶é”å®š
        try:
            print(f"--- è‡ªåŠ¨é‡ç½®GeoServerç¼“å­˜ ---")
            reset_result = geoserver_service.reset_geoserver_caches()
            print(f"ç¼“å­˜é‡ç½®ç»“æœ: {reset_result}")
        except Exception as cache_error:
            print(f"âš ï¸ ç¼“å­˜é‡ç½®å¤±è´¥: {str(cache_error)}")
            # ä¸å½±å“ä¸»æµç¨‹ç»§ç»­
        
        return jsonify({
            'success': True,
            'message': 'GeoServeræœåŠ¡å–æ¶ˆå‘å¸ƒæˆåŠŸï¼Œå·²è‡ªåŠ¨é‡ç½®ç¼“å­˜',
            'deleted_layer': f"{workspace_name}:{layer_name}",
            'store_info': {
                'name': store_name,
                'type': store_type,
                'data_type': 'æ …æ ¼' if is_raster else 'çŸ¢é‡'
            },
            'cleanup_info': {
                'cache_reset': True,
                'recommendations': [
                    'å¦‚æœGeoServeræ•°æ®ç›®å½•ä¸­ä»æœ‰ç›¸å…³æ–‡ä»¶ï¼Œå¯è°ƒç”¨ /files/{file_id}/force-cleanup è¿›è¡Œå¼ºåˆ¶æ¸…ç†',
                    'å¦‚é‡æ–‡ä»¶è¢«å ç”¨é—®é¢˜ï¼Œå»ºè®®é‡å¯GeoServeræœåŠ¡',
                    'å¯ä»¥æ£€æŸ¥GeoServeræ—¥å¿—äº†è§£è¯¦ç»†ä¿¡æ¯'
                ]
            }
        }), 200
    
    except Exception as e:
        print(f"âŒ å–æ¶ˆå‘å¸ƒGeoServeræœåŠ¡å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'å–æ¶ˆå‘å¸ƒå¤±è´¥: {str(e)}'}), 500

@file_bp.route('/coordinate-systems/search', methods=['GET'])
def search_coordinate_systems():
    """æœç´¢åæ ‡ç³»"""
    try:
        # è·å–æœç´¢å…³é”®è¯
        keyword = request.args.get('keyword', '').strip()
        limit = int(request.args.get('limit', 20))
        
        if not keyword:
            return jsonify({'error': 'è¯·æä¾›æœç´¢å…³é”®è¯'}), 400
        
        # æŒ‰ç©ºæ ¼åˆ†å‰²å…³é”®è¯ï¼Œæ”¯æŒå¤šå…³é”®è¯æœç´¢
        keywords = [k.strip() for k in keyword.split() if k.strip()]
        
        if not keywords:
            return jsonify({'error': 'è¯·æä¾›æœ‰æ•ˆçš„æœç´¢å…³é”®è¯'}), 400
        
        # æ„å»ºå¤šå…³é”®è¯æœç´¢SQL
        # æ¯ä¸ªå…³é”®è¯éƒ½è¦åœ¨æ‰€æœ‰å­—æ®µä¸­æœç´¢ï¼Œä½¿ç”¨ANDè¿æ¥ä¸åŒå…³é”®è¯
        keyword_conditions = []
        params = []
        
        for i, kw in enumerate(keywords):
            # ä¸ºæ¯ä¸ªå…³é”®è¯æ„å»ºORæ¡ä»¶ï¼ˆåœ¨ä¸åŒå­—æ®µä¸­æœç´¢ï¼‰
            keyword_condition = f"""
            (
                LOWER(srtext) LIKE LOWER(%s) 
                OR LOWER(proj4text) LIKE LOWER(%s)
                OR CAST(srid AS TEXT) LIKE %s
                OR CAST(auth_srid AS TEXT) LIKE %s
            )
            """
            keyword_conditions.append(keyword_condition)
            
            # æ·»åŠ å‚æ•°ï¼ˆæ¯ä¸ªå…³é”®è¯éœ€è¦4ä¸ªå‚æ•°ï¼‰
            search_pattern = f'%{kw}%'
            params.extend([search_pattern, search_pattern, search_pattern, search_pattern])
        
        # ä½¿ç”¨ANDè¿æ¥æ‰€æœ‰å…³é”®è¯æ¡ä»¶
        where_clause = " AND ".join(keyword_conditions)
        
        search_sql = f"""
        SELECT 
            srid,
            auth_name,
            auth_srid,
            srtext,
            proj4text
        FROM spatial_ref_sys 
        WHERE {where_clause}
        ORDER BY 
            CASE 
                WHEN CAST(srid AS TEXT) = %s THEN 1
                WHEN CAST(auth_srid AS TEXT) = %s THEN 2
                WHEN LOWER(srtext) LIKE LOWER(%s) THEN 3
                ELSE 4
            END,
            srid
        LIMIT %s
        """
        
        # æ·»åŠ æ’åºå’Œé™åˆ¶å‚æ•°
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå…³é”®è¯è¿›è¡Œæ’åºä¼˜å…ˆçº§åˆ¤æ–­
        first_keyword = keywords[0]
        params.extend([first_keyword, first_keyword, f'%{first_keyword}%', limit])
        
        # æ‰§è¡ŒæŸ¥è¯¢
        results = execute_query(search_sql, params)
        
        # å¤„ç†ç»“æœï¼Œæå–æœ‰ç”¨ä¿¡æ¯
        coordinate_systems = []
        for row in results:
            # ä»srtextä¸­æå–åæ ‡ç³»åç§°
            srtext = row['srtext'] or ''
            name = extract_coordinate_system_name(srtext)
            
            # æ„å»ºæ˜¾ç¤ºåç§°
            display_name = f"EPSG:{row['auth_srid']}"
            if name:
                display_name += f" - {name}"
            
            coordinate_systems.append({
                'srid': row['srid'],
                'auth_name': row['auth_name'],
                'auth_srid': row['auth_srid'],
                'epsg_code': f"EPSG:{row['auth_srid']}",
                'name': name,
                'display_name': display_name,
                'srtext': srtext,
                'proj4text': row['proj4text']
            })
        
        return jsonify({
            'success': True,
            'coordinate_systems': coordinate_systems,
            'total': len(coordinate_systems),
            'keyword': keyword,
            'keywords': keywords
        }), 200
        
    except Exception as e:
        current_app.logger.error(f"æœç´¢åæ ‡ç³»å¤±è´¥: {str(e)}")
        return jsonify({'error': f'æœç´¢åæ ‡ç³»å¤±è´¥: {str(e)}'}), 500

def extract_coordinate_system_name(srtext):
    """ä»srtextä¸­æå–åæ ‡ç³»åç§°"""
    try:
        if not srtext:
            return None
            
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–PROJCSæˆ–GEOGCSä¸­çš„åç§°
        import re
        
        # åŒ¹é…PROJCS["name",...] æˆ– GEOGCS["name",...]
        pattern = r'(?:PROJCS|GEOGCS)\["([^"]+)"'
        match = re.search(pattern, srtext)
        
        if match:
            name = match.group(1)
            # æ¸…ç†åç§°ï¼Œç§»é™¤ä¸€äº›å¸¸è§çš„åç¼€
            name = re.sub(r'\s*\(.*?\)\s*$', '', name)  # ç§»é™¤æ‹¬å·å†…å®¹
            return name
            
        return None
        
    except Exception:
        return None

@file_bp.route('/coordinate-systems/common', methods=['GET'])
def get_common_coordinate_systems():
    """è·å–å¸¸ç”¨åæ ‡ç³»åˆ—è¡¨"""
    try:
        # å®šä¹‰å¸¸ç”¨åæ ‡ç³»çš„EPSGä»£ç 
        common_epsgs = [
            4326,   # WGS 84
            3857,   # Web Mercator
            4490,   # CGCS2000
            4214,   # Beijing 1954
            4610,   # Xian 1980
            2383,   # Xian 1980 / 3-degree Gauss-Kruger CM 114E
            4549,   # CGCS2000 / 3-degree Gauss-Kruger CM 114E
            4548,   # CGCS2000 / 3-degree Gauss-Kruger CM 111E
            4547,   # CGCS2000 / 3-degree Gauss-Kruger CM 108E
            4546,   # CGCS2000 / 3-degree Gauss-Kruger CM 105E
        ]
        
        # æ„å»ºæŸ¥è¯¢SQL
        placeholders = ','.join(['%s'] * len(common_epsgs))
        sql = f"""
        SELECT 
            srid,
            auth_name,
            auth_srid,
            srtext,
            proj4text
        FROM spatial_ref_sys 
        WHERE auth_srid IN ({placeholders})
        ORDER BY 
            CASE auth_srid
                WHEN 4326 THEN 1
                WHEN 3857 THEN 2  
                WHEN 4490 THEN 3
                WHEN 4214 THEN 4
                WHEN 4610 THEN 5
                ELSE 6
            END
        """
        
        results = execute_query(sql, common_epsgs)
        
        # å¤„ç†ç»“æœ
        coordinate_systems = []
        for row in results:
            srtext = row['srtext'] or ''
            name = extract_coordinate_system_name(srtext)
            
            display_name = f"EPSG:{row['auth_srid']}"
            if name:
                display_name += f" - {name}"
            
            coordinate_systems.append({
                'srid': row['srid'],
                'auth_name': row['auth_name'],
                'auth_srid': row['auth_srid'],
                'epsg_code': f"EPSG:{row['auth_srid']}",
                'name': name,
                'display_name': display_name,
                'srtext': srtext,
                'proj4text': row['proj4text']
            })
        
        return jsonify({
            'success': True,
            'coordinate_systems': coordinate_systems,
            'total': len(coordinate_systems)
        }), 200
        
    except Exception as e:
        current_app.logger.error(f"è·å–å¸¸ç”¨åæ ‡ç³»å¤±è´¥: {str(e)}")
        return jsonify({'error': f'è·å–å¸¸ç”¨åæ ‡ç³»å¤±è´¥: {str(e)}'}), 500

@file_bp.route('/<string:file_id>/force-cleanup', methods=['POST'])
def force_cleanup_geoserver_files(file_id):
    """å¼ºåˆ¶æ¸…ç†GeoServeræ–‡ä»¶å’Œç¼“å­˜"""
    try:
        print(f"=== å¼€å§‹å¼ºåˆ¶æ¸…ç†GeoServeræ–‡ä»¶ ===")
        print(f"æ–‡ä»¶ID: {file_id}")
        
        # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_info = file_service.get_file_by_id(file_id)
        if not file_info:
            return jsonify({'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # 2. å¼ºåˆ¶é‡ç½®GeoServerç¼“å­˜å’Œè¿æ¥
        from services.geoserver_service import GeoServerService
        geoserver_service = GeoServerService()
        
        # 3. è°ƒç”¨GeoServer REST APIé‡ç½®æ‰€æœ‰ç¼“å­˜
        reset_result = geoserver_service.reset_geoserver_caches()
        print(f"GeoServerç¼“å­˜é‡ç½®ç»“æœ: {reset_result}")
        
        # 4. è·å–GeoServeræ•°æ®ç›®å½•ä¸­çš„ç›¸å…³æ–‡ä»¶
        cleanup_paths = geoserver_service.get_file_cleanup_paths(file_id)
        
        # 5. å°è¯•åˆ é™¤æ–‡ä»¶
        cleanup_results = []
        for file_path in cleanup_paths:
            result = geoserver_service.force_delete_file(file_path)
            cleanup_results.append({
                'path': file_path,
                'success': result['success'],
                'message': result['message']
            })
        
        return jsonify({
            'success': True,
            'message': 'å¼ºåˆ¶æ¸…ç†æ“ä½œå®Œæˆ',
            'reset_result': reset_result,
            'cleanup_results': cleanup_results,
            'recommendations': [
                'å¦‚æœæ–‡ä»¶ä»è¢«å ç”¨ï¼Œè¯·é‡å¯GeoServeræœåŠ¡',
                'å¯ä»¥ä½¿ç”¨Process Exploreræˆ–Resource MonitoræŸ¥çœ‹æ–‡ä»¶å¥æŸ„',
                'å¿…è¦æ—¶å¯ä»¥é‡å¯æ•´ä¸ªåº”ç”¨æœåŠ¡å™¨'
            ]
        }), 200
        
    except Exception as e:
        print(f"å¼ºåˆ¶æ¸…ç†å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'å¼ºåˆ¶æ¸…ç†å¤±è´¥: {str(e)}'}), 500 